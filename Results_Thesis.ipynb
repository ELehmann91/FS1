{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Results_Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cjj7J65SZxsE",
        "RffXXZigrgGL",
        "eszN0r_mWfF9"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ELehmann91/FS1/blob/master/Results_Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru35-Xo1kmrW",
        "colab_type": "text"
      },
      "source": [
        "# Train script\n",
        "  \n",
        "using prewritten fuctions and standardized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5sB703QrHaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a6344b64-7b46-47e5-847f-6d1104caf6f7"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive, files\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path ='/content/gdrive/My Drive/Thesis_ecb_ecoicop'"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJUAJfPTnMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install eli5\n",
        "!git clone 'https://github.com/ELehmann91/Thesis_Multilingual_Transferlearning'\n",
        "\n",
        "%cd Thesis_Multilingual_Transferlearning\n",
        "import labeler_cc5\n",
        "import coicop_model\n",
        "import model_helper\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import io"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iupya9-dk4m0",
        "colab_type": "text"
      },
      "source": [
        "## Import Data\n",
        "  \n",
        "data in the normalized folder are splitted between languages (currently de fr & it) and share the same columns so they can be merged easily"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvvxjN1mrrZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "529f814d-4b82-41e8-ea02-86d74abb7c34"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_path = '/data/'#\n",
        "#file_path = 'fra/carrfour_trans_pred.csv'\n",
        "file_path = 'normalized/norm_fr.csv'\n",
        "file_path2 = 'normalized/norm_de.csv'\n",
        "file_path3 = 'at/norm_at.csv'\n",
        "#file_path = 'edeka_pred.csv'\n",
        "\n",
        "# french data\n",
        "df_fr = pd.read_csv(path+data_path+file_path,sep='|',index_col=False)\n",
        "\n",
        "# only already labeled\n",
        "df_fr = df_fr[df_fr['cc5'].isna()==False]\n",
        "df_fr = df_fr[df_fr['shop'].isin( ['carrefour','auchan'])]#,'banque_de_france'])]\n",
        "df_fr['cc5'] = df_fr['cc5'].apply(lambda x: '9999_Non-Food' if int(str(x)[0])>2 else x)\n",
        "print(len(df_fr))\n",
        "\n",
        "# german data\n",
        "df_de = pd.read_csv(path+data_path+file_path2,sep='|',index_col=False)\n",
        "# only already labeled\n",
        "df_de = df_de[df_de['cc5'].isna()==False]\n",
        "print(len(df_de))\n",
        "# austrian data\n",
        "df_at = pd.read_csv(path+data_path+file_path3,sep='|',index_col=False)\n",
        "# only already labeled\n",
        "df_at = df_at[df_at['cc5'].isna()==False]\n",
        "df_de = df_de.append(df_at)\n",
        "print(len(df_de))\n",
        "\n",
        "df_fr = df_fr.sample(frac=1).reset_index(drop=True)\n",
        "df_de = df_de.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7923\n",
            "21903\n",
            "23199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZH6sOjr2_no",
        "colab_type": "text"
      },
      "source": [
        "### Exclude non-food?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-40uLS9OAZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "dd24240c-54a9-412e-8ea9-a981e3cd7624"
      },
      "source": [
        "no_Classes = 75\n",
        "exclude_non_food = True\n",
        "if exclude_non_food:\n",
        "    df_fr = df_fr[df_fr['cc5']!='9999_Non-Food']\n",
        "    df_de = df_de[df_de['cc5']!='9999_Non-Food']\n",
        "    df_at = df_at[df_at['cc5']!='9999_Non-Food']\n",
        "    no_Classes = 74\n",
        "    print(len(df_fr))\n",
        "    print(len(df_de))\n",
        "    print(len(df_at))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7225\n",
            "22064\n",
            "241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vswr191ClXi1",
        "colab_type": "text"
      },
      "source": [
        "decide which columns should be used for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n55A0HV-g95g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var = 'name'\n",
        "#df_fr['text'] = df_fr[var].fillna('unknown') \n",
        "#df_de['text'] = df_de[var].fillna('unknown') \n",
        "#df_at['text'] = df_at[var].fillna('unknown') \n",
        "\n",
        "var1 = 'categ'\n",
        "var2 = 'words_from_url'\n",
        "#df_fr['text'] = df_fr[var1].fillna('unknown')  + ' <sep> ' + df_fr[var2].fillna('unknown') \n",
        "#df_de['text'] = df_de[var1].fillna('unknown')  + ' <sep> ' + df_de[var2].fillna('unknown') \n",
        "#df_at['text'] = df_at[var1].fillna('unknown')  + ' <sep> ' + df_at[var2].fillna('unknown') \n",
        "\n",
        "\n",
        "#var1 = 'categ'\n",
        "#var2 = 'words_from_url' \n",
        "#var3 = 'name'\n",
        "var1 = 'name' \n",
        "var2 = 'categ' \n",
        "var3 = 'words_from_url' \n",
        "df_fr['text'] = ' <fr> ' + df_fr[var1].fillna('unknown')  + ' <sep> ' + df_fr[var2].fillna('unknown')  + ' <sep> ' + df_fr[var3].fillna('unknown') \n",
        "df_de['text'] = ' <de> ' + df_de[var1].fillna('unknown')  + ' <sep> ' + df_de[var2].fillna('unknown')  + ' <sep> ' + df_de[var3].fillna('unknown') \n",
        "df_at['text'] = ' <de> ' + df_at[var1].fillna('unknown')  + ' <sep> ' + df_at[var2].fillna('unknown')  + ' <sep> ' + df_at[var3].fillna('unknown') \n",
        "\n",
        "#df_fr['text'] = df_fr[var1].fillna('unknown')  + df_fr[var2].fillna('unknown')  + df_fr[var3].fillna('unknown') \n",
        "#df_de['text'] = df_de[var1].fillna('unknown')  + df_de[var2].fillna('unknown')  + df_de[var3].fillna('unknown') \n",
        "#df_at['text'] = df_at[var1].fillna('unknown')  + df_at[var2].fillna('unknown')  + df_at[var3].fillna('unknown') \n",
        "\n",
        "#df_fr['text'] = ' <fr> ' + df_fr['name'] + ' <sep> ' + df_fr['categ'].fillna('unknown') + ' <sep> ' + df_fr['words_from_url'].fillna('unknown') + ' <sep> ' + df_fr['prod_desc'].fillna('unknown') \n",
        "#df_de['text'] = ' <de> ' + df_de['name'] + ' <sep> ' + df_de['categ'].fillna('unknown') + ' <sep> ' + df_de['words_from_url'].fillna('unknown') + ' <sep> ' + df_de['prod_desc'].fillna('unknown') \n",
        "#df_at['text'] = ' <de> ' + df_at['name'] + ' <sep> ' + df_at['categ'].fillna('unknown') + ' <sep> ' + df_at['words_from_url'].fillna('unknown') + ' <sep> ' + df_at['prod_desc'].fillna('unknown') \n"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScESyOiJNwoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "rep_dict = {'.':' ',\n",
        "                        ',': ' ',\n",
        "                        '&': ' ',\n",
        "                        '-': ' ',\n",
        "                        '/': ' ',\n",
        "                        'ü': 'ue',\n",
        "                        'ä': 'ae',\n",
        "                        'ö': 'oe',\n",
        "                        'ß': 'ss',\n",
        "                        'ê': 'e',\n",
        "                        'é': 'e',\n",
        "                        'è': 'e',\n",
        "                        'â': 'a',\n",
        "                        'á': 'a',\n",
        "                        'à': 'a',\n",
        "                        'ô':'o',\n",
        "                        'œ': 'ae',\n",
        "                        '%': ' percent ',\n",
        "                        '1': ' one ',\n",
        "                        '2': ' two ',\n",
        "                        '3': ' three ',\n",
        "                        '4': ' four ',\n",
        "                        '5': ' five ',\n",
        "                        '6': ' six ',\n",
        "                        '7': ' seven ',\n",
        "                        '8': ' eigth ',\n",
        "                        '9': ' nine ',\n",
        "                        '0': ' zero ',\n",
        "                        ' l ':' liter ',\n",
        "                        ' ml ':' liter '\n",
        "                        }\n",
        "\n",
        "def prepro(line):\n",
        "    if isinstance(line,str):\n",
        "        text_str = ' '.join(str(t) for t in line.split())\n",
        "        text_str = text_str.lower()\n",
        "        for a,b in rep_dict.items():\n",
        "            text_str = text_str.replace(a,b)\n",
        "        text_str = re.sub('[^a-zäöüàáâéèêßœ<>]+', ' ', text_str)\n",
        "    else: \n",
        "        text_str = str(line)\n",
        "    return text_str"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1on_by8aNzmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fr['text'] = df_fr['text'].apply(lambda x:prepro(x))\n",
        "df_de['text'] = df_de['text'].apply(lambda x:prepro(x))\n",
        "df_at['text'] = df_at['text'].apply(lambda x:prepro(x))"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUiw5fuU250I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "36cc6ff8-564d-47be-aac1-f6ab83ed5d7b"
      },
      "source": [
        "print('50% quantile no. of words per row french',np.quantile(df_fr['text'].apply(lambda x: len(str(x).split())),.50))\n",
        "print('50% quantile no. of words per row german',np.quantile(df_de['text'].apply(lambda x: len(str(x).split())),.50))\n",
        "print('50% quantile no. of words per row austrian',np.quantile(df_at['text'].apply(lambda x: len(str(x).split())),.50))\n",
        "\n",
        "print('90% quantile no. of words per row french',np.quantile(df_fr['text'].apply(lambda x: len(str(x).split())),.90))\n",
        "print('90% quantile no. of words per row german',np.quantile(df_de['text'].apply(lambda x: len(str(x).split())),.90))\n",
        "print('90% quantile no. of words per row austrian',np.quantile(df_at['text'].apply(lambda x: len(str(x).split())),.90))\n",
        "\n",
        "seq_len = int(max(np.quantile(df_fr['text'].apply(lambda x: len(str(x).split())),.75),np.quantile(df_de['text'].apply(lambda x: len(str(x).split())),.95)))\n",
        "print('seq_len',seq_len)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50% quantile no. of words per row french 28.0\n",
            "50% quantile no. of words per row german 19.0\n",
            "50% quantile no. of words per row austrian 19.0\n",
            "90% quantile no. of words per row french 36.0\n",
            "90% quantile no. of words per row german 29.700000000000728\n",
            "90% quantile no. of words per row austrian 24.0\n",
            "seq_len 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPbed6wD3pXB",
        "colab_type": "text"
      },
      "source": [
        "### Split Train Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvZmopEj259h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cd80544b-201f-4763-b457-70aaa5125829"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def split_train_abs(df):\n",
        "    X_train, X_val_test, y_train, y_val_test  = train_test_split(df['text'], df['cc5'], random_state=42, shuffle=True)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val_test , y_val_test, train_size=.5,random_state=42)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "X_train_de, X_val_de, X_test_de, y_train_de, y_val_de, y_test_de = split_train_abs(df_de)\n",
        "X_train_fr, X_val_fr, X_test_fr, y_train_fr, y_val_fr, y_test_fr = split_train_abs(df_fr)\n",
        "\n",
        "print('de',X_train_de.shape, X_val_de.shape, X_test_de.shape, y_train_de.shape, y_val_de.shape, y_test_de.shape )\n",
        "print('fr',X_train_fr.shape, X_val_fr.shape, X_test_fr.shape, y_train_fr.shape, y_val_fr.shape, y_test_fr.shape )"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de (16548,) (2758,) (2758,) (16548,) (2758,) (2758,)\n",
            "fr (5418,) (903,) (904,) (5418,) (903,) (904,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5t7nvAB6U7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2c07a12-1523-47b1-d103-d8763a0b39ef"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer_de = Tokenizer()\n",
        "tokenizer_de.fit_on_texts(X_train_de.append(X_val_de))\n",
        "vocab_size_de = len(tokenizer_de.word_index) + 1\n",
        "\n",
        "tokenizer_fr = Tokenizer()\n",
        "tokenizer_fr.fit_on_texts(X_train_fr.append(X_val_fr))\n",
        "vocab_size_fr = len(tokenizer_fr.word_index) + 1\n",
        "\n",
        "tokenizer_de_fr = Tokenizer()\n",
        "tokenizer_de_fr.fit_on_texts(X_train_de.append(X_val_de).append(X_train_fr).append(X_val_fr))\n",
        "\n",
        "vocab_size_de_fr = len(tokenizer_de_fr.word_index) + 1\n",
        "print(vocab_size_de,vocab_size_fr,vocab_size_de_fr)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12126 3962 14787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBPdY7e98jRw",
        "colab_type": "text"
      },
      "source": [
        "tokenize & pad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYz66JnJ5dNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#german\n",
        "X_train_tokens_de = tokenizer_de.texts_to_sequences(X_train_de)\n",
        "X_val_tokens_de = tokenizer_de.texts_to_sequences(X_val_de)\n",
        "X_test_tokens_de = tokenizer_de.texts_to_sequences(X_test_de)\n",
        "\n",
        "X_train_pad_de = pad_sequences(X_train_tokens_de,maxlen=seq_len, padding='post')\n",
        "X_val_pad_de = pad_sequences(X_val_tokens_de,maxlen=seq_len, padding='post')\n",
        "X_test_pad_de = pad_sequences(X_test_tokens_de,maxlen=seq_len, padding='post')\n",
        "\n",
        "#french\n",
        "X_train_tokens_fr = tokenizer_fr.texts_to_sequences(X_train_fr)\n",
        "X_val_tokens_fr = tokenizer_fr.texts_to_sequences(X_val_fr)\n",
        "X_test_tokens_fr = tokenizer_fr.texts_to_sequences(X_test_fr)\n",
        "\n",
        "X_train_pad_fr = pad_sequences(X_train_tokens_fr,maxlen=seq_len, padding='post')\n",
        "X_val_pad_fr = pad_sequences(X_val_tokens_fr,maxlen=seq_len, padding='post')\n",
        "X_test_pad_fr = pad_sequences(X_test_tokens_fr,maxlen=seq_len, padding='post')"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X22q8A2r8rmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "d6c38c47-fd5c-47c6-ef63-687dbbffa5ed"
      },
      "source": [
        "import pickle\n",
        "french = True\n",
        "german = True\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "if french:\n",
        "    fr_git_embed = pickle.load( open(path + '/embeddings/fr_slim_embed_ext.p', \"rb\" ) ) #fr_slim_embed_ext #fr_muse_align #fr_muse\n",
        "    #fr_model = KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Thesis_ecb_ecoicop/embeddings/wiki.fr.vec')\n",
        "if german:\n",
        "    de_git_embed = pickle.load( open(path + '/embeddings/de_slim_embed_ext.p', \"rb\" ) ) #de_muse\n",
        "    #de_model = KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Thesis_ecb_ecoicop/embeddings/wiki.de.vec')\n",
        "\n",
        "v = np.zeros(300)\n",
        "v[0]=1\n",
        "fr_git_embed['<sep>'] = v\n",
        "de_git_embed['<sep>'] = v\n",
        "v[0]=0\n",
        "v[1]=1\n",
        "fr_git_embed['<fr>'] = v\n",
        "v[1]=-1\n",
        "de_git_embed['<de>'] = v\n",
        "\n",
        "print('de_git_embed',len(de_git_embed.keys()))\n",
        "print('fr_git_embed',len(fr_git_embed.keys()))\n",
        "\n",
        "X_train_emb_de = np.array(list(model_helper.text_to_embed(X_train_de, ['de' for a in X_train_de], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_val_emb_de = np.array(list(model_helper.text_to_embed(X_val_de, ['de' for a in X_val_de], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_test_emb_de = np.array(list(model_helper.text_to_embed(X_test_de, ['de' for a in X_test_de], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "\n",
        "X_train_emb_fr = np.array(list(model_helper.text_to_embed(X_train_fr, ['fr' for a in X_train_fr], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_val_emb_fr = np.array(list(model_helper.text_to_embed(X_val_fr, ['fr' for a in X_val_fr], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_test_emb_fr = np.array(list(model_helper.text_to_embed(X_test_fr, ['fr' for a in X_test_fr], de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "\n",
        "print('de',X_train_emb_de.shape, X_val_emb_de.shape, X_test_emb_de.shape)\n",
        "print('fr',X_train_emb_fr.shape, X_val_emb_fr.shape, X_test_emb_fr.shape)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761it [00:00, 7603.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "de_git_embed 64413\n",
            "fr_git_embed 43014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16548it [00:02, 7854.59it/s]\n",
            "2758it [00:00, 7841.19it/s]\n",
            "2758it [00:00, 7833.22it/s]\n",
            "5418it [00:00, 8040.78it/s]\n",
            "903it [00:00, 7649.56it/s]\n",
            "904it [00:00, 8502.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "de (16548, 32, 300) (2758, 32, 300) (2758, 32, 300)\n",
            "fr (5418, 32, 300) (903, 32, 300) (904, 32, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjZke3ew9XYX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6cf3b111-3344-41e3-c8c2-a50ce6aa2325"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(df_de['cc5'])\n",
        "\n",
        "def encode_label(y_):\n",
        "    y__ = encoder.transform(y_)\n",
        "    y_enc =tf.keras.utils.to_categorical(y__, num_classes=no_Classes, dtype=\"float32\")\n",
        "    return y_enc\n",
        "\n",
        "y_train_enc_de = encode_label(y_train_de)\n",
        "y_val_enc_de = encode_label(y_val_de)\n",
        "y_test_enc_de = encode_label(y_test_de)\n",
        "\n",
        "y_train_enc_fr = encode_label(y_train_fr)\n",
        "y_val_enc_fr = encode_label(y_val_fr)\n",
        "y_test_enc_fr = encode_label(y_test_fr)\n",
        "\n",
        "print(y_train_enc_de.shape,y_val_enc_de.shape,y_test_enc_de.shape)\n",
        "print(y_train_enc_fr.shape,y_val_enc_fr.shape,y_test_enc_fr.shape)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16548, 74) (2758, 74) (2758, 74)\n",
            "(5418, 74) (903, 74) (904, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOG6Bc_RVe10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weigth_dict(y_train):\n",
        "    weights_dict = dict(zip(y_train.value_counts().index.tolist(),list(len(y_train) / ( len(y_train.unique())  * y_train.value_counts()))))\n",
        "\n",
        "    class_weight_dict = {}\n",
        "    for n,lab in enumerate(encoder.classes_):\n",
        "        try:\n",
        "            class_weight_dict[n] = weights_dict[lab]\n",
        "        except:\n",
        "            class_weight_dict[n] = 1\n",
        "    return class_weight_dict\n",
        "\n",
        "class_weight_dict_de = get_weigth_dict(y_train_de)\n",
        "class_weight_dict_fr = get_weigth_dict(y_train_fr)\n",
        "class_weight_dict_de_fr = get_weigth_dict(y_train_de.append(y_train_fr))"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so7nxPzl5dKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unknown = np.random.rand(embedding_dim)\n",
        "\n",
        "def get_embed_matrix(embed,tokenizer,vocab_size,embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word,i in tokenizer.word_index.items():\n",
        "        try:\n",
        "            embedding_matrix[i] = embed[word]\n",
        "        except KeyError:\n",
        "            #next\n",
        "            embedding_matrix[i] = unknown #np.random.rand(embedding_dim)\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix_de = get_embed_matrix(de_git_embed,tokenizer_de,vocab_size_de,embedding_dim)\n",
        "embedding_matrix_fr = get_embed_matrix(fr_git_embed,tokenizer_fr,vocab_size_fr,embedding_dim)\n",
        "\n",
        "combine_embed = de_git_embed\n",
        "combine_embed.update(fr_git_embed)\n",
        "embedding_matrix_de_fr = get_embed_matrix(combine_embed,tokenizer_de_fr,vocab_size_de_fr,embedding_dim)\n"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09DZu4q4nouv",
        "colab_type": "text"
      },
      "source": [
        "# Single Language Classifier German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upNTfEpdntqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, balanced_accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2q91oJWnttV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_idf_log_reg(X_train,y_train,X_test,y_test,no,weights_dict):\n",
        "    X_train = [str(x).replace('<','').replace('>','') for x in X_train[:no]]\n",
        "    y_train = y_train[:no]\n",
        "    X_test = [str(x).replace('<','').replace('>','') for x in X_test]\n",
        "    vectorizer  = TfidfVectorizer()\n",
        "    vectorizer.fit(X_train)\n",
        "    X_train_vec = vectorizer.transform(X_train)\n",
        "    X_test_vec  = vectorizer.transform(X_test)\n",
        "\n",
        "    logreg = LogisticRegression(C=1,max_iter=500, solver='newton-cg')#,class_weight=weights_dict)\n",
        "    logreg.fit(X_train_vec, y_train)\n",
        "\n",
        "    y_pred_train = logreg.predict(X_train_vec)\n",
        "    y_pred_test = logreg.predict(X_test_vec)\n",
        "\n",
        "    print('train obs.',no,'accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
        "    print('train obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_train, y_train))\n",
        "    print('test obs.',no,'accuracy %s' % accuracy_score(y_pred_test, y_test))\n",
        "    print('test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test, y_test))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNe84VIOxHo",
        "colab_type": "text"
      },
      "source": [
        "##LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsi7UOpeiGDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "bd5dbb42-ce72-47b0-ee4c-19839cc75eb0"
      },
      "source": [
        "tf_idf_log_reg(X_train_de,y_train_de,X_test_de,y_test_de,7500,class_weight_dict_de)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train obs. 7500 accuracy 0.946\n",
            "train obs. 7500 b_accuracy 0.9533639227124376\n",
            "test obs. 7500 accuracy 0.9093546047860769\n",
            "test obs. 7500 b_accuracy 0.896177281600899\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IVDbZDzn4zv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "c45741c7-7677-4ba7-db78-c6ddf3cbec59"
      },
      "source": [
        "stra = False\n",
        "for obs in [250,500,1000,2000,5000,10000,15000]:\n",
        "    tf_idf_log_reg(X_train_de,y_train_de,X_test_de,y_test_de,obs,class_weight_dict_de)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train obs. 250 accuracy 0.712\n",
            "train obs. 250 b_accuracy 0.8904477499812186\n",
            "test obs. 250 accuracy 0.43981145757795503\n",
            "test obs. 250 b_accuracy 0.7102677805085398\n",
            "\n",
            "train obs. 500 accuracy 0.848\n",
            "train obs. 500 b_accuracy 0.9208751856797603\n",
            "test obs. 500 accuracy 0.6722262509064539\n",
            "test obs. 500 b_accuracy 0.7821326528055228\n",
            "\n",
            "train obs. 1000 accuracy 0.873\n",
            "train obs. 1000 b_accuracy 0.9245646211589628\n",
            "test obs. 1000 accuracy 0.7400290065264684\n",
            "test obs. 1000 b_accuracy 0.794090869601478\n",
            "\n",
            "train obs. 2000 accuracy 0.9115\n",
            "train obs. 2000 b_accuracy 0.9419072298487603\n",
            "test obs. 2000 accuracy 0.8292240754169689\n",
            "test obs. 2000 b_accuracy 0.8556651411116252\n",
            "\n",
            "train obs. 5000 accuracy 0.94\n",
            "train obs. 5000 b_accuracy 0.9486689241398468\n",
            "test obs. 5000 accuracy 0.897389412617839\n",
            "test obs. 5000 b_accuracy 0.8936069459962492\n",
            "\n",
            "train obs. 10000 accuracy 0.9539\n",
            "train obs. 10000 b_accuracy 0.9567879514596341\n",
            "test obs. 10000 accuracy 0.9213197969543148\n",
            "test obs. 10000 b_accuracy 0.9099505194549371\n",
            "\n",
            "train obs. 15000 accuracy 0.9588666666666666\n",
            "train obs. 15000 b_accuracy 0.9584687185439551\n",
            "test obs. 15000 accuracy 0.9347353154459753\n",
            "test obs. 15000 b_accuracy 0.9203519679949796\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7FiZZp6OvSB",
        "colab_type": "text"
      },
      "source": [
        "## NN Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP1eMhccQBtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, AvgPool2D,Dropout, Dense,Embedding, Flatten,Reshape, GlobalAveragePooling1D,MaxPool2D, Concatenate,Conv1D,Conv2D,BatchNormalization,Add,Masking,GlobalMaxPooling1D,LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.regularizers import l1,l2\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7KbLKMg634_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_CNN(X_train_pad,y_train_enc,X_val_pad,y_val_enc,X_test_pad,y_test,\n",
        "            vocab_size,embedding_matrix,class_weight_dict,no):\n",
        "    \n",
        "\n",
        "    dropout_rate=.5\n",
        "\n",
        "    lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/75)\n",
        "\n",
        "    input_layer = Input(shape = (seq_len,), dtype = 'float')\n",
        "    embedd_seq = Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "    conv_layer = Conv1D(filters=150,   kernel_size= 5,   padding='valid',  activation='relu', strides=1)(embedd_seq)\n",
        "    pool_layer = GlobalMaxPooling1D()(conv_layer)\n",
        "    #pool_layer = GlobalAveragePooling1D()(embedd_seq)\n",
        "    drop_layer = Dropout(dropout_rate)(pool_layer)\n",
        "    pred_layer = Dense(y_train_enc.shape[1], activation = 'softmax')(drop_layer) #, kernel_regularizer=l1_l2(0.001)\n",
        "\n",
        "    avg_pool_mod = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    avg_pool_mod.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = avg_pool_mod.fit(x = X_train_pad[:no], y = y_train_enc[:no],\\\n",
        "                    validation_data = (X_val_pad, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 256, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test = avg_pool_mod.predict(X_test_pad)\n",
        "    y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "    y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "    print('test obs.',no,'accuracy %s' % accuracy_score(y_pred_test, y_test))\n",
        "    print('test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test, y_test))\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty02iah0mBfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_CNN2D(X_train_pad,y_train_enc,X_val_pad,y_val_enc,X_test_pad,y_test,\n",
        "              vocab_size,embedding_matrix,class_weight_dict,no,max=True,emb_train=False):\n",
        "    \n",
        "    dropout_rate= .001\n",
        "    filter_sizes = [1,2,5]\n",
        "    num_filters = 75\n",
        "\n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    x = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable = emb_train)(input_layer)\n",
        "    x = Reshape((seq_len, embedding_dim, 1))(x)\n",
        "\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embedding_dim),\n",
        "                                      kernel_initializer='he_normal', activation='relu')(x)\n",
        "        if max:                              \n",
        "            maxpool_pool.append(MaxPool2D(pool_size=(seq_len - filter_sizes[i] + 1, 1))(conv))\n",
        "        else:\n",
        "            maxpool_pool.append(AvgPool2D(pool_size=(seq_len - filter_sizes[i] + 1, 1))(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "\n",
        "    #conv_layer = Conv2D(filters=100,   kernel_size=(5,300),   padding='same',  activation='relu', strides=1,name='convolution')(x)\n",
        "    #pool_layer = MaxPool2D(pool_size = (35,1),name='max_pooling')(conv_layer)\n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn2d = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "    #de_cnn2d.summary()\n",
        "    #lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    de_cnn2d.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = de_cnn2d.fit(x = X_train_pad[:no], y = y_train_enc[:no],\\\n",
        "                    validation_data = (X_val_pad, y_val_enc), \\\n",
        "                    epochs = 150, batch_size = 256, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test = de_cnn2d.predict(X_test_pad)\n",
        "    y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "    y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "    print('test obs.',no,'accuracy %s' % accuracy_score(y_pred_test, y_test))\n",
        "    print('test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test, y_test))"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHsjtwzX64cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_RNN(X_train_pad,y_train_enc,X_val_pad,y_val_enc,X_test_pad,y_test,vocab_size,embedding_matrix,class_weight_dict,no):\n",
        "    dropout_rate=.5\n",
        "    lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "    input_layer = Input(shape = (seq_len,), dtype = 'int32')\n",
        "    embedd_seq = Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], input_length = seq_len, trainable = True)(input_layer)\n",
        "    lstm_layer = Bidirectional(LSTM(128,activation = 'tanh',recurrent_activation = 'sigmoid', dropout = dropout_rate,recurrent_dropout = 0, unroll = False,use_bias = True))(embedd_seq)\n",
        "    drop_layer = Dropout(dropout_rate)(lstm_layer)\n",
        "    pred_layer = Dense(y_train_enc.shape[1], activation = 'softmax')(drop_layer) #, kernel_regularizer=l1_l2(0.001)\n",
        "\n",
        "    avg_pool_mod = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    avg_pool_mod.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = avg_pool_mod.fit(x = X_train_pad[:no], y = y_train_enc[:no],\\\n",
        "                    validation_data = (X_val_pad, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 256, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test = avg_pool_mod.predict(X_test_pad)\n",
        "    y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "    y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "    print('test obs.',no,'accuracy %s' % accuracy_score(y_pred_test, y_test))\n",
        "    print('test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test, y_test))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1E-j4fIQJTa",
        "colab_type": "text"
      },
      "source": [
        "##CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3tEI_3HQNSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "803c45fb-7b60-4bf0-f7d7-c781846ea2e8"
      },
      "source": [
        "for obs in [500,1000,2000,5000,10000,15000]:\n",
        "     run_CNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 4.6950 - accuracy: 0.0080 - val_loss: 4.4204 - val_accuracy: 0.0018\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 4.3491 - accuracy: 0.0340 - val_loss: 4.2455 - val_accuracy: 0.0421\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 4.0200 - accuracy: 0.0320 - val_loss: 4.1881 - val_accuracy: 0.0631\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 3.7197 - accuracy: 0.0580 - val_loss: 4.0305 - val_accuracy: 0.1033\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 3.4989 - accuracy: 0.1100 - val_loss: 3.8984 - val_accuracy: 0.1972\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 3.1687 - accuracy: 0.2140 - val_loss: 3.8003 - val_accuracy: 0.2382\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 2.9849 - accuracy: 0.2960 - val_loss: 3.6731 - val_accuracy: 0.2375\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 2.7514 - accuracy: 0.3140 - val_loss: 3.4597 - val_accuracy: 0.3002\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.4899 - accuracy: 0.4020 - val_loss: 3.2478 - val_accuracy: 0.3299\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 2.1948 - accuracy: 0.5100 - val_loss: 3.0459 - val_accuracy: 0.3891\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.8673 - accuracy: 0.5640 - val_loss: 2.8384 - val_accuracy: 0.4333\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1.5911 - accuracy: 0.6380 - val_loss: 2.6517 - val_accuracy: 0.4663\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1.4029 - accuracy: 0.6480 - val_loss: 2.4732 - val_accuracy: 0.5044\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.1635 - accuracy: 0.7240 - val_loss: 2.3138 - val_accuracy: 0.5392\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.0206 - accuracy: 0.7720 - val_loss: 2.1774 - val_accuracy: 0.5645\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.8384 - accuracy: 0.8160 - val_loss: 2.0617 - val_accuracy: 0.5943\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.7662 - accuracy: 0.8360 - val_loss: 1.9565 - val_accuracy: 0.6160\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5402 - accuracy: 0.8840 - val_loss: 1.8612 - val_accuracy: 0.6342\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4899 - accuracy: 0.9060 - val_loss: 1.7827 - val_accuracy: 0.6421\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4235 - accuracy: 0.8980 - val_loss: 1.7278 - val_accuracy: 0.6552\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.3671 - accuracy: 0.9220 - val_loss: 1.6878 - val_accuracy: 0.6766\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.3200 - accuracy: 0.9380 - val_loss: 1.6432 - val_accuracy: 0.6893\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2668 - accuracy: 0.9580 - val_loss: 1.6077 - val_accuracy: 0.7005\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2203 - accuracy: 0.9520 - val_loss: 1.5785 - val_accuracy: 0.7070\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.2269 - accuracy: 0.9600 - val_loss: 1.5505 - val_accuracy: 0.7114\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1869 - accuracy: 0.9600 - val_loss: 1.5292 - val_accuracy: 0.7241\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1567 - accuracy: 0.9720 - val_loss: 1.5177 - val_accuracy: 0.7252\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1282 - accuracy: 0.9760 - val_loss: 1.5134 - val_accuracy: 0.7292\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.1064 - accuracy: 0.9740 - val_loss: 1.5171 - val_accuracy: 0.7295\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0968 - accuracy: 0.9800 - val_loss: 1.5245 - val_accuracy: 0.7230\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0804 - accuracy: 0.9840 - val_loss: 1.5282 - val_accuracy: 0.7230\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0919 - accuracy: 0.9880 - val_loss: 1.5203 - val_accuracy: 0.7284\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0748 - accuracy: 0.9920 - val_loss: 1.5029 - val_accuracy: 0.7299\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0727 - accuracy: 0.9900 - val_loss: 1.4878 - val_accuracy: 0.7339\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0478 - accuracy: 0.9940 - val_loss: 1.4815 - val_accuracy: 0.7350\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0366 - accuracy: 0.9960 - val_loss: 1.4778 - val_accuracy: 0.7302\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0467 - accuracy: 0.9900 - val_loss: 1.4720 - val_accuracy: 0.7295\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0333 - accuracy: 0.9940 - val_loss: 1.4675 - val_accuracy: 0.7350\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0257 - accuracy: 0.9940 - val_loss: 1.4656 - val_accuracy: 0.7339\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0398 - accuracy: 0.9980 - val_loss: 1.4664 - val_accuracy: 0.7342\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0281 - accuracy: 0.9980 - val_loss: 1.4682 - val_accuracy: 0.7346\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0320 - accuracy: 0.9920 - val_loss: 1.4709 - val_accuracy: 0.7324\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0267 - accuracy: 0.9980 - val_loss: 1.4760 - val_accuracy: 0.7357\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.4836 - val_accuracy: 0.7368\n",
            "test obs. 500 accuracy 0.7400290065264684\n",
            "test obs. 500 b_accuracy 0.6872781122875673\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 4.9804 - accuracy: 0.0120 - val_loss: 4.3525 - val_accuracy: 0.0018\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 4.4328 - accuracy: 0.0330 - val_loss: 4.1270 - val_accuracy: 0.0736\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 4.0239 - accuracy: 0.0990 - val_loss: 3.8952 - val_accuracy: 0.0968\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 3.6452 - accuracy: 0.1660 - val_loss: 3.6147 - val_accuracy: 0.1751\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 3.2067 - accuracy: 0.2400 - val_loss: 3.3130 - val_accuracy: 0.2342\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 2.7922 - accuracy: 0.3310 - val_loss: 2.8780 - val_accuracy: 0.3706\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 2.1896 - accuracy: 0.4940 - val_loss: 2.4475 - val_accuracy: 0.4808\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.8105 - accuracy: 0.6090 - val_loss: 2.0958 - val_accuracy: 0.5591\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.3660 - accuracy: 0.7060 - val_loss: 1.8056 - val_accuracy: 0.6080\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.1457 - accuracy: 0.7480 - val_loss: 1.5668 - val_accuracy: 0.6592\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.9125 - accuracy: 0.7940 - val_loss: 1.4123 - val_accuracy: 0.6817\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.7023 - accuracy: 0.8420 - val_loss: 1.2862 - val_accuracy: 0.7114\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.5122 - accuracy: 0.8760 - val_loss: 1.1604 - val_accuracy: 0.7418\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.4997 - accuracy: 0.9010 - val_loss: 1.1023 - val_accuracy: 0.7531\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.3485 - accuracy: 0.9260 - val_loss: 1.0726 - val_accuracy: 0.7585\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.2786 - accuracy: 0.9350 - val_loss: 1.0331 - val_accuracy: 0.7625\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.2259 - accuracy: 0.9530 - val_loss: 1.0162 - val_accuracy: 0.7672\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.1639 - accuracy: 0.9650 - val_loss: 0.9657 - val_accuracy: 0.7788\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.1732 - accuracy: 0.9610 - val_loss: 0.9180 - val_accuracy: 0.7948\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.1200 - accuracy: 0.9760 - val_loss: 0.9058 - val_accuracy: 0.7959\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.1258 - accuracy: 0.9720 - val_loss: 0.9062 - val_accuracy: 0.7955\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0898 - accuracy: 0.9830 - val_loss: 0.9133 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.0832 - accuracy: 0.9830 - val_loss: 0.9155 - val_accuracy: 0.7915\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0791 - accuracy: 0.9870 - val_loss: 0.9053 - val_accuracy: 0.7959\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0676 - accuracy: 0.9930 - val_loss: 0.8991 - val_accuracy: 0.8028\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0456 - accuracy: 0.9900 - val_loss: 0.8955 - val_accuracy: 0.8053\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0563 - accuracy: 0.9870 - val_loss: 0.8886 - val_accuracy: 0.8071\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.0426 - accuracy: 0.9930 - val_loss: 0.8928 - val_accuracy: 0.8082\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0545 - accuracy: 0.9890 - val_loss: 0.9057 - val_accuracy: 0.8038\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0512 - accuracy: 0.9930 - val_loss: 0.9202 - val_accuracy: 0.7991\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.0417 - accuracy: 0.9930 - val_loss: 0.9268 - val_accuracy: 0.7951\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0324 - accuracy: 0.9940 - val_loss: 0.9256 - val_accuracy: 0.8028\n",
            "test obs. 1000 accuracy 0.7929659173313995\n",
            "test obs. 1000 b_accuracy 0.7383002125968681\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 4.7785 - accuracy: 0.0210 - val_loss: 4.1580 - val_accuracy: 0.0489\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 4.0595 - accuracy: 0.0685 - val_loss: 3.7903 - val_accuracy: 0.1639\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 3.5883 - accuracy: 0.1890 - val_loss: 3.1348 - val_accuracy: 0.3238\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.9886 - accuracy: 0.3420 - val_loss: 2.3715 - val_accuracy: 0.5268\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 2.3926 - accuracy: 0.4555 - val_loss: 1.8362 - val_accuracy: 0.6352\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.8119 - accuracy: 0.5925 - val_loss: 1.3856 - val_accuracy: 0.7194\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.3627 - accuracy: 0.6945 - val_loss: 1.1065 - val_accuracy: 0.7574\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.0366 - accuracy: 0.7570 - val_loss: 0.9459 - val_accuracy: 0.8046\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.7820 - accuracy: 0.8135 - val_loss: 0.8081 - val_accuracy: 0.8252\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5833 - accuracy: 0.8585 - val_loss: 0.7008 - val_accuracy: 0.8524\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.4865 - accuracy: 0.8920 - val_loss: 0.6407 - val_accuracy: 0.8720\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3850 - accuracy: 0.9225 - val_loss: 0.5978 - val_accuracy: 0.8811\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.3157 - accuracy: 0.9340 - val_loss: 0.5771 - val_accuracy: 0.8803\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.2665 - accuracy: 0.9335 - val_loss: 0.5639 - val_accuracy: 0.8829\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.2714 - accuracy: 0.9550 - val_loss: 0.5491 - val_accuracy: 0.8887\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.2010 - accuracy: 0.9615 - val_loss: 0.5437 - val_accuracy: 0.8905\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1764 - accuracy: 0.9630 - val_loss: 0.5371 - val_accuracy: 0.8851\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1500 - accuracy: 0.9685 - val_loss: 0.5253 - val_accuracy: 0.8923\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1072 - accuracy: 0.9750 - val_loss: 0.5356 - val_accuracy: 0.8930\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1267 - accuracy: 0.9740 - val_loss: 0.5330 - val_accuracy: 0.8872\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0995 - accuracy: 0.9740 - val_loss: 0.5292 - val_accuracy: 0.8901\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0856 - accuracy: 0.9820 - val_loss: 0.5269 - val_accuracy: 0.8963\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0773 - accuracy: 0.9845 - val_loss: 0.5331 - val_accuracy: 0.8956\n",
            "test obs. 2000 accuracy 0.8883248730964467\n",
            "test obs. 2000 b_accuracy 0.8501262281486863\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 1s 49ms/step - loss: 4.3522 - accuracy: 0.0670 - val_loss: 3.5358 - val_accuracy: 0.3299\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 3.1399 - accuracy: 0.3450 - val_loss: 1.8438 - val_accuracy: 0.6439\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 1.9131 - accuracy: 0.5904 - val_loss: 1.0584 - val_accuracy: 0.7730\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 1.1446 - accuracy: 0.7440 - val_loss: 0.6928 - val_accuracy: 0.8528\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.7869 - accuracy: 0.8310 - val_loss: 0.5034 - val_accuracy: 0.8920\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.5667 - accuracy: 0.8894 - val_loss: 0.4267 - val_accuracy: 0.9090\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.4202 - accuracy: 0.9078 - val_loss: 0.4051 - val_accuracy: 0.9104\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.3424 - accuracy: 0.9302 - val_loss: 0.3543 - val_accuracy: 0.9206\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.2588 - accuracy: 0.9518 - val_loss: 0.3554 - val_accuracy: 0.9166\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.2133 - accuracy: 0.9544 - val_loss: 0.3610 - val_accuracy: 0.9228\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.1854 - accuracy: 0.9608 - val_loss: 0.3429 - val_accuracy: 0.9242\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.1606 - accuracy: 0.9654 - val_loss: 0.3609 - val_accuracy: 0.9210\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.1483 - accuracy: 0.9684 - val_loss: 0.3459 - val_accuracy: 0.9195\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.1172 - accuracy: 0.9744 - val_loss: 0.3381 - val_accuracy: 0.9268\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.0984 - accuracy: 0.9792 - val_loss: 0.3386 - val_accuracy: 0.9246\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.0954 - accuracy: 0.9812 - val_loss: 0.3596 - val_accuracy: 0.9217\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.1002 - accuracy: 0.9804 - val_loss: 0.3540 - val_accuracy: 0.9199\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.0837 - accuracy: 0.9790 - val_loss: 0.3566 - val_accuracy: 0.9260\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.0831 - accuracy: 0.9846 - val_loss: 0.3459 - val_accuracy: 0.9253\n",
            "test obs. 5000 accuracy 0.9220449601160261\n",
            "test obs. 5000 b_accuracy 0.8846150546640495\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 2s 41ms/step - loss: 3.8050 - accuracy: 0.1915 - val_loss: 1.8246 - val_accuracy: 0.5990\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 1.7186 - accuracy: 0.6270 - val_loss: 0.6719 - val_accuracy: 0.8510\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.8261 - accuracy: 0.8170 - val_loss: 0.3958 - val_accuracy: 0.9046\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.5375 - accuracy: 0.8857 - val_loss: 0.3072 - val_accuracy: 0.9268\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.3861 - accuracy: 0.9216 - val_loss: 0.2704 - val_accuracy: 0.9405\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.2880 - accuracy: 0.9400 - val_loss: 0.2490 - val_accuracy: 0.9413\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.2073 - accuracy: 0.9525 - val_loss: 0.2638 - val_accuracy: 0.9427\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1627 - accuracy: 0.9617 - val_loss: 0.2404 - val_accuracy: 0.9474\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1495 - accuracy: 0.9648 - val_loss: 0.2429 - val_accuracy: 0.9485\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.1439 - accuracy: 0.9706 - val_loss: 0.2432 - val_accuracy: 0.9471\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.1449 - accuracy: 0.9704 - val_loss: 0.2612 - val_accuracy: 0.9489\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.1190 - accuracy: 0.9753 - val_loss: 0.2578 - val_accuracy: 0.9514\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.0987 - accuracy: 0.9765 - val_loss: 0.2663 - val_accuracy: 0.9489\n",
            "test obs. 10000 accuracy 0.9408992023205222\n",
            "test obs. 10000 b_accuracy 0.9029172456872084\n",
            "Epoch 1/50\n",
            "59/59 [==============================] - 2s 41ms/step - loss: 3.1910 - accuracy: 0.3155 - val_loss: 1.0887 - val_accuracy: 0.7625\n",
            "Epoch 2/50\n",
            "59/59 [==============================] - 2s 36ms/step - loss: 1.0620 - accuracy: 0.7599 - val_loss: 0.4286 - val_accuracy: 0.9090\n",
            "Epoch 3/50\n",
            "59/59 [==============================] - 2s 36ms/step - loss: 0.5647 - accuracy: 0.8780 - val_loss: 0.3060 - val_accuracy: 0.9253\n",
            "Epoch 4/50\n",
            "59/59 [==============================] - 2s 36ms/step - loss: 0.3790 - accuracy: 0.9239 - val_loss: 0.2355 - val_accuracy: 0.9438\n",
            "Epoch 5/50\n",
            "59/59 [==============================] - 2s 37ms/step - loss: 0.2566 - accuracy: 0.9438 - val_loss: 0.2177 - val_accuracy: 0.9489\n",
            "Epoch 6/50\n",
            "59/59 [==============================] - 2s 37ms/step - loss: 0.1966 - accuracy: 0.9547 - val_loss: 0.2055 - val_accuracy: 0.9536\n",
            "Epoch 7/50\n",
            "59/59 [==============================] - 2s 36ms/step - loss: 0.1550 - accuracy: 0.9625 - val_loss: 0.2138 - val_accuracy: 0.9558\n",
            "Epoch 8/50\n",
            "59/59 [==============================] - 2s 36ms/step - loss: 0.1244 - accuracy: 0.9671 - val_loss: 0.2046 - val_accuracy: 0.9540\n",
            "Epoch 9/50\n",
            "59/59 [==============================] - 2s 36ms/step - loss: 0.1207 - accuracy: 0.9719 - val_loss: 0.2155 - val_accuracy: 0.9550\n",
            "Epoch 10/50\n",
            "59/59 [==============================] - 2s 35ms/step - loss: 0.1068 - accuracy: 0.9741 - val_loss: 0.2203 - val_accuracy: 0.9547\n",
            "Epoch 11/50\n",
            "59/59 [==============================] - 2s 35ms/step - loss: 0.0935 - accuracy: 0.9768 - val_loss: 0.2269 - val_accuracy: 0.9572\n",
            "Epoch 12/50\n",
            "59/59 [==============================] - 2s 35ms/step - loss: 0.0894 - accuracy: 0.9785 - val_loss: 0.2216 - val_accuracy: 0.9572\n",
            "Epoch 13/50\n",
            "59/59 [==============================] - 2s 36ms/step - loss: 0.0906 - accuracy: 0.9776 - val_loss: 0.2387 - val_accuracy: 0.9569\n",
            "test obs. 15000 accuracy 0.9550398839738942\n",
            "test obs. 15000 b_accuracy 0.9225721425254979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-1K5rtvmvcg",
        "colab_type": "text"
      },
      "source": [
        "## CNN2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "893RDiv5mqOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4a9a5ff-ae72-4bfe-fec0-942dbe69ca6d"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000,10000,15000]:\n",
        "     run_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs,True,True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 5.1965 - accuracy: 0.0100 - val_loss: 4.3668 - val_accuracy: 0.0149\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 4.5441 - accuracy: 0.0000e+00 - val_loss: 4.3358 - val_accuracy: 0.0152\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4.1823 - accuracy: 0.0200 - val_loss: 4.3918 - val_accuracy: 0.0145\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 3.9297 - accuracy: 0.0400 - val_loss: 4.4257 - val_accuracy: 0.0152\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 3.6947 - accuracy: 0.0900 - val_loss: 4.4304 - val_accuracy: 0.0218\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.5605 - accuracy: 0.1000 - val_loss: 4.4294 - val_accuracy: 0.0207\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 3.1791 - accuracy: 0.1600 - val_loss: 4.4281 - val_accuracy: 0.0199\n",
            "test obs. 100 accuracy 0.013415518491660623\n",
            "test obs. 100 b_accuracy 0.24493091194286123\n",
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 4.7410 - accuracy: 0.0120 - val_loss: 4.4361 - val_accuracy: 0.0040\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.6600 - accuracy: 0.0160 - val_loss: 4.3989 - val_accuracy: 0.0025\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 4.4057 - accuracy: 0.0240 - val_loss: 4.2890 - val_accuracy: 0.0025\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 4.2504 - accuracy: 0.0200 - val_loss: 4.2563 - val_accuracy: 0.0054\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.9106 - accuracy: 0.0640 - val_loss: 4.2634 - val_accuracy: 0.0424\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 3.8117 - accuracy: 0.1040 - val_loss: 4.2736 - val_accuracy: 0.0489\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.7082 - accuracy: 0.0880 - val_loss: 4.2971 - val_accuracy: 0.0471\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.6193 - accuracy: 0.0880 - val_loss: 4.2937 - val_accuracy: 0.0424\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 3.4423 - accuracy: 0.1120 - val_loss: 4.2605 - val_accuracy: 0.0450\n",
            "test obs. 250 accuracy 0.046047860768672955\n",
            "test obs. 250 b_accuracy 0.5181140617849379\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 5.0784 - accuracy: 0.0160 - val_loss: 4.3655 - val_accuracy: 0.0011\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 4.6861 - accuracy: 0.0160 - val_loss: 4.2886 - val_accuracy: 0.0011\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 4.4968 - accuracy: 0.0260 - val_loss: 4.2207 - val_accuracy: 0.0156\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 4.2878 - accuracy: 0.0700 - val_loss: 4.1580 - val_accuracy: 0.0355\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 4.0977 - accuracy: 0.1020 - val_loss: 4.1118 - val_accuracy: 0.0228\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 3.9100 - accuracy: 0.0920 - val_loss: 4.0387 - val_accuracy: 0.0363\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 3.6666 - accuracy: 0.1320 - val_loss: 3.9293 - val_accuracy: 0.0892\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 3.3686 - accuracy: 0.1900 - val_loss: 3.7827 - val_accuracy: 0.1686\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 3.1545 - accuracy: 0.2660 - val_loss: 3.6292 - val_accuracy: 0.2411\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.8683 - accuracy: 0.3600 - val_loss: 3.4778 - val_accuracy: 0.2872\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.5889 - accuracy: 0.4380 - val_loss: 3.3057 - val_accuracy: 0.3176\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 2.3088 - accuracy: 0.4780 - val_loss: 3.0990 - val_accuracy: 0.3666\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 2.1079 - accuracy: 0.5500 - val_loss: 2.8920 - val_accuracy: 0.4260\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 1.8708 - accuracy: 0.5820 - val_loss: 2.6658 - val_accuracy: 0.4819\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.6417 - accuracy: 0.6420 - val_loss: 2.4520 - val_accuracy: 0.5315\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.3625 - accuracy: 0.7080 - val_loss: 2.2529 - val_accuracy: 0.5794\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1.2323 - accuracy: 0.7540 - val_loss: 2.0835 - val_accuracy: 0.6178\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.1054 - accuracy: 0.7960 - val_loss: 1.9492 - val_accuracy: 0.6302\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.9270 - accuracy: 0.7940 - val_loss: 1.8304 - val_accuracy: 0.6381\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.8115 - accuracy: 0.8420 - val_loss: 1.7258 - val_accuracy: 0.6555\n",
            "Epoch 21/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.7049 - accuracy: 0.8580 - val_loss: 1.6477 - val_accuracy: 0.6574\n",
            "Epoch 22/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5538 - accuracy: 0.8760 - val_loss: 1.5809 - val_accuracy: 0.6701\n",
            "Epoch 23/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4507 - accuracy: 0.8920 - val_loss: 1.5235 - val_accuracy: 0.6817\n",
            "Epoch 24/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4685 - accuracy: 0.9120 - val_loss: 1.4784 - val_accuracy: 0.6943\n",
            "Epoch 25/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4253 - accuracy: 0.9080 - val_loss: 1.4430 - val_accuracy: 0.6962\n",
            "Epoch 26/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.3631 - accuracy: 0.9120 - val_loss: 1.4200 - val_accuracy: 0.7059\n",
            "Epoch 27/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.3652 - accuracy: 0.9140 - val_loss: 1.4051 - val_accuracy: 0.7067\n",
            "Epoch 28/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2300 - accuracy: 0.9280 - val_loss: 1.3922 - val_accuracy: 0.7114\n",
            "Epoch 29/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1670 - accuracy: 0.9540 - val_loss: 1.3806 - val_accuracy: 0.7234\n",
            "Epoch 30/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2757 - accuracy: 0.9320 - val_loss: 1.3723 - val_accuracy: 0.7331\n",
            "Epoch 31/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2475 - accuracy: 0.9320 - val_loss: 1.3661 - val_accuracy: 0.7368\n",
            "Epoch 32/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1792 - accuracy: 0.9660 - val_loss: 1.3597 - val_accuracy: 0.7375\n",
            "Epoch 33/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1445 - accuracy: 0.9700 - val_loss: 1.3531 - val_accuracy: 0.7433\n",
            "Epoch 34/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.1531 - accuracy: 0.9700 - val_loss: 1.3501 - val_accuracy: 0.7426\n",
            "Epoch 35/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.1429 - accuracy: 0.9680 - val_loss: 1.3472 - val_accuracy: 0.7491\n",
            "Epoch 36/150\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.1519 - accuracy: 0.9660 - val_loss: 1.3431 - val_accuracy: 0.7491\n",
            "Epoch 37/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1064 - accuracy: 0.9780 - val_loss: 1.3411 - val_accuracy: 0.7502\n",
            "Epoch 38/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1053 - accuracy: 0.9680 - val_loss: 1.3351 - val_accuracy: 0.7520\n",
            "Epoch 39/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1068 - accuracy: 0.9760 - val_loss: 1.3316 - val_accuracy: 0.7542\n",
            "Epoch 40/150\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0944 - accuracy: 0.9700 - val_loss: 1.3294 - val_accuracy: 0.7560\n",
            "Epoch 41/150\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1222 - accuracy: 0.9800 - val_loss: 1.3318 - val_accuracy: 0.7553\n",
            "Epoch 42/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0795 - accuracy: 0.9760 - val_loss: 1.3342 - val_accuracy: 0.7563\n",
            "Epoch 43/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.1140 - accuracy: 0.9720 - val_loss: 1.3371 - val_accuracy: 0.7556\n",
            "Epoch 44/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0746 - accuracy: 0.9900 - val_loss: 1.3428 - val_accuracy: 0.7534\n",
            "Epoch 45/150\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0939 - accuracy: 0.9780 - val_loss: 1.3505 - val_accuracy: 0.7513\n",
            "test obs. 500 accuracy 0.7498187092095722\n",
            "test obs. 500 b_accuracy 0.6827268502227134\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 4.6426 - accuracy: 0.0090 - val_loss: 4.2313 - val_accuracy: 0.0747\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 4.2003 - accuracy: 0.0490 - val_loss: 4.1243 - val_accuracy: 0.0511\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 3.9848 - accuracy: 0.1040 - val_loss: 3.9363 - val_accuracy: 0.1624\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 3.7339 - accuracy: 0.1770 - val_loss: 3.7437 - val_accuracy: 0.2034\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 3.2962 - accuracy: 0.2590 - val_loss: 3.4241 - val_accuracy: 0.3521\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.9128 - accuracy: 0.3680 - val_loss: 3.0603 - val_accuracy: 0.4467\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 2.4717 - accuracy: 0.4670 - val_loss: 2.6297 - val_accuracy: 0.5413\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.1163 - accuracy: 0.5860 - val_loss: 2.2006 - val_accuracy: 0.6251\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1.5851 - accuracy: 0.6720 - val_loss: 1.8317 - val_accuracy: 0.6784\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1.2631 - accuracy: 0.7500 - val_loss: 1.5632 - val_accuracy: 0.7092\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.9411 - accuracy: 0.7740 - val_loss: 1.3344 - val_accuracy: 0.7458\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.8008 - accuracy: 0.8170 - val_loss: 1.1904 - val_accuracy: 0.7708\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.7109 - accuracy: 0.8580 - val_loss: 1.1132 - val_accuracy: 0.7716\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.5601 - accuracy: 0.8630 - val_loss: 1.0492 - val_accuracy: 0.7839\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.4828 - accuracy: 0.8890 - val_loss: 1.0034 - val_accuracy: 0.7948\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.3855 - accuracy: 0.9130 - val_loss: 0.9700 - val_accuracy: 0.7999\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3423 - accuracy: 0.9270 - val_loss: 0.9455 - val_accuracy: 0.8089\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.2995 - accuracy: 0.9200 - val_loss: 0.9346 - val_accuracy: 0.8151\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.2665 - accuracy: 0.9270 - val_loss: 0.9104 - val_accuracy: 0.8245\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.2245 - accuracy: 0.9460 - val_loss: 0.8903 - val_accuracy: 0.8263\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.1830 - accuracy: 0.9530 - val_loss: 0.8776 - val_accuracy: 0.8249\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.1690 - accuracy: 0.9600 - val_loss: 0.8720 - val_accuracy: 0.8289\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.1516 - accuracy: 0.9660 - val_loss: 0.8651 - val_accuracy: 0.8358\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.1301 - accuracy: 0.9660 - val_loss: 0.8638 - val_accuracy: 0.8361\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.1383 - accuracy: 0.9740 - val_loss: 0.8746 - val_accuracy: 0.8372\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.1182 - accuracy: 0.9720 - val_loss: 0.8828 - val_accuracy: 0.8401\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.1182 - accuracy: 0.9710 - val_loss: 0.8839 - val_accuracy: 0.8408\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.1394 - accuracy: 0.9740 - val_loss: 0.8831 - val_accuracy: 0.8397\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.1072 - accuracy: 0.9770 - val_loss: 0.8800 - val_accuracy: 0.8423\n",
            "test obs. 1000 accuracy 0.8448150833937635\n",
            "test obs. 1000 b_accuracy 0.7566430972869265\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 4.4101 - accuracy: 0.0305 - val_loss: 4.0611 - val_accuracy: 0.1835\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 3.9361 - accuracy: 0.1855 - val_loss: 3.5322 - val_accuracy: 0.3655\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 3.3432 - accuracy: 0.3445 - val_loss: 2.7562 - val_accuracy: 0.5678\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.6406 - accuracy: 0.5040 - val_loss: 1.9528 - val_accuracy: 0.7201\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.8846 - accuracy: 0.6310 - val_loss: 1.2882 - val_accuracy: 0.7781\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3336 - accuracy: 0.7250 - val_loss: 0.9200 - val_accuracy: 0.8234\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.9998 - accuracy: 0.8015 - val_loss: 0.7384 - val_accuracy: 0.8495\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.7185 - accuracy: 0.8465 - val_loss: 0.6320 - val_accuracy: 0.8640\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.5607 - accuracy: 0.8825 - val_loss: 0.5895 - val_accuracy: 0.8673\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.5057 - accuracy: 0.8855 - val_loss: 0.5490 - val_accuracy: 0.8767\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3584 - accuracy: 0.9145 - val_loss: 0.5158 - val_accuracy: 0.8782\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3337 - accuracy: 0.9335 - val_loss: 0.4974 - val_accuracy: 0.8840\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.2339 - accuracy: 0.9430 - val_loss: 0.4909 - val_accuracy: 0.8872\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2317 - accuracy: 0.9495 - val_loss: 0.4746 - val_accuracy: 0.8894\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2208 - accuracy: 0.9375 - val_loss: 0.4830 - val_accuracy: 0.8840\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2168 - accuracy: 0.9500 - val_loss: 0.4752 - val_accuracy: 0.8883\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2055 - accuracy: 0.9660 - val_loss: 0.4707 - val_accuracy: 0.8876\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1523 - accuracy: 0.9620 - val_loss: 0.4592 - val_accuracy: 0.8941\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1428 - accuracy: 0.9665 - val_loss: 0.4538 - val_accuracy: 0.8949\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1064 - accuracy: 0.9755 - val_loss: 0.4625 - val_accuracy: 0.8916\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1228 - accuracy: 0.9715 - val_loss: 0.4760 - val_accuracy: 0.8905\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1213 - accuracy: 0.9720 - val_loss: 0.4763 - val_accuracy: 0.8912\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0939 - accuracy: 0.9740 - val_loss: 0.4703 - val_accuracy: 0.8934\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1038 - accuracy: 0.9775 - val_loss: 0.4730 - val_accuracy: 0.8923\n",
            "test obs. 2000 accuracy 0.8984771573604061\n",
            "test obs. 2000 b_accuracy 0.8483096250907629\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 1s 47ms/step - loss: 4.2303 - accuracy: 0.1130 - val_loss: 3.4288 - val_accuracy: 0.4815\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 3.0080 - accuracy: 0.4702 - val_loss: 1.5733 - val_accuracy: 0.7683\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 1.7414 - accuracy: 0.6790 - val_loss: 0.7531 - val_accuracy: 0.8615\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.9962 - accuracy: 0.8004 - val_loss: 0.5080 - val_accuracy: 0.8927\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.7316 - accuracy: 0.8566 - val_loss: 0.4394 - val_accuracy: 0.9068\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.4816 - accuracy: 0.9048 - val_loss: 0.3781 - val_accuracy: 0.9195\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 0.3520 - accuracy: 0.9252 - val_loss: 0.3482 - val_accuracy: 0.9213\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.2974 - accuracy: 0.9366 - val_loss: 0.3553 - val_accuracy: 0.9177\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.2391 - accuracy: 0.9466 - val_loss: 0.3283 - val_accuracy: 0.9293\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.2194 - accuracy: 0.9558 - val_loss: 0.3210 - val_accuracy: 0.9264\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 0.1697 - accuracy: 0.9584 - val_loss: 0.3314 - val_accuracy: 0.9260\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1634 - accuracy: 0.9666 - val_loss: 0.3252 - val_accuracy: 0.9304\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.2005 - accuracy: 0.9628 - val_loss: 0.3266 - val_accuracy: 0.9318\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.1136 - accuracy: 0.9696 - val_loss: 0.3452 - val_accuracy: 0.9322\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.1024 - accuracy: 0.9756 - val_loss: 0.3433 - val_accuracy: 0.9322\n",
            "test obs. 5000 accuracy 0.9336475707034083\n",
            "test obs. 5000 b_accuracy 0.8733421005790856\n",
            "Epoch 1/150\n",
            "40/40 [==============================] - 2s 39ms/step - loss: 3.5767 - accuracy: 0.2778 - val_loss: 1.4556 - val_accuracy: 0.8009\n",
            "Epoch 2/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.3946 - accuracy: 0.7328 - val_loss: 0.4970 - val_accuracy: 0.8959\n",
            "Epoch 3/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.6993 - accuracy: 0.8621 - val_loss: 0.3198 - val_accuracy: 0.9253\n",
            "Epoch 4/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.4252 - accuracy: 0.9053 - val_loss: 0.2814 - val_accuracy: 0.9387\n",
            "Epoch 5/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3134 - accuracy: 0.9323 - val_loss: 0.2593 - val_accuracy: 0.9420\n",
            "Epoch 6/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2568 - accuracy: 0.9447 - val_loss: 0.2744 - val_accuracy: 0.9351\n",
            "Epoch 7/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2083 - accuracy: 0.9548 - val_loss: 0.2667 - val_accuracy: 0.9398\n",
            "Epoch 8/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1715 - accuracy: 0.9617 - val_loss: 0.2784 - val_accuracy: 0.9402\n",
            "Epoch 9/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1495 - accuracy: 0.9668 - val_loss: 0.2851 - val_accuracy: 0.9420\n",
            "Epoch 10/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1609 - accuracy: 0.9640 - val_loss: 0.2739 - val_accuracy: 0.9460\n",
            "test obs. 10000 accuracy 0.9448875997099347\n",
            "test obs. 10000 b_accuracy 0.8931225952073879\n",
            "Epoch 1/150\n",
            "59/59 [==============================] - 2s 37ms/step - loss: 2.9669 - accuracy: 0.4103 - val_loss: 0.7243 - val_accuracy: 0.8597\n",
            "Epoch 2/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.8918 - accuracy: 0.8203 - val_loss: 0.3584 - val_accuracy: 0.9137\n",
            "Epoch 3/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.5112 - accuracy: 0.8987 - val_loss: 0.2618 - val_accuracy: 0.9362\n",
            "Epoch 4/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.3478 - accuracy: 0.9277 - val_loss: 0.2306 - val_accuracy: 0.9384\n",
            "Epoch 5/150\n",
            "59/59 [==============================] - 2s 33ms/step - loss: 0.2409 - accuracy: 0.9457 - val_loss: 0.2163 - val_accuracy: 0.9453\n",
            "Epoch 6/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.2004 - accuracy: 0.9515 - val_loss: 0.2303 - val_accuracy: 0.9496\n",
            "Epoch 7/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.1652 - accuracy: 0.9621 - val_loss: 0.2182 - val_accuracy: 0.9492\n",
            "Epoch 8/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.2049 - accuracy: 0.9587 - val_loss: 0.2139 - val_accuracy: 0.9511\n",
            "Epoch 9/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.1315 - accuracy: 0.9677 - val_loss: 0.2272 - val_accuracy: 0.9496\n",
            "Epoch 10/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.1097 - accuracy: 0.9716 - val_loss: 0.2356 - val_accuracy: 0.9500\n",
            "Epoch 11/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.0962 - accuracy: 0.9728 - val_loss: 0.2288 - val_accuracy: 0.9569\n",
            "Epoch 12/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.0966 - accuracy: 0.9746 - val_loss: 0.2338 - val_accuracy: 0.9536\n",
            "Epoch 13/150\n",
            "59/59 [==============================] - 2s 33ms/step - loss: 0.0873 - accuracy: 0.9765 - val_loss: 0.2401 - val_accuracy: 0.9554\n",
            "test obs. 15000 accuracy 0.9557650471356055\n",
            "test obs. 15000 b_accuracy 0.900593083730014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2z_NR3QJILQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8d47f96-6235-4d29-d765-0daa23ac9b98"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000,10000,15000]:\n",
        "     run_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs,False,True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 4.3941 - accuracy: 0.0100 - val_loss: 4.3033 - val_accuracy: 0.0109\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.3091 - accuracy: 0.0400 - val_loss: 4.3026 - val_accuracy: 0.0257\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 4.2668 - accuracy: 0.0300 - val_loss: 4.3072 - val_accuracy: 0.0250\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.1862 - accuracy: 0.0400 - val_loss: 4.3129 - val_accuracy: 0.0185\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 4.1843 - accuracy: 0.0300 - val_loss: 4.3255 - val_accuracy: 0.0257\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 4.0862 - accuracy: 0.0500 - val_loss: 4.3470 - val_accuracy: 0.0247\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 3.9386 - accuracy: 0.0600 - val_loss: 4.3839 - val_accuracy: 0.0160\n",
            "test obs. 100 accuracy 0.013778100072516316\n",
            "test obs. 100 b_accuracy 0.10275751354298725\n",
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 4.4793 - accuracy: 0.0120 - val_loss: 4.2897 - val_accuracy: 0.0087\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.4296 - accuracy: 0.0240 - val_loss: 4.2938 - val_accuracy: 0.0047\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 4.4356 - accuracy: 0.0120 - val_loss: 4.2967 - val_accuracy: 0.0040\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 4.3674 - accuracy: 0.0200 - val_loss: 4.3029 - val_accuracy: 0.0047\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.2945 - accuracy: 0.0080 - val_loss: 4.3130 - val_accuracy: 0.0065\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 4.2167 - accuracy: 0.0360 - val_loss: 4.3312 - val_accuracy: 0.0112\n",
            "test obs. 250 accuracy 0.010877447425670777\n",
            "test obs. 250 b_accuracy 0.10357203969646607\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 4.7067 - accuracy: 0.0180 - val_loss: 4.3129 - val_accuracy: 0.0120\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 4.6606 - accuracy: 0.0140 - val_loss: 4.2979 - val_accuracy: 0.0033\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 4.6087 - accuracy: 0.0140 - val_loss: 4.2824 - val_accuracy: 0.0040\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 4.5217 - accuracy: 0.0220 - val_loss: 4.2718 - val_accuracy: 0.0025\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 4.4240 - accuracy: 0.0200 - val_loss: 4.2678 - val_accuracy: 0.0080\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 4.3690 - accuracy: 0.0440 - val_loss: 4.2736 - val_accuracy: 0.0080\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 4.3319 - accuracy: 0.0400 - val_loss: 4.2621 - val_accuracy: 0.0170\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 4.2272 - accuracy: 0.0360 - val_loss: 4.2275 - val_accuracy: 0.0428\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 4.1356 - accuracy: 0.0660 - val_loss: 4.1679 - val_accuracy: 0.0464\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 3.9767 - accuracy: 0.0620 - val_loss: 4.0868 - val_accuracy: 0.0558\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 3.8395 - accuracy: 0.0900 - val_loss: 4.0097 - val_accuracy: 0.0533\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 3.6605 - accuracy: 0.1060 - val_loss: 3.9303 - val_accuracy: 0.0547\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 3.5333 - accuracy: 0.1360 - val_loss: 3.8494 - val_accuracy: 0.0819\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 3.3610 - accuracy: 0.1460 - val_loss: 3.7564 - val_accuracy: 0.1102\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 3.2385 - accuracy: 0.1740 - val_loss: 3.6584 - val_accuracy: 0.1483\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 3.1218 - accuracy: 0.2300 - val_loss: 3.5503 - val_accuracy: 0.1835\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.9863 - accuracy: 0.2780 - val_loss: 3.4369 - val_accuracy: 0.2266\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 2.7908 - accuracy: 0.3320 - val_loss: 3.3157 - val_accuracy: 0.2694\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 2.6827 - accuracy: 0.3760 - val_loss: 3.1858 - val_accuracy: 0.2944\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 2.4739 - accuracy: 0.4180 - val_loss: 3.0578 - val_accuracy: 0.3096\n",
            "Epoch 21/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 2.3391 - accuracy: 0.4300 - val_loss: 2.9351 - val_accuracy: 0.3437\n",
            "Epoch 22/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 2.2196 - accuracy: 0.4580 - val_loss: 2.8083 - val_accuracy: 0.3771\n",
            "Epoch 23/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 2.0743 - accuracy: 0.5100 - val_loss: 2.6821 - val_accuracy: 0.4191\n",
            "Epoch 24/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1.9432 - accuracy: 0.5700 - val_loss: 2.5632 - val_accuracy: 0.4583\n",
            "Epoch 25/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1.8779 - accuracy: 0.5700 - val_loss: 2.4580 - val_accuracy: 0.4953\n",
            "Epoch 26/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1.6557 - accuracy: 0.6180 - val_loss: 2.3548 - val_accuracy: 0.5218\n",
            "Epoch 27/150\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.5074 - accuracy: 0.6800 - val_loss: 2.2534 - val_accuracy: 0.5392\n",
            "Epoch 28/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.3596 - accuracy: 0.7000 - val_loss: 2.1554 - val_accuracy: 0.5584\n",
            "Epoch 29/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1.3022 - accuracy: 0.6940 - val_loss: 2.0637 - val_accuracy: 0.5783\n",
            "Epoch 30/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 1.2724 - accuracy: 0.6960 - val_loss: 1.9862 - val_accuracy: 0.5823\n",
            "Epoch 31/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.1956 - accuracy: 0.7240 - val_loss: 1.9182 - val_accuracy: 0.5932\n",
            "Epoch 32/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.0374 - accuracy: 0.7980 - val_loss: 1.8620 - val_accuracy: 0.6077\n",
            "Epoch 33/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1.0054 - accuracy: 0.7980 - val_loss: 1.8089 - val_accuracy: 0.6171\n",
            "Epoch 34/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.9211 - accuracy: 0.7920 - val_loss: 1.7589 - val_accuracy: 0.6309\n",
            "Epoch 35/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.8650 - accuracy: 0.8300 - val_loss: 1.7186 - val_accuracy: 0.6360\n",
            "Epoch 36/150\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.7851 - accuracy: 0.8300 - val_loss: 1.6803 - val_accuracy: 0.6476\n",
            "Epoch 37/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.7781 - accuracy: 0.8220 - val_loss: 1.6449 - val_accuracy: 0.6552\n",
            "Epoch 38/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6814 - accuracy: 0.8500 - val_loss: 1.6132 - val_accuracy: 0.6650\n",
            "Epoch 39/150\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.6858 - accuracy: 0.8360 - val_loss: 1.5824 - val_accuracy: 0.6679\n",
            "Epoch 40/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6564 - accuracy: 0.8680 - val_loss: 1.5569 - val_accuracy: 0.6704\n",
            "Epoch 41/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5996 - accuracy: 0.8660 - val_loss: 1.5388 - val_accuracy: 0.6748\n",
            "Epoch 42/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6051 - accuracy: 0.8620 - val_loss: 1.5261 - val_accuracy: 0.6846\n",
            "Epoch 43/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4916 - accuracy: 0.8800 - val_loss: 1.5119 - val_accuracy: 0.6853\n",
            "Epoch 44/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4815 - accuracy: 0.8760 - val_loss: 1.4928 - val_accuracy: 0.6904\n",
            "Epoch 45/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4821 - accuracy: 0.8920 - val_loss: 1.4689 - val_accuracy: 0.7016\n",
            "Epoch 46/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4418 - accuracy: 0.8840 - val_loss: 1.4507 - val_accuracy: 0.7107\n",
            "Epoch 47/150\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.3970 - accuracy: 0.9080 - val_loss: 1.4401 - val_accuracy: 0.7201\n",
            "Epoch 48/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.3733 - accuracy: 0.9160 - val_loss: 1.4278 - val_accuracy: 0.7230\n",
            "Epoch 49/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.3287 - accuracy: 0.9180 - val_loss: 1.4144 - val_accuracy: 0.7270\n",
            "Epoch 50/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.3353 - accuracy: 0.9320 - val_loss: 1.4087 - val_accuracy: 0.7270\n",
            "Epoch 51/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.3037 - accuracy: 0.9280 - val_loss: 1.4009 - val_accuracy: 0.7310\n",
            "Epoch 52/150\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.2875 - accuracy: 0.9540 - val_loss: 1.3930 - val_accuracy: 0.7342\n",
            "Epoch 53/150\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2683 - accuracy: 0.9420 - val_loss: 1.3837 - val_accuracy: 0.7393\n",
            "Epoch 54/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2762 - accuracy: 0.9300 - val_loss: 1.3753 - val_accuracy: 0.7415\n",
            "Epoch 55/150\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.2130 - accuracy: 0.9560 - val_loss: 1.3720 - val_accuracy: 0.7364\n",
            "Epoch 56/150\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2008 - accuracy: 0.9560 - val_loss: 1.3747 - val_accuracy: 0.7397\n",
            "Epoch 57/150\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2015 - accuracy: 0.9640 - val_loss: 1.3774 - val_accuracy: 0.7397\n",
            "Epoch 58/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2552 - accuracy: 0.9400 - val_loss: 1.3813 - val_accuracy: 0.7382\n",
            "Epoch 59/150\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.1925 - accuracy: 0.9620 - val_loss: 1.3857 - val_accuracy: 0.7386\n",
            "Epoch 60/150\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2040 - accuracy: 0.9660 - val_loss: 1.3885 - val_accuracy: 0.7386\n",
            "test obs. 500 accuracy 0.7407541696881799\n",
            "test obs. 500 b_accuracy 0.677346585909181\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 4.3612 - accuracy: 0.0080 - val_loss: 4.2939 - val_accuracy: 0.0022\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 4.3042 - accuracy: 0.0140 - val_loss: 4.2534 - val_accuracy: 0.0018\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 4.2246 - accuracy: 0.0260 - val_loss: 4.1950 - val_accuracy: 0.0116\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 4.1409 - accuracy: 0.0520 - val_loss: 4.1028 - val_accuracy: 0.0638\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 4.0088 - accuracy: 0.0930 - val_loss: 3.9689 - val_accuracy: 0.0754\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 3.8175 - accuracy: 0.1240 - val_loss: 3.8038 - val_accuracy: 0.1178\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 3.6628 - accuracy: 0.1310 - val_loss: 3.6336 - val_accuracy: 0.1273\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 3.4159 - accuracy: 0.1910 - val_loss: 3.4481 - val_accuracy: 0.1904\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 3.1492 - accuracy: 0.2600 - val_loss: 3.2191 - val_accuracy: 0.2973\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 2.8823 - accuracy: 0.3270 - val_loss: 2.9876 - val_accuracy: 0.3702\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 2.5710 - accuracy: 0.3970 - val_loss: 2.7345 - val_accuracy: 0.4423\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.3038 - accuracy: 0.4630 - val_loss: 2.4550 - val_accuracy: 0.4989\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 2.0314 - accuracy: 0.5470 - val_loss: 2.1970 - val_accuracy: 0.5595\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.7954 - accuracy: 0.5940 - val_loss: 1.9851 - val_accuracy: 0.5914\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.5643 - accuracy: 0.6430 - val_loss: 1.7947 - val_accuracy: 0.6273\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.4235 - accuracy: 0.6920 - val_loss: 1.6123 - val_accuracy: 0.6726\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.1964 - accuracy: 0.7290 - val_loss: 1.4656 - val_accuracy: 0.7092\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 1.1463 - accuracy: 0.7730 - val_loss: 1.3595 - val_accuracy: 0.7277\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.9125 - accuracy: 0.8120 - val_loss: 1.2792 - val_accuracy: 0.7328\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.8055 - accuracy: 0.8330 - val_loss: 1.1957 - val_accuracy: 0.7455\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.7224 - accuracy: 0.8380 - val_loss: 1.1365 - val_accuracy: 0.7524\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.6621 - accuracy: 0.8650 - val_loss: 1.0889 - val_accuracy: 0.7585\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.5679 - accuracy: 0.8710 - val_loss: 1.0472 - val_accuracy: 0.7741\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.5308 - accuracy: 0.8740 - val_loss: 1.0203 - val_accuracy: 0.7901\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.5363 - accuracy: 0.9080 - val_loss: 0.9901 - val_accuracy: 0.7941\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.4151 - accuracy: 0.9150 - val_loss: 0.9695 - val_accuracy: 0.7861\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.3944 - accuracy: 0.9220 - val_loss: 0.9484 - val_accuracy: 0.7991\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.3464 - accuracy: 0.9320 - val_loss: 0.9356 - val_accuracy: 0.7995\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.3185 - accuracy: 0.9370 - val_loss: 0.9282 - val_accuracy: 0.8028\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.3113 - accuracy: 0.9330 - val_loss: 0.9185 - val_accuracy: 0.8129\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.2635 - accuracy: 0.9410 - val_loss: 0.9123 - val_accuracy: 0.8158\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.2397 - accuracy: 0.9540 - val_loss: 0.9044 - val_accuracy: 0.8180\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.2254 - accuracy: 0.9590 - val_loss: 0.8990 - val_accuracy: 0.8191\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.2160 - accuracy: 0.9530 - val_loss: 0.8940 - val_accuracy: 0.8227\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.2101 - accuracy: 0.9590 - val_loss: 0.8869 - val_accuracy: 0.8234\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.1898 - accuracy: 0.9610 - val_loss: 0.8773 - val_accuracy: 0.8256\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.1568 - accuracy: 0.9580 - val_loss: 0.8696 - val_accuracy: 0.8292\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.1678 - accuracy: 0.9640 - val_loss: 0.8677 - val_accuracy: 0.8299\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.1463 - accuracy: 0.9710 - val_loss: 0.8712 - val_accuracy: 0.8314\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.1720 - accuracy: 0.9730 - val_loss: 0.8769 - val_accuracy: 0.8303\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.1561 - accuracy: 0.9700 - val_loss: 0.8827 - val_accuracy: 0.8292\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.1439 - accuracy: 0.9710 - val_loss: 0.8834 - val_accuracy: 0.8321\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.1665 - accuracy: 0.9590 - val_loss: 0.8798 - val_accuracy: 0.8318\n",
            "test obs. 1000 accuracy 0.8292240754169689\n",
            "test obs. 1000 b_accuracy 0.7364286226124771\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 4.3428 - accuracy: 0.0150 - val_loss: 4.2328 - val_accuracy: 0.0431\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.2314 - accuracy: 0.0525 - val_loss: 4.0589 - val_accuracy: 0.0968\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 4.0459 - accuracy: 0.1260 - val_loss: 3.7748 - val_accuracy: 0.2016\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 3.7789 - accuracy: 0.1700 - val_loss: 3.4780 - val_accuracy: 0.2487\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.3543 - accuracy: 0.2445 - val_loss: 3.0141 - val_accuracy: 0.3546\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.8686 - accuracy: 0.3630 - val_loss: 2.4964 - val_accuracy: 0.5341\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.3703 - accuracy: 0.4910 - val_loss: 2.0058 - val_accuracy: 0.6240\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.9159 - accuracy: 0.5880 - val_loss: 1.6027 - val_accuracy: 0.6838\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.5262 - accuracy: 0.6560 - val_loss: 1.2914 - val_accuracy: 0.7219\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.2141 - accuracy: 0.7260 - val_loss: 1.0684 - val_accuracy: 0.7759\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.0313 - accuracy: 0.7785 - val_loss: 0.9363 - val_accuracy: 0.7951\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.8060 - accuracy: 0.8245 - val_loss: 0.8238 - val_accuracy: 0.8176\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6639 - accuracy: 0.8555 - val_loss: 0.7206 - val_accuracy: 0.8441\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.5603 - accuracy: 0.8795 - val_loss: 0.6646 - val_accuracy: 0.8528\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.4523 - accuracy: 0.9055 - val_loss: 0.6148 - val_accuracy: 0.8644\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3713 - accuracy: 0.9115 - val_loss: 0.5862 - val_accuracy: 0.8731\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3466 - accuracy: 0.9260 - val_loss: 0.5576 - val_accuracy: 0.8760\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3014 - accuracy: 0.9385 - val_loss: 0.5456 - val_accuracy: 0.8822\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2686 - accuracy: 0.9345 - val_loss: 0.5224 - val_accuracy: 0.8825\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2255 - accuracy: 0.9605 - val_loss: 0.5059 - val_accuracy: 0.8865\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2115 - accuracy: 0.9580 - val_loss: 0.4995 - val_accuracy: 0.8952\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1973 - accuracy: 0.9635 - val_loss: 0.5025 - val_accuracy: 0.8909\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1753 - accuracy: 0.9570 - val_loss: 0.5008 - val_accuracy: 0.8876\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1734 - accuracy: 0.9685 - val_loss: 0.4957 - val_accuracy: 0.8880\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1488 - accuracy: 0.9710 - val_loss: 0.4909 - val_accuracy: 0.8912\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1451 - accuracy: 0.9740 - val_loss: 0.4847 - val_accuracy: 0.8952\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.1392 - accuracy: 0.9700 - val_loss: 0.4874 - val_accuracy: 0.8956\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.1318 - accuracy: 0.9755 - val_loss: 0.4883 - val_accuracy: 0.8927\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1162 - accuracy: 0.9750 - val_loss: 0.4904 - val_accuracy: 0.8988\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - accuracy: 0.9740 - val_loss: 0.4896 - val_accuracy: 0.9003\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1131 - accuracy: 0.9765 - val_loss: 0.4888 - val_accuracy: 0.9010\n",
            "test obs. 2000 accuracy 0.902102973168963\n",
            "test obs. 2000 b_accuracy 0.829626060850697\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 1s 70ms/step - loss: 4.3210 - accuracy: 0.0482 - val_loss: 4.0023 - val_accuracy: 0.2375\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 3.9210 - accuracy: 0.1782 - val_loss: 3.2222 - val_accuracy: 0.4188\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 2.9985 - accuracy: 0.3956 - val_loss: 1.9527 - val_accuracy: 0.6856\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 1.9726 - accuracy: 0.5774 - val_loss: 1.1476 - val_accuracy: 0.7941\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 1.2414 - accuracy: 0.7426 - val_loss: 0.7625 - val_accuracy: 0.8474\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.8298 - accuracy: 0.8086 - val_loss: 0.5618 - val_accuracy: 0.8814\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.6201 - accuracy: 0.8720 - val_loss: 0.4661 - val_accuracy: 0.8916\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.4523 - accuracy: 0.9054 - val_loss: 0.4069 - val_accuracy: 0.9075\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.3595 - accuracy: 0.9304 - val_loss: 0.3902 - val_accuracy: 0.9090\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.2843 - accuracy: 0.9378 - val_loss: 0.3598 - val_accuracy: 0.9195\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.2434 - accuracy: 0.9506 - val_loss: 0.3543 - val_accuracy: 0.9213\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.2050 - accuracy: 0.9582 - val_loss: 0.3446 - val_accuracy: 0.9249\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.2065 - accuracy: 0.9648 - val_loss: 0.3324 - val_accuracy: 0.9260\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.1596 - accuracy: 0.9644 - val_loss: 0.3344 - val_accuracy: 0.9242\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1625 - accuracy: 0.9652 - val_loss: 0.3376 - val_accuracy: 0.9246\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.1393 - accuracy: 0.9774 - val_loss: 0.3395 - val_accuracy: 0.9260\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1196 - accuracy: 0.9756 - val_loss: 0.3542 - val_accuracy: 0.9253\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1121 - accuracy: 0.9754 - val_loss: 0.3577 - val_accuracy: 0.9253\n",
            "test obs. 5000 accuracy 0.9329224075416969\n",
            "test obs. 5000 b_accuracy 0.8604252540713982\n",
            "Epoch 1/150\n",
            "40/40 [==============================] - 2s 38ms/step - loss: 4.0593 - accuracy: 0.1417 - val_loss: 3.0247 - val_accuracy: 0.5192\n",
            "Epoch 2/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 2.5479 - accuracy: 0.4745 - val_loss: 1.1339 - val_accuracy: 0.7825\n",
            "Epoch 3/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.2063 - accuracy: 0.7367 - val_loss: 0.5515 - val_accuracy: 0.8916\n",
            "Epoch 4/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.7330 - accuracy: 0.8532 - val_loss: 0.4020 - val_accuracy: 0.9097\n",
            "Epoch 5/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.4727 - accuracy: 0.9067 - val_loss: 0.3093 - val_accuracy: 0.9304\n",
            "Epoch 6/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3530 - accuracy: 0.9293 - val_loss: 0.2818 - val_accuracy: 0.9394\n",
            "Epoch 7/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2533 - accuracy: 0.9472 - val_loss: 0.2681 - val_accuracy: 0.9405\n",
            "Epoch 8/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2085 - accuracy: 0.9566 - val_loss: 0.2655 - val_accuracy: 0.9420\n",
            "Epoch 9/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1619 - accuracy: 0.9653 - val_loss: 0.2652 - val_accuracy: 0.9449\n",
            "Epoch 10/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1414 - accuracy: 0.9708 - val_loss: 0.2601 - val_accuracy: 0.9420\n",
            "Epoch 11/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1232 - accuracy: 0.9754 - val_loss: 0.2644 - val_accuracy: 0.9442\n",
            "Epoch 12/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1042 - accuracy: 0.9770 - val_loss: 0.2656 - val_accuracy: 0.9445\n",
            "Epoch 13/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1027 - accuracy: 0.9803 - val_loss: 0.2766 - val_accuracy: 0.9431\n",
            "Epoch 14/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0741 - accuracy: 0.9831 - val_loss: 0.2722 - val_accuracy: 0.9445\n",
            "Epoch 15/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0671 - accuracy: 0.9832 - val_loss: 0.2781 - val_accuracy: 0.9445\n",
            "test obs. 10000 accuracy 0.9470630891950689\n",
            "test obs. 10000 b_accuracy 0.8847317137905696\n",
            "Epoch 1/150\n",
            "59/59 [==============================] - 2s 37ms/step - loss: 3.8016 - accuracy: 0.2129 - val_loss: 1.9934 - val_accuracy: 0.6987\n",
            "Epoch 2/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 1.6106 - accuracy: 0.6659 - val_loss: 0.5554 - val_accuracy: 0.9032\n",
            "Epoch 3/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.6806 - accuracy: 0.8633 - val_loss: 0.3270 - val_accuracy: 0.9282\n",
            "Epoch 4/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.3975 - accuracy: 0.9185 - val_loss: 0.2510 - val_accuracy: 0.9405\n",
            "Epoch 5/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.2740 - accuracy: 0.9429 - val_loss: 0.2259 - val_accuracy: 0.9492\n",
            "Epoch 6/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.2135 - accuracy: 0.9559 - val_loss: 0.2124 - val_accuracy: 0.9529\n",
            "Epoch 7/150\n",
            "59/59 [==============================] - 2s 35ms/step - loss: 0.1539 - accuracy: 0.9663 - val_loss: 0.2057 - val_accuracy: 0.9540\n",
            "Epoch 8/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.1200 - accuracy: 0.9741 - val_loss: 0.2034 - val_accuracy: 0.9558\n",
            "Epoch 9/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.1070 - accuracy: 0.9739 - val_loss: 0.2072 - val_accuracy: 0.9583\n",
            "Epoch 10/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.1008 - accuracy: 0.9766 - val_loss: 0.2092 - val_accuracy: 0.9587\n",
            "Epoch 11/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.0861 - accuracy: 0.9811 - val_loss: 0.2216 - val_accuracy: 0.9561\n",
            "Epoch 12/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.0838 - accuracy: 0.9809 - val_loss: 0.2305 - val_accuracy: 0.9543\n",
            "Epoch 13/150\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.0633 - accuracy: 0.9843 - val_loss: 0.2395 - val_accuracy: 0.9561\n",
            "test obs. 15000 accuracy 0.9579405366207396\n",
            "test obs. 15000 b_accuracy 0.9278737267443529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu8Ihtx1JK7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0dd9f9b4-51d5-4884-a497-75e61a62d296"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000,10000,15000]:\n",
        "     run_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs,True,False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 4.8206 - accuracy: 0.0100 - val_loss: 4.5748 - val_accuracy: 0.0011\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.3088 - accuracy: 0.0000e+00 - val_loss: 4.6201 - val_accuracy: 0.0011\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.2038 - accuracy: 0.0300 - val_loss: 4.5411 - val_accuracy: 0.0011\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 4.2079 - accuracy: 0.0100 - val_loss: 4.4748 - val_accuracy: 0.0011\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4.0358 - accuracy: 0.0200 - val_loss: 4.4167 - val_accuracy: 0.0033\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 3.8061 - accuracy: 0.0200 - val_loss: 4.4093 - val_accuracy: 0.0069\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 3.8694 - accuracy: 0.0400 - val_loss: 4.4145 - val_accuracy: 0.0167\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 3.6180 - accuracy: 0.0500 - val_loss: 4.4627 - val_accuracy: 0.0145\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 3.6110 - accuracy: 0.0800 - val_loss: 4.5047 - val_accuracy: 0.0152\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.4934 - accuracy: 0.0600 - val_loss: 4.5417 - val_accuracy: 0.0163\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.4015 - accuracy: 0.0500 - val_loss: 4.5762 - val_accuracy: 0.0181\n",
            "test obs. 100 accuracy 0.014865844815083394\n",
            "test obs. 100 b_accuracy 0.03593213858277975\n",
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 4.6881 - accuracy: 0.0080 - val_loss: 4.4895 - val_accuracy: 0.0062\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 4.7136 - accuracy: 0.0160 - val_loss: 4.4122 - val_accuracy: 0.0047\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.4187 - accuracy: 0.0240 - val_loss: 4.3640 - val_accuracy: 0.0025\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 4.3167 - accuracy: 0.0280 - val_loss: 4.3378 - val_accuracy: 0.0025\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 4.2530 - accuracy: 0.0280 - val_loss: 4.3086 - val_accuracy: 0.0025\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4.1880 - accuracy: 0.0360 - val_loss: 4.3003 - val_accuracy: 0.0040\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.1543 - accuracy: 0.0360 - val_loss: 4.3037 - val_accuracy: 0.0163\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4.1461 - accuracy: 0.0440 - val_loss: 4.3033 - val_accuracy: 0.0181\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 4.0241 - accuracy: 0.0320 - val_loss: 4.3128 - val_accuracy: 0.0134\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 3.9391 - accuracy: 0.0600 - val_loss: 4.3314 - val_accuracy: 0.0156\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 3.8555 - accuracy: 0.0680 - val_loss: 4.3658 - val_accuracy: 0.0062\n",
            "test obs. 250 accuracy 0.008339376359680928\n",
            "test obs. 250 b_accuracy 0.46520280892988153\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 5.0965 - accuracy: 0.0140 - val_loss: 4.5335 - val_accuracy: 3.6258e-04\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 4.6965 - accuracy: 0.0120 - val_loss: 4.3846 - val_accuracy: 0.0073\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 4.5885 - accuracy: 0.0140 - val_loss: 4.3172 - val_accuracy: 0.0040\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 4.5067 - accuracy: 0.0200 - val_loss: 4.2935 - val_accuracy: 0.0015\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 4.4941 - accuracy: 0.0200 - val_loss: 4.2756 - val_accuracy: 0.0076\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 4.4191 - accuracy: 0.0240 - val_loss: 4.2511 - val_accuracy: 0.0127\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 4.2935 - accuracy: 0.0320 - val_loss: 4.2314 - val_accuracy: 0.0189\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 4.1809 - accuracy: 0.0400 - val_loss: 4.2233 - val_accuracy: 0.0083\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 4.1294 - accuracy: 0.0440 - val_loss: 4.2227 - val_accuracy: 0.0105\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 4.0311 - accuracy: 0.0400 - val_loss: 4.2274 - val_accuracy: 0.0102\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.9743 - accuracy: 0.0360 - val_loss: 4.1987 - val_accuracy: 0.0141\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.8670 - accuracy: 0.0440 - val_loss: 4.1392 - val_accuracy: 0.0189\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.7638 - accuracy: 0.0600 - val_loss: 4.0710 - val_accuracy: 0.0363\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.7339 - accuracy: 0.0840 - val_loss: 4.0073 - val_accuracy: 0.0736\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6596 - accuracy: 0.0820 - val_loss: 3.9498 - val_accuracy: 0.0736\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.6137 - accuracy: 0.0900 - val_loss: 3.8908 - val_accuracy: 0.0823\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.4397 - accuracy: 0.1100 - val_loss: 3.8240 - val_accuracy: 0.0736\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.3758 - accuracy: 0.1120 - val_loss: 3.7440 - val_accuracy: 0.0812\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.1803 - accuracy: 0.1540 - val_loss: 3.6628 - val_accuracy: 0.0888\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.1238 - accuracy: 0.1560 - val_loss: 3.5859 - val_accuracy: 0.1015\n",
            "Epoch 21/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.0329 - accuracy: 0.1740 - val_loss: 3.5149 - val_accuracy: 0.1262\n",
            "Epoch 22/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.0511 - accuracy: 0.1840 - val_loss: 3.4532 - val_accuracy: 0.1429\n",
            "Epoch 23/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.9510 - accuracy: 0.1900 - val_loss: 3.3764 - val_accuracy: 0.1668\n",
            "Epoch 24/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.7617 - accuracy: 0.2340 - val_loss: 3.3019 - val_accuracy: 0.1940\n",
            "Epoch 25/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.6811 - accuracy: 0.2480 - val_loss: 3.2379 - val_accuracy: 0.2234\n",
            "Epoch 26/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.6534 - accuracy: 0.2500 - val_loss: 3.1728 - val_accuracy: 0.2313\n",
            "Epoch 27/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 2.5677 - accuracy: 0.2720 - val_loss: 3.1204 - val_accuracy: 0.2549\n",
            "Epoch 28/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.4973 - accuracy: 0.2660 - val_loss: 3.0635 - val_accuracy: 0.2607\n",
            "Epoch 29/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.4595 - accuracy: 0.2900 - val_loss: 2.9948 - val_accuracy: 0.2861\n",
            "Epoch 30/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.3185 - accuracy: 0.3240 - val_loss: 2.9134 - val_accuracy: 0.3078\n",
            "Epoch 31/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.2486 - accuracy: 0.3580 - val_loss: 2.8392 - val_accuracy: 0.3223\n",
            "Epoch 32/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.1592 - accuracy: 0.3760 - val_loss: 2.7741 - val_accuracy: 0.3336\n",
            "Epoch 33/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.2582 - accuracy: 0.3600 - val_loss: 2.7183 - val_accuracy: 0.3626\n",
            "Epoch 34/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.2156 - accuracy: 0.4080 - val_loss: 2.6858 - val_accuracy: 0.3767\n",
            "Epoch 35/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.0895 - accuracy: 0.3740 - val_loss: 2.6562 - val_accuracy: 0.3629\n",
            "Epoch 36/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.0107 - accuracy: 0.3940 - val_loss: 2.6166 - val_accuracy: 0.3648\n",
            "Epoch 37/150\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.9755 - accuracy: 0.3980 - val_loss: 2.5608 - val_accuracy: 0.3843\n",
            "Epoch 38/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.8503 - accuracy: 0.4140 - val_loss: 2.4999 - val_accuracy: 0.4300\n",
            "Epoch 39/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.8353 - accuracy: 0.4580 - val_loss: 2.4495 - val_accuracy: 0.4453\n",
            "Epoch 40/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.8383 - accuracy: 0.4560 - val_loss: 2.4169 - val_accuracy: 0.4496\n",
            "Epoch 41/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.7830 - accuracy: 0.4320 - val_loss: 2.3917 - val_accuracy: 0.4536\n",
            "Epoch 42/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.6864 - accuracy: 0.4600 - val_loss: 2.3767 - val_accuracy: 0.4456\n",
            "Epoch 43/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.6260 - accuracy: 0.4720 - val_loss: 2.3411 - val_accuracy: 0.4503\n",
            "Epoch 44/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.5437 - accuracy: 0.4800 - val_loss: 2.2949 - val_accuracy: 0.4659\n",
            "Epoch 45/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.5386 - accuracy: 0.5240 - val_loss: 2.2423 - val_accuracy: 0.4898\n",
            "Epoch 46/150\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.4867 - accuracy: 0.5180 - val_loss: 2.1987 - val_accuracy: 0.5054\n",
            "Epoch 47/150\n",
            "2/2 [==============================] - 0s 210ms/step - loss: 1.5596 - accuracy: 0.5620 - val_loss: 2.1608 - val_accuracy: 0.5149\n",
            "Epoch 48/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.3627 - accuracy: 0.5380 - val_loss: 2.1295 - val_accuracy: 0.5207\n",
            "Epoch 49/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.3414 - accuracy: 0.5780 - val_loss: 2.1056 - val_accuracy: 0.5170\n",
            "Epoch 50/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.3858 - accuracy: 0.5660 - val_loss: 2.0820 - val_accuracy: 0.5167\n",
            "Epoch 51/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.3565 - accuracy: 0.5620 - val_loss: 2.0569 - val_accuracy: 0.5337\n",
            "Epoch 52/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.3244 - accuracy: 0.5640 - val_loss: 2.0310 - val_accuracy: 0.5428\n",
            "Epoch 53/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.2521 - accuracy: 0.5960 - val_loss: 2.0054 - val_accuracy: 0.5482\n",
            "Epoch 54/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.2581 - accuracy: 0.5580 - val_loss: 1.9747 - val_accuracy: 0.5649\n",
            "Epoch 55/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.1491 - accuracy: 0.6220 - val_loss: 1.9493 - val_accuracy: 0.5769\n",
            "Epoch 56/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1.1487 - accuracy: 0.6300 - val_loss: 1.9280 - val_accuracy: 0.5769\n",
            "Epoch 57/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.1430 - accuracy: 0.6480 - val_loss: 1.9150 - val_accuracy: 0.5740\n",
            "Epoch 58/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.0438 - accuracy: 0.6320 - val_loss: 1.8955 - val_accuracy: 0.5743\n",
            "Epoch 59/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.0943 - accuracy: 0.6720 - val_loss: 1.8754 - val_accuracy: 0.5830\n",
            "Epoch 60/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.0995 - accuracy: 0.6460 - val_loss: 1.8527 - val_accuracy: 0.5856\n",
            "Epoch 61/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.0339 - accuracy: 0.6820 - val_loss: 1.8308 - val_accuracy: 0.5899\n",
            "Epoch 62/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.0436 - accuracy: 0.6540 - val_loss: 1.8119 - val_accuracy: 0.5906\n",
            "Epoch 63/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.9927 - accuracy: 0.6780 - val_loss: 1.8004 - val_accuracy: 0.5986\n",
            "Epoch 64/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.0085 - accuracy: 0.6820 - val_loss: 1.7897 - val_accuracy: 0.6033\n",
            "Epoch 65/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.9456 - accuracy: 0.7100 - val_loss: 1.7740 - val_accuracy: 0.6001\n",
            "Epoch 66/150\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.9922 - accuracy: 0.6820 - val_loss: 1.7501 - val_accuracy: 0.6059\n",
            "Epoch 67/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8813 - accuracy: 0.7200 - val_loss: 1.7261 - val_accuracy: 0.6146\n",
            "Epoch 68/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.9016 - accuracy: 0.7100 - val_loss: 1.7140 - val_accuracy: 0.6182\n",
            "Epoch 69/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.8385 - accuracy: 0.7280 - val_loss: 1.7010 - val_accuracy: 0.6215\n",
            "Epoch 70/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.9135 - accuracy: 0.7120 - val_loss: 1.6867 - val_accuracy: 0.6229\n",
            "Epoch 71/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.8020 - accuracy: 0.7460 - val_loss: 1.6750 - val_accuracy: 0.6280\n",
            "Epoch 72/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.8440 - accuracy: 0.7400 - val_loss: 1.6627 - val_accuracy: 0.6334\n",
            "Epoch 73/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.8130 - accuracy: 0.7680 - val_loss: 1.6520 - val_accuracy: 0.6367\n",
            "Epoch 74/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.8293 - accuracy: 0.7340 - val_loss: 1.6420 - val_accuracy: 0.6378\n",
            "Epoch 75/150\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.8403 - accuracy: 0.7520 - val_loss: 1.6330 - val_accuracy: 0.6403\n",
            "Epoch 76/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7771 - accuracy: 0.7560 - val_loss: 1.6280 - val_accuracy: 0.6432\n",
            "Epoch 77/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.7166 - accuracy: 0.7820 - val_loss: 1.6174 - val_accuracy: 0.6476\n",
            "Epoch 78/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.7490 - accuracy: 0.7500 - val_loss: 1.6070 - val_accuracy: 0.6516\n",
            "Epoch 79/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.7228 - accuracy: 0.7820 - val_loss: 1.5994 - val_accuracy: 0.6545\n",
            "Epoch 80/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6916 - accuracy: 0.7880 - val_loss: 1.5918 - val_accuracy: 0.6581\n",
            "Epoch 81/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.6340 - accuracy: 0.7920 - val_loss: 1.5796 - val_accuracy: 0.6642\n",
            "Epoch 82/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7035 - accuracy: 0.7940 - val_loss: 1.5730 - val_accuracy: 0.6664\n",
            "Epoch 83/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6182 - accuracy: 0.7780 - val_loss: 1.5639 - val_accuracy: 0.6708\n",
            "Epoch 84/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.6255 - accuracy: 0.8000 - val_loss: 1.5450 - val_accuracy: 0.6762\n",
            "Epoch 85/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6324 - accuracy: 0.8120 - val_loss: 1.5353 - val_accuracy: 0.6849\n",
            "Epoch 86/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6719 - accuracy: 0.8100 - val_loss: 1.5345 - val_accuracy: 0.6831\n",
            "Epoch 87/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6494 - accuracy: 0.8100 - val_loss: 1.5333 - val_accuracy: 0.6827\n",
            "Epoch 88/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6205 - accuracy: 0.8000 - val_loss: 1.5418 - val_accuracy: 0.6759\n",
            "Epoch 89/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6339 - accuracy: 0.7840 - val_loss: 1.5439 - val_accuracy: 0.6740\n",
            "Epoch 90/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6106 - accuracy: 0.7980 - val_loss: 1.5320 - val_accuracy: 0.6751\n",
            "Epoch 91/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5705 - accuracy: 0.8060 - val_loss: 1.5198 - val_accuracy: 0.6766\n",
            "Epoch 92/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5775 - accuracy: 0.8000 - val_loss: 1.5072 - val_accuracy: 0.6827\n",
            "Epoch 93/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5369 - accuracy: 0.8560 - val_loss: 1.4951 - val_accuracy: 0.6871\n",
            "Epoch 94/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5177 - accuracy: 0.8420 - val_loss: 1.4928 - val_accuracy: 0.6835\n",
            "Epoch 95/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5491 - accuracy: 0.8000 - val_loss: 1.5014 - val_accuracy: 0.6838\n",
            "Epoch 96/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4975 - accuracy: 0.8480 - val_loss: 1.5072 - val_accuracy: 0.6824\n",
            "Epoch 97/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5014 - accuracy: 0.8380 - val_loss: 1.4972 - val_accuracy: 0.6875\n",
            "Epoch 98/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4926 - accuracy: 0.8440 - val_loss: 1.4840 - val_accuracy: 0.7005\n",
            "Epoch 99/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4848 - accuracy: 0.8560 - val_loss: 1.4712 - val_accuracy: 0.7016\n",
            "Epoch 100/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4328 - accuracy: 0.8680 - val_loss: 1.4645 - val_accuracy: 0.7038\n",
            "Epoch 101/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4433 - accuracy: 0.8700 - val_loss: 1.4632 - val_accuracy: 0.7041\n",
            "Epoch 102/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4843 - accuracy: 0.8740 - val_loss: 1.4702 - val_accuracy: 0.7038\n",
            "Epoch 103/150\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5207 - accuracy: 0.8580 - val_loss: 1.4765 - val_accuracy: 0.7030\n",
            "Epoch 104/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4582 - accuracy: 0.8460 - val_loss: 1.4775 - val_accuracy: 0.6994\n",
            "Epoch 105/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4411 - accuracy: 0.8700 - val_loss: 1.4687 - val_accuracy: 0.7030\n",
            "Epoch 106/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4099 - accuracy: 0.8740 - val_loss: 1.4640 - val_accuracy: 0.7034\n",
            "test obs. 500 accuracy 0.6990572878897752\n",
            "test obs. 500 b_accuracy 0.6684534438272235\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 4.6651 - accuracy: 0.0100 - val_loss: 4.3030 - val_accuracy: 0.0044\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 4.3981 - accuracy: 0.0150 - val_loss: 4.2461 - val_accuracy: 0.0247\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 4.2222 - accuracy: 0.0210 - val_loss: 4.2259 - val_accuracy: 0.0185\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 4.1327 - accuracy: 0.0310 - val_loss: 4.1785 - val_accuracy: 0.0149\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 4.0049 - accuracy: 0.0420 - val_loss: 4.1105 - val_accuracy: 0.0170\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 3.9617 - accuracy: 0.0510 - val_loss: 4.0075 - val_accuracy: 0.0214\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.8205 - accuracy: 0.0600 - val_loss: 3.9182 - val_accuracy: 0.0892\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 3.6687 - accuracy: 0.0980 - val_loss: 3.7922 - val_accuracy: 0.1628\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.5311 - accuracy: 0.1460 - val_loss: 3.6766 - val_accuracy: 0.1987\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.3122 - accuracy: 0.1800 - val_loss: 3.5513 - val_accuracy: 0.2085\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 3.2507 - accuracy: 0.1970 - val_loss: 3.4127 - val_accuracy: 0.2563\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.1127 - accuracy: 0.2050 - val_loss: 3.2773 - val_accuracy: 0.3173\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.9504 - accuracy: 0.2190 - val_loss: 3.1284 - val_accuracy: 0.3336\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.8438 - accuracy: 0.2700 - val_loss: 2.9900 - val_accuracy: 0.3622\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.6783 - accuracy: 0.3020 - val_loss: 2.8525 - val_accuracy: 0.3996\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.4769 - accuracy: 0.3220 - val_loss: 2.7287 - val_accuracy: 0.4108\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.3884 - accuracy: 0.3530 - val_loss: 2.6170 - val_accuracy: 0.4112\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.3041 - accuracy: 0.3570 - val_loss: 2.5113 - val_accuracy: 0.4315\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.1566 - accuracy: 0.4220 - val_loss: 2.4077 - val_accuracy: 0.4507\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.0684 - accuracy: 0.3960 - val_loss: 2.3224 - val_accuracy: 0.4775\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.0405 - accuracy: 0.4280 - val_loss: 2.2335 - val_accuracy: 0.4975\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.9045 - accuracy: 0.4590 - val_loss: 2.1367 - val_accuracy: 0.5145\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.8577 - accuracy: 0.4590 - val_loss: 2.0579 - val_accuracy: 0.5305\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.7484 - accuracy: 0.4970 - val_loss: 1.9785 - val_accuracy: 0.5551\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.6903 - accuracy: 0.5020 - val_loss: 1.9053 - val_accuracy: 0.5703\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.6099 - accuracy: 0.5190 - val_loss: 1.8444 - val_accuracy: 0.5848\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.5508 - accuracy: 0.5750 - val_loss: 1.7814 - val_accuracy: 0.5972\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.5824 - accuracy: 0.5460 - val_loss: 1.7308 - val_accuracy: 0.6207\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.4767 - accuracy: 0.5610 - val_loss: 1.6741 - val_accuracy: 0.6215\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.4374 - accuracy: 0.5850 - val_loss: 1.6228 - val_accuracy: 0.6164\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.3890 - accuracy: 0.6000 - val_loss: 1.5679 - val_accuracy: 0.6320\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.3079 - accuracy: 0.6050 - val_loss: 1.5278 - val_accuracy: 0.6624\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.2166 - accuracy: 0.6260 - val_loss: 1.4878 - val_accuracy: 0.6621\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.2287 - accuracy: 0.6360 - val_loss: 1.4554 - val_accuracy: 0.6628\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.2080 - accuracy: 0.6550 - val_loss: 1.4273 - val_accuracy: 0.6682\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.1423 - accuracy: 0.6520 - val_loss: 1.4103 - val_accuracy: 0.6769\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.0770 - accuracy: 0.6800 - val_loss: 1.3763 - val_accuracy: 0.6766\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.0695 - accuracy: 0.6840 - val_loss: 1.3438 - val_accuracy: 0.6791\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.0278 - accuracy: 0.6760 - val_loss: 1.3055 - val_accuracy: 0.6914\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.9886 - accuracy: 0.6980 - val_loss: 1.2726 - val_accuracy: 0.7023\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.0275 - accuracy: 0.6910 - val_loss: 1.2482 - val_accuracy: 0.7096\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.9219 - accuracy: 0.7270 - val_loss: 1.2315 - val_accuracy: 0.7136\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.8783 - accuracy: 0.7160 - val_loss: 1.2162 - val_accuracy: 0.7103\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.8645 - accuracy: 0.7450 - val_loss: 1.1944 - val_accuracy: 0.7092\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.8538 - accuracy: 0.7270 - val_loss: 1.1720 - val_accuracy: 0.7154\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.8794 - accuracy: 0.7300 - val_loss: 1.1409 - val_accuracy: 0.7302\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.8504 - accuracy: 0.7530 - val_loss: 1.1238 - val_accuracy: 0.7364\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.7647 - accuracy: 0.7720 - val_loss: 1.1095 - val_accuracy: 0.7346\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.7210 - accuracy: 0.7720 - val_loss: 1.0879 - val_accuracy: 0.7404\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.7434 - accuracy: 0.7720 - val_loss: 1.0760 - val_accuracy: 0.7455\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.7141 - accuracy: 0.7670 - val_loss: 1.0695 - val_accuracy: 0.7491\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.7048 - accuracy: 0.7930 - val_loss: 1.0669 - val_accuracy: 0.7473\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.6865 - accuracy: 0.8060 - val_loss: 1.0516 - val_accuracy: 0.7502\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6522 - accuracy: 0.7950 - val_loss: 1.0378 - val_accuracy: 0.7596\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6936 - accuracy: 0.7810 - val_loss: 1.0259 - val_accuracy: 0.7618\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6435 - accuracy: 0.8190 - val_loss: 1.0191 - val_accuracy: 0.7592\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5941 - accuracy: 0.8200 - val_loss: 1.0141 - val_accuracy: 0.7596\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5966 - accuracy: 0.8130 - val_loss: 0.9993 - val_accuracy: 0.7654\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6008 - accuracy: 0.8100 - val_loss: 0.9881 - val_accuracy: 0.7687\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.5624 - accuracy: 0.8400 - val_loss: 0.9812 - val_accuracy: 0.7734\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5595 - accuracy: 0.8380 - val_loss: 0.9748 - val_accuracy: 0.7730\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.5976 - accuracy: 0.8130 - val_loss: 0.9640 - val_accuracy: 0.7752\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.5385 - accuracy: 0.8200 - val_loss: 0.9515 - val_accuracy: 0.7766\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.5408 - accuracy: 0.8460 - val_loss: 0.9446 - val_accuracy: 0.7730\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5127 - accuracy: 0.8340 - val_loss: 0.9450 - val_accuracy: 0.7737\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4946 - accuracy: 0.8430 - val_loss: 0.9444 - val_accuracy: 0.7737\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5031 - accuracy: 0.8430 - val_loss: 0.9329 - val_accuracy: 0.7864\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4843 - accuracy: 0.8470 - val_loss: 0.9250 - val_accuracy: 0.7868\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5642 - accuracy: 0.8170 - val_loss: 0.9251 - val_accuracy: 0.7828\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4719 - accuracy: 0.8440 - val_loss: 0.9204 - val_accuracy: 0.7868\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4996 - accuracy: 0.8370 - val_loss: 0.9139 - val_accuracy: 0.7875\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4703 - accuracy: 0.8520 - val_loss: 0.9107 - val_accuracy: 0.7941\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4432 - accuracy: 0.8550 - val_loss: 0.9074 - val_accuracy: 0.7962\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4731 - accuracy: 0.8590 - val_loss: 0.8974 - val_accuracy: 0.7919\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4426 - accuracy: 0.8550 - val_loss: 0.8959 - val_accuracy: 0.7941\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4714 - accuracy: 0.8540 - val_loss: 0.8981 - val_accuracy: 0.7941\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4003 - accuracy: 0.8670 - val_loss: 0.8926 - val_accuracy: 0.7977\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4098 - accuracy: 0.8660 - val_loss: 0.8822 - val_accuracy: 0.8038\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4145 - accuracy: 0.8710 - val_loss: 0.8807 - val_accuracy: 0.8038\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3889 - accuracy: 0.8810 - val_loss: 0.8768 - val_accuracy: 0.7984\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4356 - accuracy: 0.8630 - val_loss: 0.8746 - val_accuracy: 0.8024\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4037 - accuracy: 0.8640 - val_loss: 0.8729 - val_accuracy: 0.8053\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3651 - accuracy: 0.8710 - val_loss: 0.8654 - val_accuracy: 0.8042\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3564 - accuracy: 0.8950 - val_loss: 0.8587 - val_accuracy: 0.8049\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3796 - accuracy: 0.8860 - val_loss: 0.8616 - val_accuracy: 0.7999\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3376 - accuracy: 0.8940 - val_loss: 0.8603 - val_accuracy: 0.7995\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3992 - accuracy: 0.8850 - val_loss: 0.8553 - val_accuracy: 0.7995\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3654 - accuracy: 0.8860 - val_loss: 0.8564 - val_accuracy: 0.8020\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3671 - accuracy: 0.8620 - val_loss: 0.8543 - val_accuracy: 0.8031\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3567 - accuracy: 0.8910 - val_loss: 0.8578 - val_accuracy: 0.8060\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3267 - accuracy: 0.9130 - val_loss: 0.8673 - val_accuracy: 0.8009\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3550 - accuracy: 0.8810 - val_loss: 0.8688 - val_accuracy: 0.8013\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.2977 - accuracy: 0.9110 - val_loss: 0.8592 - val_accuracy: 0.8064\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3153 - accuracy: 0.8630 - val_loss: 0.8548 - val_accuracy: 0.8089\n",
            "test obs. 1000 accuracy 0.8005801305293692\n",
            "test obs. 1000 b_accuracy 0.7429509351362569\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 4.4719 - accuracy: 0.0230 - val_loss: 4.2561 - val_accuracy: 0.0261\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.2337 - accuracy: 0.0290 - val_loss: 4.1530 - val_accuracy: 0.0522\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.0547 - accuracy: 0.0550 - val_loss: 4.0226 - val_accuracy: 0.0700\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.9005 - accuracy: 0.0685 - val_loss: 3.8514 - val_accuracy: 0.1233\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.6727 - accuracy: 0.0975 - val_loss: 3.6212 - val_accuracy: 0.1258\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.4152 - accuracy: 0.1690 - val_loss: 3.3298 - val_accuracy: 0.2161\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.1782 - accuracy: 0.1975 - val_loss: 3.0560 - val_accuracy: 0.2545\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.9240 - accuracy: 0.2625 - val_loss: 2.7974 - val_accuracy: 0.3930\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.6842 - accuracy: 0.3070 - val_loss: 2.5343 - val_accuracy: 0.4616\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.4064 - accuracy: 0.3550 - val_loss: 2.3127 - val_accuracy: 0.4906\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.2632 - accuracy: 0.3855 - val_loss: 2.1182 - val_accuracy: 0.5359\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.0954 - accuracy: 0.4230 - val_loss: 1.9496 - val_accuracy: 0.5852\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.9452 - accuracy: 0.4590 - val_loss: 1.7857 - val_accuracy: 0.6073\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.7440 - accuracy: 0.5155 - val_loss: 1.6538 - val_accuracy: 0.6374\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.6391 - accuracy: 0.5425 - val_loss: 1.5380 - val_accuracy: 0.6439\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.5516 - accuracy: 0.5465 - val_loss: 1.3973 - val_accuracy: 0.6769\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.4804 - accuracy: 0.5750 - val_loss: 1.3346 - val_accuracy: 0.7009\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.3682 - accuracy: 0.6060 - val_loss: 1.2514 - val_accuracy: 0.7023\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.3022 - accuracy: 0.6140 - val_loss: 1.1914 - val_accuracy: 0.7266\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.2335 - accuracy: 0.6495 - val_loss: 1.1479 - val_accuracy: 0.7277\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.1572 - accuracy: 0.6620 - val_loss: 1.0843 - val_accuracy: 0.7321\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.0722 - accuracy: 0.6800 - val_loss: 1.0259 - val_accuracy: 0.7538\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.0611 - accuracy: 0.6705 - val_loss: 0.9992 - val_accuracy: 0.7712\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.0059 - accuracy: 0.7035 - val_loss: 0.9515 - val_accuracy: 0.7676\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.9135 - accuracy: 0.7200 - val_loss: 0.9149 - val_accuracy: 0.7864\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.8648 - accuracy: 0.7375 - val_loss: 0.8772 - val_accuracy: 0.8013\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.8830 - accuracy: 0.7295 - val_loss: 0.8522 - val_accuracy: 0.8020\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.8360 - accuracy: 0.7510 - val_loss: 0.8368 - val_accuracy: 0.8017\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.8580 - accuracy: 0.7440 - val_loss: 0.8105 - val_accuracy: 0.8158\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.7704 - accuracy: 0.7655 - val_loss: 0.7807 - val_accuracy: 0.8252\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.7823 - accuracy: 0.7615 - val_loss: 0.7667 - val_accuracy: 0.8202\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.7416 - accuracy: 0.7740 - val_loss: 0.7431 - val_accuracy: 0.8252\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.6906 - accuracy: 0.7870 - val_loss: 0.7227 - val_accuracy: 0.8263\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.7079 - accuracy: 0.7900 - val_loss: 0.7164 - val_accuracy: 0.8321\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.6538 - accuracy: 0.8060 - val_loss: 0.6928 - val_accuracy: 0.8383\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.6086 - accuracy: 0.8080 - val_loss: 0.6773 - val_accuracy: 0.8434\n",
            "Epoch 37/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.6055 - accuracy: 0.8045 - val_loss: 0.6743 - val_accuracy: 0.8416\n",
            "Epoch 38/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.6074 - accuracy: 0.8150 - val_loss: 0.6665 - val_accuracy: 0.8365\n",
            "Epoch 39/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.6025 - accuracy: 0.8015 - val_loss: 0.6460 - val_accuracy: 0.8488\n",
            "Epoch 40/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5481 - accuracy: 0.8325 - val_loss: 0.6256 - val_accuracy: 0.8542\n",
            "Epoch 41/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5439 - accuracy: 0.8450 - val_loss: 0.6183 - val_accuracy: 0.8535\n",
            "Epoch 42/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5495 - accuracy: 0.8285 - val_loss: 0.6090 - val_accuracy: 0.8571\n",
            "Epoch 43/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5077 - accuracy: 0.8280 - val_loss: 0.6066 - val_accuracy: 0.8546\n",
            "Epoch 44/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4831 - accuracy: 0.8420 - val_loss: 0.5945 - val_accuracy: 0.8629\n",
            "Epoch 45/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4916 - accuracy: 0.8405 - val_loss: 0.5896 - val_accuracy: 0.8611\n",
            "Epoch 46/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4956 - accuracy: 0.8445 - val_loss: 0.5848 - val_accuracy: 0.8662\n",
            "Epoch 47/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4718 - accuracy: 0.8495 - val_loss: 0.5819 - val_accuracy: 0.8651\n",
            "Epoch 48/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4855 - accuracy: 0.8620 - val_loss: 0.5748 - val_accuracy: 0.8637\n",
            "Epoch 49/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4548 - accuracy: 0.8580 - val_loss: 0.5712 - val_accuracy: 0.8611\n",
            "Epoch 50/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4321 - accuracy: 0.8590 - val_loss: 0.5645 - val_accuracy: 0.8651\n",
            "Epoch 51/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4148 - accuracy: 0.8680 - val_loss: 0.5521 - val_accuracy: 0.8702\n",
            "Epoch 52/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4300 - accuracy: 0.8635 - val_loss: 0.5505 - val_accuracy: 0.8669\n",
            "Epoch 53/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4182 - accuracy: 0.8625 - val_loss: 0.5378 - val_accuracy: 0.8695\n",
            "Epoch 54/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3773 - accuracy: 0.8820 - val_loss: 0.5441 - val_accuracy: 0.8677\n",
            "Epoch 55/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3878 - accuracy: 0.8760 - val_loss: 0.5374 - val_accuracy: 0.8713\n",
            "Epoch 56/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3881 - accuracy: 0.8735 - val_loss: 0.5320 - val_accuracy: 0.8684\n",
            "Epoch 57/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3753 - accuracy: 0.8825 - val_loss: 0.5260 - val_accuracy: 0.8727\n",
            "Epoch 58/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3653 - accuracy: 0.8845 - val_loss: 0.5227 - val_accuracy: 0.8738\n",
            "Epoch 59/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3485 - accuracy: 0.8955 - val_loss: 0.5240 - val_accuracy: 0.8760\n",
            "Epoch 60/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3680 - accuracy: 0.8890 - val_loss: 0.5213 - val_accuracy: 0.8753\n",
            "Epoch 61/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3345 - accuracy: 0.8935 - val_loss: 0.5209 - val_accuracy: 0.8771\n",
            "Epoch 62/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.3515 - accuracy: 0.8850 - val_loss: 0.5238 - val_accuracy: 0.8720\n",
            "Epoch 63/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3601 - accuracy: 0.8790 - val_loss: 0.5218 - val_accuracy: 0.8713\n",
            "Epoch 64/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3150 - accuracy: 0.8985 - val_loss: 0.5170 - val_accuracy: 0.8720\n",
            "Epoch 65/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3455 - accuracy: 0.9020 - val_loss: 0.5073 - val_accuracy: 0.8742\n",
            "Epoch 66/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3138 - accuracy: 0.8955 - val_loss: 0.5055 - val_accuracy: 0.8767\n",
            "Epoch 67/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2850 - accuracy: 0.9095 - val_loss: 0.5067 - val_accuracy: 0.8789\n",
            "Epoch 68/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3329 - accuracy: 0.8950 - val_loss: 0.5113 - val_accuracy: 0.8756\n",
            "Epoch 69/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3241 - accuracy: 0.8950 - val_loss: 0.5065 - val_accuracy: 0.8796\n",
            "Epoch 70/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3044 - accuracy: 0.9060 - val_loss: 0.5047 - val_accuracy: 0.8789\n",
            "Epoch 71/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.2806 - accuracy: 0.9060 - val_loss: 0.4998 - val_accuracy: 0.8803\n",
            "Epoch 72/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2635 - accuracy: 0.9065 - val_loss: 0.4959 - val_accuracy: 0.8818\n",
            "Epoch 73/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2906 - accuracy: 0.9035 - val_loss: 0.4897 - val_accuracy: 0.8825\n",
            "Epoch 74/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2463 - accuracy: 0.9135 - val_loss: 0.4908 - val_accuracy: 0.8811\n",
            "Epoch 75/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2564 - accuracy: 0.9200 - val_loss: 0.4851 - val_accuracy: 0.8822\n",
            "Epoch 76/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2769 - accuracy: 0.9110 - val_loss: 0.4874 - val_accuracy: 0.8807\n",
            "Epoch 77/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2604 - accuracy: 0.9060 - val_loss: 0.4898 - val_accuracy: 0.8796\n",
            "Epoch 78/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2320 - accuracy: 0.9245 - val_loss: 0.4862 - val_accuracy: 0.8825\n",
            "Epoch 79/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2465 - accuracy: 0.9125 - val_loss: 0.4867 - val_accuracy: 0.8836\n",
            "Epoch 80/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.2447 - accuracy: 0.9235 - val_loss: 0.4848 - val_accuracy: 0.8843\n",
            "Epoch 81/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2411 - accuracy: 0.9195 - val_loss: 0.4825 - val_accuracy: 0.8840\n",
            "Epoch 82/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2177 - accuracy: 0.9315 - val_loss: 0.4749 - val_accuracy: 0.8858\n",
            "Epoch 83/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2271 - accuracy: 0.9335 - val_loss: 0.4779 - val_accuracy: 0.8843\n",
            "Epoch 84/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.2310 - accuracy: 0.9155 - val_loss: 0.4715 - val_accuracy: 0.8847\n",
            "Epoch 85/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2204 - accuracy: 0.9290 - val_loss: 0.4760 - val_accuracy: 0.8880\n",
            "Epoch 86/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2244 - accuracy: 0.9235 - val_loss: 0.4770 - val_accuracy: 0.8854\n",
            "Epoch 87/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2351 - accuracy: 0.9270 - val_loss: 0.4697 - val_accuracy: 0.8894\n",
            "Epoch 88/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2138 - accuracy: 0.9330 - val_loss: 0.4645 - val_accuracy: 0.8891\n",
            "Epoch 89/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2154 - accuracy: 0.9300 - val_loss: 0.4655 - val_accuracy: 0.8930\n",
            "Epoch 90/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2227 - accuracy: 0.9310 - val_loss: 0.4722 - val_accuracy: 0.8872\n",
            "Epoch 91/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2210 - accuracy: 0.9320 - val_loss: 0.4727 - val_accuracy: 0.8861\n",
            "Epoch 92/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2269 - accuracy: 0.9350 - val_loss: 0.4721 - val_accuracy: 0.8865\n",
            "Epoch 93/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2126 - accuracy: 0.9370 - val_loss: 0.4776 - val_accuracy: 0.8869\n",
            "test obs. 2000 accuracy 0.8908629441624365\n",
            "test obs. 2000 b_accuracy 0.8306269746705013\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 4.3442 - accuracy: 0.0336 - val_loss: 4.0445 - val_accuracy: 0.1407\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 3.9681 - accuracy: 0.1330 - val_loss: 3.4478 - val_accuracy: 0.2919\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 3.4102 - accuracy: 0.2058 - val_loss: 2.8120 - val_accuracy: 0.3829\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2.8343 - accuracy: 0.3026 - val_loss: 2.2523 - val_accuracy: 0.5522\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2.4165 - accuracy: 0.3736 - val_loss: 1.8659 - val_accuracy: 0.6030\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2.0387 - accuracy: 0.4484 - val_loss: 1.5787 - val_accuracy: 0.6574\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.8523 - accuracy: 0.4984 - val_loss: 1.4053 - val_accuracy: 0.6936\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.6260 - accuracy: 0.5302 - val_loss: 1.2186 - val_accuracy: 0.7270\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.4454 - accuracy: 0.5824 - val_loss: 1.0789 - val_accuracy: 0.7553\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.3242 - accuracy: 0.6020 - val_loss: 0.9954 - val_accuracy: 0.7825\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.2040 - accuracy: 0.6492 - val_loss: 0.8918 - val_accuracy: 0.8020\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.1447 - accuracy: 0.6506 - val_loss: 0.8425 - val_accuracy: 0.8038\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.1093 - accuracy: 0.6780 - val_loss: 0.7944 - val_accuracy: 0.8187\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.0160 - accuracy: 0.7050 - val_loss: 0.7477 - val_accuracy: 0.8296\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.9567 - accuracy: 0.7204 - val_loss: 0.6983 - val_accuracy: 0.8401\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.9083 - accuracy: 0.7376 - val_loss: 0.6471 - val_accuracy: 0.8546\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.8578 - accuracy: 0.7452 - val_loss: 0.6235 - val_accuracy: 0.8590\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7795 - accuracy: 0.7602 - val_loss: 0.5896 - val_accuracy: 0.8687\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7953 - accuracy: 0.7692 - val_loss: 0.5791 - val_accuracy: 0.8640\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7736 - accuracy: 0.7750 - val_loss: 0.5656 - val_accuracy: 0.8651\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7307 - accuracy: 0.7876 - val_loss: 0.5261 - val_accuracy: 0.8735\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6647 - accuracy: 0.8044 - val_loss: 0.5125 - val_accuracy: 0.8782\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6528 - accuracy: 0.7996 - val_loss: 0.4976 - val_accuracy: 0.8803\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6070 - accuracy: 0.8232 - val_loss: 0.4931 - val_accuracy: 0.8778\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6042 - accuracy: 0.8162 - val_loss: 0.4723 - val_accuracy: 0.8832\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5924 - accuracy: 0.8304 - val_loss: 0.4484 - val_accuracy: 0.8927\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5785 - accuracy: 0.8300 - val_loss: 0.4544 - val_accuracy: 0.8854\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5500 - accuracy: 0.8330 - val_loss: 0.4346 - val_accuracy: 0.8883\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5318 - accuracy: 0.8456 - val_loss: 0.4322 - val_accuracy: 0.8923\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5114 - accuracy: 0.8384 - val_loss: 0.4221 - val_accuracy: 0.8978\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5081 - accuracy: 0.8540 - val_loss: 0.4128 - val_accuracy: 0.9014\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4799 - accuracy: 0.8492 - val_loss: 0.4066 - val_accuracy: 0.9014\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5048 - accuracy: 0.8560 - val_loss: 0.4066 - val_accuracy: 0.8992\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4483 - accuracy: 0.8654 - val_loss: 0.4016 - val_accuracy: 0.8992\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4456 - accuracy: 0.8610 - val_loss: 0.3923 - val_accuracy: 0.9046\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4352 - accuracy: 0.8662 - val_loss: 0.3892 - val_accuracy: 0.9039\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4390 - accuracy: 0.8706 - val_loss: 0.3883 - val_accuracy: 0.9028\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4038 - accuracy: 0.8792 - val_loss: 0.3796 - val_accuracy: 0.9032\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4112 - accuracy: 0.8806 - val_loss: 0.3827 - val_accuracy: 0.9021\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3666 - accuracy: 0.8852 - val_loss: 0.3751 - val_accuracy: 0.9065\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.8840 - val_loss: 0.3683 - val_accuracy: 0.9068\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3620 - accuracy: 0.8806 - val_loss: 0.3693 - val_accuracy: 0.9090\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3733 - accuracy: 0.8852 - val_loss: 0.3674 - val_accuracy: 0.9075\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3519 - accuracy: 0.8926 - val_loss: 0.3619 - val_accuracy: 0.9101\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3518 - accuracy: 0.8928 - val_loss: 0.3629 - val_accuracy: 0.9104\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3620 - accuracy: 0.8930 - val_loss: 0.3583 - val_accuracy: 0.9108\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3403 - accuracy: 0.8958 - val_loss: 0.3510 - val_accuracy: 0.9094\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3203 - accuracy: 0.8948 - val_loss: 0.3520 - val_accuracy: 0.9112\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3214 - accuracy: 0.9038 - val_loss: 0.3533 - val_accuracy: 0.9097\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3076 - accuracy: 0.9038 - val_loss: 0.3487 - val_accuracy: 0.9108\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2995 - accuracy: 0.9096 - val_loss: 0.3500 - val_accuracy: 0.9137\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3156 - accuracy: 0.9076 - val_loss: 0.3426 - val_accuracy: 0.9133\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3012 - accuracy: 0.9038 - val_loss: 0.3447 - val_accuracy: 0.9159\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2806 - accuracy: 0.9140 - val_loss: 0.3431 - val_accuracy: 0.9115\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2848 - accuracy: 0.9084 - val_loss: 0.3408 - val_accuracy: 0.9159\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2933 - accuracy: 0.9118 - val_loss: 0.3465 - val_accuracy: 0.9144\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3110 - accuracy: 0.9006 - val_loss: 0.3445 - val_accuracy: 0.9152\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3159 - accuracy: 0.9124 - val_loss: 0.3488 - val_accuracy: 0.9130\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3054 - accuracy: 0.9020 - val_loss: 0.3427 - val_accuracy: 0.9162\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2858 - accuracy: 0.9140 - val_loss: 0.3436 - val_accuracy: 0.9137\n",
            "test obs. 5000 accuracy 0.9234952864394489\n",
            "test obs. 5000 b_accuracy 0.8580329316416527\n",
            "Epoch 1/150\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 4.1832 - accuracy: 0.0654 - val_loss: 3.7257 - val_accuracy: 0.2672\n",
            "Epoch 2/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 3.3122 - accuracy: 0.2401 - val_loss: 2.4766 - val_accuracy: 0.5384\n",
            "Epoch 3/150\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 2.4215 - accuracy: 0.3762 - val_loss: 1.7229 - val_accuracy: 0.6472\n",
            "Epoch 4/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.9322 - accuracy: 0.4854 - val_loss: 1.2904 - val_accuracy: 0.7241\n",
            "Epoch 5/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.5476 - accuracy: 0.5668 - val_loss: 1.0435 - val_accuracy: 0.7712\n",
            "Epoch 6/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.3471 - accuracy: 0.6309 - val_loss: 0.8636 - val_accuracy: 0.8057\n",
            "Epoch 7/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.1615 - accuracy: 0.6645 - val_loss: 0.7447 - val_accuracy: 0.8484\n",
            "Epoch 8/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.0714 - accuracy: 0.7026 - val_loss: 0.6626 - val_accuracy: 0.8753\n",
            "Epoch 9/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9707 - accuracy: 0.7353 - val_loss: 0.5848 - val_accuracy: 0.8767\n",
            "Epoch 10/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8596 - accuracy: 0.7650 - val_loss: 0.5372 - val_accuracy: 0.8912\n",
            "Epoch 11/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8232 - accuracy: 0.7678 - val_loss: 0.4850 - val_accuracy: 0.8909\n",
            "Epoch 12/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7438 - accuracy: 0.7963 - val_loss: 0.4703 - val_accuracy: 0.8949\n",
            "Epoch 13/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7211 - accuracy: 0.7991 - val_loss: 0.4603 - val_accuracy: 0.8876\n",
            "Epoch 14/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6700 - accuracy: 0.8093 - val_loss: 0.4191 - val_accuracy: 0.9036\n",
            "Epoch 15/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6418 - accuracy: 0.8174 - val_loss: 0.4133 - val_accuracy: 0.9028\n",
            "Epoch 16/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6048 - accuracy: 0.8247 - val_loss: 0.3875 - val_accuracy: 0.9072\n",
            "Epoch 17/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5769 - accuracy: 0.8345 - val_loss: 0.3865 - val_accuracy: 0.9065\n",
            "Epoch 18/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5540 - accuracy: 0.8387 - val_loss: 0.3698 - val_accuracy: 0.9083\n",
            "Epoch 19/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5111 - accuracy: 0.8496 - val_loss: 0.3598 - val_accuracy: 0.9097\n",
            "Epoch 20/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.4972 - accuracy: 0.8558 - val_loss: 0.3476 - val_accuracy: 0.9094\n",
            "Epoch 21/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4875 - accuracy: 0.8586 - val_loss: 0.3429 - val_accuracy: 0.9112\n",
            "Epoch 22/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4574 - accuracy: 0.8659 - val_loss: 0.3345 - val_accuracy: 0.9130\n",
            "Epoch 23/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.4511 - accuracy: 0.8607 - val_loss: 0.3297 - val_accuracy: 0.9144\n",
            "Epoch 24/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.4248 - accuracy: 0.8700 - val_loss: 0.3262 - val_accuracy: 0.9148\n",
            "Epoch 25/150\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4305 - accuracy: 0.8690 - val_loss: 0.3172 - val_accuracy: 0.9173\n",
            "Epoch 26/150\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4260 - accuracy: 0.8687 - val_loss: 0.3172 - val_accuracy: 0.9155\n",
            "Epoch 27/150\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4047 - accuracy: 0.8677 - val_loss: 0.3051 - val_accuracy: 0.9220\n",
            "Epoch 28/150\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4082 - accuracy: 0.8794 - val_loss: 0.3009 - val_accuracy: 0.9206\n",
            "Epoch 29/150\n",
            "40/40 [==============================] - 0s 12ms/step - loss: 0.4188 - accuracy: 0.8780 - val_loss: 0.3125 - val_accuracy: 0.9199\n",
            "Epoch 30/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3900 - accuracy: 0.8803 - val_loss: 0.2941 - val_accuracy: 0.9231\n",
            "Epoch 31/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3741 - accuracy: 0.8895 - val_loss: 0.2923 - val_accuracy: 0.9224\n",
            "Epoch 32/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3538 - accuracy: 0.8891 - val_loss: 0.2918 - val_accuracy: 0.9239\n",
            "Epoch 33/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3715 - accuracy: 0.8864 - val_loss: 0.2956 - val_accuracy: 0.9217\n",
            "Epoch 34/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3534 - accuracy: 0.8921 - val_loss: 0.2851 - val_accuracy: 0.9268\n",
            "Epoch 35/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3317 - accuracy: 0.8988 - val_loss: 0.2825 - val_accuracy: 0.9289\n",
            "Epoch 36/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3253 - accuracy: 0.8958 - val_loss: 0.2816 - val_accuracy: 0.9282\n",
            "Epoch 37/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3415 - accuracy: 0.8986 - val_loss: 0.2773 - val_accuracy: 0.9311\n",
            "Epoch 38/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3166 - accuracy: 0.9029 - val_loss: 0.2709 - val_accuracy: 0.9297\n",
            "Epoch 39/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2964 - accuracy: 0.9077 - val_loss: 0.2639 - val_accuracy: 0.9304\n",
            "Epoch 40/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.3025 - accuracy: 0.9011 - val_loss: 0.2659 - val_accuracy: 0.9333\n",
            "Epoch 41/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2851 - accuracy: 0.9091 - val_loss: 0.2623 - val_accuracy: 0.9318\n",
            "Epoch 42/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2888 - accuracy: 0.9061 - val_loss: 0.2667 - val_accuracy: 0.9315\n",
            "Epoch 43/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2799 - accuracy: 0.9102 - val_loss: 0.2617 - val_accuracy: 0.9300\n",
            "Epoch 44/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2735 - accuracy: 0.9151 - val_loss: 0.2537 - val_accuracy: 0.9365\n",
            "Epoch 45/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2875 - accuracy: 0.9111 - val_loss: 0.2588 - val_accuracy: 0.9297\n",
            "Epoch 46/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2634 - accuracy: 0.9126 - val_loss: 0.2583 - val_accuracy: 0.9318\n",
            "Epoch 47/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2657 - accuracy: 0.9141 - val_loss: 0.2602 - val_accuracy: 0.9336\n",
            "Epoch 48/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2622 - accuracy: 0.9186 - val_loss: 0.2621 - val_accuracy: 0.9318\n",
            "Epoch 49/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2564 - accuracy: 0.9198 - val_loss: 0.2535 - val_accuracy: 0.9358\n",
            "Epoch 50/150\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.2653 - accuracy: 0.9175 - val_loss: 0.2558 - val_accuracy: 0.9336\n",
            "Epoch 51/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2562 - accuracy: 0.9165 - val_loss: 0.2597 - val_accuracy: 0.9333\n",
            "Epoch 52/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2509 - accuracy: 0.9164 - val_loss: 0.2583 - val_accuracy: 0.9347\n",
            "Epoch 53/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2262 - accuracy: 0.9248 - val_loss: 0.2550 - val_accuracy: 0.9355\n",
            "Epoch 54/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2413 - accuracy: 0.9227 - val_loss: 0.2576 - val_accuracy: 0.9344\n",
            "test obs. 10000 accuracy 0.9405366207396664\n",
            "test obs. 10000 b_accuracy 0.8828942669095575\n",
            "Epoch 1/150\n",
            "59/59 [==============================] - 1s 12ms/step - loss: 3.9841 - accuracy: 0.1071 - val_loss: 3.0426 - val_accuracy: 0.3840\n",
            "Epoch 2/150\n",
            "59/59 [==============================] - 1s 10ms/step - loss: 2.6139 - accuracy: 0.3367 - val_loss: 1.6905 - val_accuracy: 0.6751\n",
            "Epoch 3/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 1.8032 - accuracy: 0.5094 - val_loss: 1.1052 - val_accuracy: 0.7770\n",
            "Epoch 4/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 1.3848 - accuracy: 0.6207 - val_loss: 0.8380 - val_accuracy: 0.8089\n",
            "Epoch 5/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 1.1327 - accuracy: 0.6888 - val_loss: 0.6939 - val_accuracy: 0.8318\n",
            "Epoch 6/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.9958 - accuracy: 0.7293 - val_loss: 0.5851 - val_accuracy: 0.8716\n",
            "Epoch 7/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.8676 - accuracy: 0.7603 - val_loss: 0.5264 - val_accuracy: 0.8793\n",
            "Epoch 8/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.7957 - accuracy: 0.7866 - val_loss: 0.4627 - val_accuracy: 0.8930\n",
            "Epoch 9/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.7376 - accuracy: 0.8012 - val_loss: 0.4283 - val_accuracy: 0.8985\n",
            "Epoch 10/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.6618 - accuracy: 0.8172 - val_loss: 0.3976 - val_accuracy: 0.8999\n",
            "Epoch 11/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.6210 - accuracy: 0.8331 - val_loss: 0.3923 - val_accuracy: 0.9075\n",
            "Epoch 12/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.5796 - accuracy: 0.8382 - val_loss: 0.3650 - val_accuracy: 0.9119\n",
            "Epoch 13/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.5269 - accuracy: 0.8490 - val_loss: 0.3349 - val_accuracy: 0.9155\n",
            "Epoch 14/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.5614 - accuracy: 0.8425 - val_loss: 0.3395 - val_accuracy: 0.9184\n",
            "Epoch 15/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.5197 - accuracy: 0.8561 - val_loss: 0.3234 - val_accuracy: 0.9126\n",
            "Epoch 16/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4778 - accuracy: 0.8655 - val_loss: 0.3091 - val_accuracy: 0.9231\n",
            "Epoch 17/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4808 - accuracy: 0.8651 - val_loss: 0.3095 - val_accuracy: 0.9228\n",
            "Epoch 18/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4542 - accuracy: 0.8728 - val_loss: 0.3044 - val_accuracy: 0.9202\n",
            "Epoch 19/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4205 - accuracy: 0.8835 - val_loss: 0.2962 - val_accuracy: 0.9242\n",
            "Epoch 20/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4080 - accuracy: 0.8813 - val_loss: 0.2754 - val_accuracy: 0.9282\n",
            "Epoch 21/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3856 - accuracy: 0.8845 - val_loss: 0.2775 - val_accuracy: 0.9249\n",
            "Epoch 22/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4041 - accuracy: 0.8829 - val_loss: 0.2670 - val_accuracy: 0.9282\n",
            "Epoch 23/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3804 - accuracy: 0.8911 - val_loss: 0.2647 - val_accuracy: 0.9358\n",
            "Epoch 24/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3484 - accuracy: 0.8973 - val_loss: 0.2543 - val_accuracy: 0.9329\n",
            "Epoch 25/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3897 - accuracy: 0.8938 - val_loss: 0.2599 - val_accuracy: 0.9358\n",
            "Epoch 26/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3600 - accuracy: 0.8997 - val_loss: 0.2586 - val_accuracy: 0.9315\n",
            "Epoch 27/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3262 - accuracy: 0.9028 - val_loss: 0.2510 - val_accuracy: 0.9358\n",
            "Epoch 28/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3023 - accuracy: 0.9092 - val_loss: 0.2397 - val_accuracy: 0.9398\n",
            "Epoch 29/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3280 - accuracy: 0.9084 - val_loss: 0.2471 - val_accuracy: 0.9376\n",
            "Epoch 30/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3063 - accuracy: 0.9072 - val_loss: 0.2359 - val_accuracy: 0.9387\n",
            "Epoch 31/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2884 - accuracy: 0.9113 - val_loss: 0.2425 - val_accuracy: 0.9351\n",
            "Epoch 32/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2731 - accuracy: 0.9171 - val_loss: 0.2309 - val_accuracy: 0.9373\n",
            "Epoch 33/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2843 - accuracy: 0.9127 - val_loss: 0.2367 - val_accuracy: 0.9384\n",
            "Epoch 34/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2958 - accuracy: 0.9136 - val_loss: 0.2292 - val_accuracy: 0.9380\n",
            "Epoch 35/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3028 - accuracy: 0.9131 - val_loss: 0.2304 - val_accuracy: 0.9409\n",
            "Epoch 36/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2690 - accuracy: 0.9160 - val_loss: 0.2333 - val_accuracy: 0.9387\n",
            "Epoch 37/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2621 - accuracy: 0.9206 - val_loss: 0.2266 - val_accuracy: 0.9409\n",
            "Epoch 38/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2585 - accuracy: 0.9177 - val_loss: 0.2284 - val_accuracy: 0.9438\n",
            "Epoch 39/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2522 - accuracy: 0.9210 - val_loss: 0.2260 - val_accuracy: 0.9442\n",
            "Epoch 40/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2350 - accuracy: 0.9245 - val_loss: 0.2191 - val_accuracy: 0.9423\n",
            "Epoch 41/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2649 - accuracy: 0.9175 - val_loss: 0.2210 - val_accuracy: 0.9463\n",
            "Epoch 42/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2404 - accuracy: 0.9257 - val_loss: 0.2213 - val_accuracy: 0.9438\n",
            "Epoch 43/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2390 - accuracy: 0.9269 - val_loss: 0.2220 - val_accuracy: 0.9453\n",
            "Epoch 44/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2390 - accuracy: 0.9235 - val_loss: 0.2266 - val_accuracy: 0.9438\n",
            "Epoch 45/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2292 - accuracy: 0.9277 - val_loss: 0.2272 - val_accuracy: 0.9467\n",
            "test obs. 15000 accuracy 0.9525018129079043\n",
            "test obs. 15000 b_accuracy 0.9103570550452015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exv3PVXNJNl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "485a8d3a-340b-4b74-d65c-7a7c64703756"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000,10000,15000]:\n",
        "     run_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n",
        "               vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs,False,False,0.4,0.03)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 4.3851 - accuracy: 0.0200 - val_loss: 4.4986 - val_accuracy: 0.0152\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 3.9972 - accuracy: 0.0500 - val_loss: 4.9219 - val_accuracy: 0.0058\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 3.9036 - accuracy: 0.0100 - val_loss: 5.1983 - val_accuracy: 0.0011\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.8126 - accuracy: 0.0300 - val_loss: 5.0492 - val_accuracy: 0.0011\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 3.7219 - accuracy: 0.0200 - val_loss: 4.8543 - val_accuracy: 0.0036\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 3.5605 - accuracy: 0.0500 - val_loss: 4.8125 - val_accuracy: 0.0047\n",
            "test obs. 100 accuracy 0.004713560551124003\n",
            "test obs. 100 b_accuracy 0.25243291124661543\n",
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 4.4848 - accuracy: 0.0040 - val_loss: 4.6541 - val_accuracy: 0.0033\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4.3889 - accuracy: 0.0200 - val_loss: 4.6593 - val_accuracy: 0.0025\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4.2089 - accuracy: 0.0360 - val_loss: 4.5126 - val_accuracy: 0.0033\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.0683 - accuracy: 0.0160 - val_loss: 4.4964 - val_accuracy: 0.0033\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.1188 - accuracy: 0.0320 - val_loss: 4.4345 - val_accuracy: 0.0138\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 3.9089 - accuracy: 0.0320 - val_loss: 4.4184 - val_accuracy: 0.0069\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 3.8976 - accuracy: 0.0320 - val_loss: 4.4065 - val_accuracy: 0.0040\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 3.8559 - accuracy: 0.0560 - val_loss: 4.3353 - val_accuracy: 0.0606\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 3.8381 - accuracy: 0.0800 - val_loss: 4.2781 - val_accuracy: 0.0696\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 3.7002 - accuracy: 0.0960 - val_loss: 4.2554 - val_accuracy: 0.0834\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.6140 - accuracy: 0.1080 - val_loss: 4.2545 - val_accuracy: 0.0877\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 3.5010 - accuracy: 0.1320 - val_loss: 4.2663 - val_accuracy: 0.0852\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 3.4258 - accuracy: 0.1440 - val_loss: 4.2355 - val_accuracy: 0.0856\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.3228 - accuracy: 0.0960 - val_loss: 4.1680 - val_accuracy: 0.0714\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 3.3000 - accuracy: 0.1360 - val_loss: 4.1207 - val_accuracy: 0.0718\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 3.1271 - accuracy: 0.1280 - val_loss: 4.0952 - val_accuracy: 0.0707\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.0336 - accuracy: 0.1520 - val_loss: 4.0754 - val_accuracy: 0.0899\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.9302 - accuracy: 0.1800 - val_loss: 4.0278 - val_accuracy: 0.1374\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.8904 - accuracy: 0.1840 - val_loss: 3.9783 - val_accuracy: 0.1381\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.9744 - accuracy: 0.2000 - val_loss: 3.9477 - val_accuracy: 0.1472\n",
            "Epoch 21/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.7164 - accuracy: 0.2080 - val_loss: 3.9124 - val_accuracy: 0.1628\n",
            "Epoch 22/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.6166 - accuracy: 0.2360 - val_loss: 3.8850 - val_accuracy: 0.1603\n",
            "Epoch 23/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.6291 - accuracy: 0.2360 - val_loss: 3.8525 - val_accuracy: 0.1827\n",
            "Epoch 24/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.5075 - accuracy: 0.2640 - val_loss: 3.8285 - val_accuracy: 0.1987\n",
            "Epoch 25/150\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3924 - accuracy: 0.2880 - val_loss: 3.7938 - val_accuracy: 0.2277\n",
            "Epoch 26/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.4104 - accuracy: 0.2800 - val_loss: 3.7563 - val_accuracy: 0.2437\n",
            "Epoch 27/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3103 - accuracy: 0.3360 - val_loss: 3.7466 - val_accuracy: 0.2455\n",
            "Epoch 28/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3367 - accuracy: 0.2880 - val_loss: 3.7213 - val_accuracy: 0.2223\n",
            "Epoch 29/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2230 - accuracy: 0.3400 - val_loss: 3.6635 - val_accuracy: 0.2342\n",
            "Epoch 30/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.0625 - accuracy: 0.3680 - val_loss: 3.6236 - val_accuracy: 0.2426\n",
            "Epoch 31/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.1582 - accuracy: 0.4000 - val_loss: 3.5800 - val_accuracy: 0.2538\n",
            "Epoch 32/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.0055 - accuracy: 0.3480 - val_loss: 3.5526 - val_accuracy: 0.2741\n",
            "Epoch 33/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.9022 - accuracy: 0.3680 - val_loss: 3.5243 - val_accuracy: 0.2926\n",
            "Epoch 34/150\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.8194 - accuracy: 0.4000 - val_loss: 3.4990 - val_accuracy: 0.2864\n",
            "Epoch 35/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.8630 - accuracy: 0.3840 - val_loss: 3.4684 - val_accuracy: 0.2991\n",
            "Epoch 36/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.8147 - accuracy: 0.3840 - val_loss: 3.3995 - val_accuracy: 0.3194\n",
            "Epoch 37/150\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.7390 - accuracy: 0.4400 - val_loss: 3.3271 - val_accuracy: 0.3412\n",
            "Epoch 38/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.7669 - accuracy: 0.4560 - val_loss: 3.3019 - val_accuracy: 0.3372\n",
            "Epoch 39/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.6015 - accuracy: 0.4920 - val_loss: 3.3046 - val_accuracy: 0.3278\n",
            "Epoch 40/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.6141 - accuracy: 0.5040 - val_loss: 3.3206 - val_accuracy: 0.3434\n",
            "Epoch 41/150\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.6031 - accuracy: 0.4600 - val_loss: 3.3310 - val_accuracy: 0.3597\n",
            "Epoch 42/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.4762 - accuracy: 0.5120 - val_loss: 3.3183 - val_accuracy: 0.3492\n",
            "Epoch 43/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.4839 - accuracy: 0.5280 - val_loss: 3.2855 - val_accuracy: 0.3347\n",
            "Epoch 44/150\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.3945 - accuracy: 0.5200 - val_loss: 3.2330 - val_accuracy: 0.3437\n",
            "Epoch 45/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.4712 - accuracy: 0.4880 - val_loss: 3.1874 - val_accuracy: 0.3542\n",
            "Epoch 46/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.4148 - accuracy: 0.5000 - val_loss: 3.1559 - val_accuracy: 0.3535\n",
            "Epoch 47/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.2608 - accuracy: 0.5840 - val_loss: 3.1332 - val_accuracy: 0.3600\n",
            "Epoch 48/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.3253 - accuracy: 0.5600 - val_loss: 3.1033 - val_accuracy: 0.3818\n",
            "Epoch 49/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.1660 - accuracy: 0.5800 - val_loss: 3.0693 - val_accuracy: 0.4184\n",
            "Epoch 50/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.2642 - accuracy: 0.5680 - val_loss: 3.0621 - val_accuracy: 0.4184\n",
            "Epoch 51/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.2063 - accuracy: 0.5840 - val_loss: 3.0466 - val_accuracy: 0.4268\n",
            "Epoch 52/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.2930 - accuracy: 0.5480 - val_loss: 2.9917 - val_accuracy: 0.4434\n",
            "Epoch 53/150\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1.1627 - accuracy: 0.6200 - val_loss: 2.9602 - val_accuracy: 0.4449\n",
            "Epoch 54/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.2093 - accuracy: 0.6240 - val_loss: 2.9510 - val_accuracy: 0.4137\n",
            "Epoch 55/150\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.1427 - accuracy: 0.6280 - val_loss: 2.9389 - val_accuracy: 0.4097\n",
            "Epoch 56/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.1046 - accuracy: 0.6360 - val_loss: 2.9235 - val_accuracy: 0.4275\n",
            "Epoch 57/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.1781 - accuracy: 0.6320 - val_loss: 2.9327 - val_accuracy: 0.4423\n",
            "Epoch 58/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.0489 - accuracy: 0.6000 - val_loss: 2.9469 - val_accuracy: 0.4362\n",
            "Epoch 59/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.0619 - accuracy: 0.6160 - val_loss: 2.9522 - val_accuracy: 0.4297\n",
            "Epoch 60/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.0661 - accuracy: 0.6240 - val_loss: 2.9064 - val_accuracy: 0.4402\n",
            "Epoch 61/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.8926 - accuracy: 0.6640 - val_loss: 2.8675 - val_accuracy: 0.4558\n",
            "Epoch 62/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.9248 - accuracy: 0.6840 - val_loss: 2.8570 - val_accuracy: 0.4550\n",
            "Epoch 63/150\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.9840 - accuracy: 0.6520 - val_loss: 2.8635 - val_accuracy: 0.4558\n",
            "Epoch 64/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.9070 - accuracy: 0.6720 - val_loss: 2.8635 - val_accuracy: 0.4598\n",
            "Epoch 65/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.9167 - accuracy: 0.7040 - val_loss: 2.8253 - val_accuracy: 0.4634\n",
            "Epoch 66/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.8911 - accuracy: 0.7520 - val_loss: 2.8111 - val_accuracy: 0.4902\n",
            "Epoch 67/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.8267 - accuracy: 0.7440 - val_loss: 2.8182 - val_accuracy: 0.4815\n",
            "Epoch 68/150\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.8670 - accuracy: 0.6880 - val_loss: 2.8280 - val_accuracy: 0.4717\n",
            "Epoch 69/150\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.8977 - accuracy: 0.7160 - val_loss: 2.8247 - val_accuracy: 0.4833\n",
            "Epoch 70/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.8080 - accuracy: 0.7120 - val_loss: 2.8050 - val_accuracy: 0.4931\n",
            "Epoch 71/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.7172 - accuracy: 0.7640 - val_loss: 2.7763 - val_accuracy: 0.5058\n",
            "Epoch 72/150\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.7795 - accuracy: 0.7400 - val_loss: 2.7519 - val_accuracy: 0.5076\n",
            "Epoch 73/150\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.8315 - accuracy: 0.7400 - val_loss: 2.7436 - val_accuracy: 0.5033\n",
            "Epoch 74/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6423 - accuracy: 0.7880 - val_loss: 2.7444 - val_accuracy: 0.4989\n",
            "Epoch 75/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6960 - accuracy: 0.7640 - val_loss: 2.7370 - val_accuracy: 0.5087\n",
            "Epoch 76/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.7124 - accuracy: 0.7840 - val_loss: 2.7364 - val_accuracy: 0.5152\n",
            "Epoch 77/150\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.6893 - accuracy: 0.7600 - val_loss: 2.7246 - val_accuracy: 0.5167\n",
            "Epoch 78/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6377 - accuracy: 0.7440 - val_loss: 2.7035 - val_accuracy: 0.5272\n",
            "Epoch 79/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.6934 - accuracy: 0.7280 - val_loss: 2.6937 - val_accuracy: 0.5236\n",
            "Epoch 80/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.5879 - accuracy: 0.7840 - val_loss: 2.7040 - val_accuracy: 0.5196\n",
            "Epoch 81/150\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.6442 - accuracy: 0.7720 - val_loss: 2.7008 - val_accuracy: 0.5247\n",
            "Epoch 82/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.5837 - accuracy: 0.7960 - val_loss: 2.6800 - val_accuracy: 0.5261\n",
            "Epoch 83/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6287 - accuracy: 0.7840 - val_loss: 2.6535 - val_accuracy: 0.5366\n",
            "Epoch 84/150\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.6275 - accuracy: 0.7960 - val_loss: 2.6434 - val_accuracy: 0.5410\n",
            "Epoch 85/150\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.5976 - accuracy: 0.7680 - val_loss: 2.6371 - val_accuracy: 0.5410\n",
            "Epoch 86/150\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6752 - accuracy: 0.7560 - val_loss: 2.6257 - val_accuracy: 0.5479\n",
            "Epoch 87/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.5815 - accuracy: 0.8280 - val_loss: 2.6317 - val_accuracy: 0.5439\n",
            "Epoch 88/150\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.5435 - accuracy: 0.8120 - val_loss: 2.6447 - val_accuracy: 0.5392\n",
            "Epoch 89/150\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.5074 - accuracy: 0.7960 - val_loss: 2.6589 - val_accuracy: 0.5359\n",
            "Epoch 90/150\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.5370 - accuracy: 0.8240 - val_loss: 2.6755 - val_accuracy: 0.5330\n",
            "Epoch 91/150\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.5069 - accuracy: 0.8120 - val_loss: 2.6900 - val_accuracy: 0.5344\n",
            "test obs. 250 accuracy 0.5304568527918782\n",
            "test obs. 250 b_accuracy 0.5287758816077469\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 4.7286 - accuracy: 0.0160 - val_loss: 4.4555 - val_accuracy: 0.0011\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 4.5951 - accuracy: 0.0120 - val_loss: 4.3438 - val_accuracy: 0.0011\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 4.4645 - accuracy: 0.0140 - val_loss: 4.3678 - val_accuracy: 0.0011\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 4.4980 - accuracy: 0.0100 - val_loss: 4.3455 - val_accuracy: 0.0094\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 4.2975 - accuracy: 0.0160 - val_loss: 4.2894 - val_accuracy: 0.0091\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 4.1832 - accuracy: 0.0340 - val_loss: 4.1592 - val_accuracy: 0.0413\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 4.0412 - accuracy: 0.0440 - val_loss: 4.0537 - val_accuracy: 0.0482\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.9743 - accuracy: 0.0340 - val_loss: 3.9660 - val_accuracy: 0.0377\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3.8481 - accuracy: 0.0640 - val_loss: 3.8600 - val_accuracy: 0.0540\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6679 - accuracy: 0.0700 - val_loss: 3.7819 - val_accuracy: 0.0827\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.5408 - accuracy: 0.0980 - val_loss: 3.7221 - val_accuracy: 0.0867\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.3986 - accuracy: 0.1300 - val_loss: 3.6412 - val_accuracy: 0.1124\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.2922 - accuracy: 0.1520 - val_loss: 3.5490 - val_accuracy: 0.1595\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.1664 - accuracy: 0.1580 - val_loss: 3.4358 - val_accuracy: 0.1983\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.0335 - accuracy: 0.2100 - val_loss: 3.3442 - val_accuracy: 0.1748\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 2.9740 - accuracy: 0.2060 - val_loss: 3.2791 - val_accuracy: 0.1661\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.8618 - accuracy: 0.1680 - val_loss: 3.1815 - val_accuracy: 0.2179\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.7431 - accuracy: 0.2180 - val_loss: 3.1354 - val_accuracy: 0.2263\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 2.7074 - accuracy: 0.2480 - val_loss: 3.0662 - val_accuracy: 0.2495\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.6734 - accuracy: 0.2320 - val_loss: 3.0117 - val_accuracy: 0.2589\n",
            "Epoch 21/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2.4776 - accuracy: 0.2560 - val_loss: 2.9547 - val_accuracy: 0.2843\n",
            "Epoch 22/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.4600 - accuracy: 0.3000 - val_loss: 2.8592 - val_accuracy: 0.3035\n",
            "Epoch 23/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2.3000 - accuracy: 0.3220 - val_loss: 2.7571 - val_accuracy: 0.3445\n",
            "Epoch 24/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.2630 - accuracy: 0.3320 - val_loss: 2.7009 - val_accuracy: 0.3510\n",
            "Epoch 25/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.1616 - accuracy: 0.3660 - val_loss: 2.6594 - val_accuracy: 0.3390\n",
            "Epoch 26/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 2.1345 - accuracy: 0.3160 - val_loss: 2.6602 - val_accuracy: 0.3361\n",
            "Epoch 27/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2.0255 - accuracy: 0.3540 - val_loss: 2.6090 - val_accuracy: 0.3354\n",
            "Epoch 28/150\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.9733 - accuracy: 0.3780 - val_loss: 2.5243 - val_accuracy: 0.3847\n",
            "Epoch 29/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.9974 - accuracy: 0.3820 - val_loss: 2.4679 - val_accuracy: 0.4025\n",
            "Epoch 30/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.8786 - accuracy: 0.4240 - val_loss: 2.4344 - val_accuracy: 0.4036\n",
            "Epoch 31/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.8575 - accuracy: 0.4020 - val_loss: 2.3705 - val_accuracy: 0.4155\n",
            "Epoch 32/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.7457 - accuracy: 0.4560 - val_loss: 2.3290 - val_accuracy: 0.4300\n",
            "Epoch 33/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.7315 - accuracy: 0.4540 - val_loss: 2.2927 - val_accuracy: 0.4318\n",
            "Epoch 34/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.6415 - accuracy: 0.4480 - val_loss: 2.2201 - val_accuracy: 0.4714\n",
            "Epoch 35/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.5534 - accuracy: 0.5140 - val_loss: 2.2003 - val_accuracy: 0.4728\n",
            "Epoch 36/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.5481 - accuracy: 0.5000 - val_loss: 2.1797 - val_accuracy: 0.4710\n",
            "Epoch 37/150\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.5690 - accuracy: 0.5000 - val_loss: 2.1256 - val_accuracy: 0.4848\n",
            "Epoch 38/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.4530 - accuracy: 0.5120 - val_loss: 2.0850 - val_accuracy: 0.5083\n",
            "Epoch 39/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.4575 - accuracy: 0.5340 - val_loss: 2.0435 - val_accuracy: 0.5163\n",
            "Epoch 40/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.4016 - accuracy: 0.5720 - val_loss: 2.0255 - val_accuracy: 0.5218\n",
            "Epoch 41/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.4853 - accuracy: 0.5400 - val_loss: 2.0197 - val_accuracy: 0.5236\n",
            "Epoch 42/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.3556 - accuracy: 0.5760 - val_loss: 2.0030 - val_accuracy: 0.5294\n",
            "Epoch 43/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.2733 - accuracy: 0.5740 - val_loss: 1.9827 - val_accuracy: 0.5315\n",
            "Epoch 44/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.2886 - accuracy: 0.5220 - val_loss: 1.9525 - val_accuracy: 0.5366\n",
            "Epoch 45/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.2305 - accuracy: 0.5720 - val_loss: 1.9175 - val_accuracy: 0.5540\n",
            "Epoch 46/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.2598 - accuracy: 0.5900 - val_loss: 1.8872 - val_accuracy: 0.5703\n",
            "Epoch 47/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1.1671 - accuracy: 0.6320 - val_loss: 1.8704 - val_accuracy: 0.5627\n",
            "Epoch 48/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.1739 - accuracy: 0.6260 - val_loss: 1.8609 - val_accuracy: 0.5493\n",
            "Epoch 49/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.1638 - accuracy: 0.6040 - val_loss: 1.8240 - val_accuracy: 0.5580\n",
            "Epoch 50/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.1180 - accuracy: 0.6460 - val_loss: 1.7950 - val_accuracy: 0.5722\n",
            "Epoch 51/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.0691 - accuracy: 0.6320 - val_loss: 1.7902 - val_accuracy: 0.5863\n",
            "Epoch 52/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.0892 - accuracy: 0.6340 - val_loss: 1.7896 - val_accuracy: 0.5841\n",
            "Epoch 53/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.0913 - accuracy: 0.6400 - val_loss: 1.7840 - val_accuracy: 0.5816\n",
            "Epoch 54/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1.0524 - accuracy: 0.6280 - val_loss: 1.7722 - val_accuracy: 0.5801\n",
            "Epoch 55/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.9953 - accuracy: 0.6640 - val_loss: 1.7462 - val_accuracy: 0.5957\n",
            "Epoch 56/150\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.9789 - accuracy: 0.6760 - val_loss: 1.7229 - val_accuracy: 0.6037\n",
            "Epoch 57/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.9785 - accuracy: 0.6800 - val_loss: 1.7077 - val_accuracy: 0.6120\n",
            "Epoch 58/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.9545 - accuracy: 0.6940 - val_loss: 1.7051 - val_accuracy: 0.6051\n",
            "Epoch 59/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.9411 - accuracy: 0.6800 - val_loss: 1.7050 - val_accuracy: 0.6055\n",
            "Epoch 60/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.9064 - accuracy: 0.6780 - val_loss: 1.6924 - val_accuracy: 0.6055\n",
            "Epoch 61/150\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.9294 - accuracy: 0.6820 - val_loss: 1.6667 - val_accuracy: 0.6106\n",
            "Epoch 62/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.8517 - accuracy: 0.7140 - val_loss: 1.6415 - val_accuracy: 0.6106\n",
            "Epoch 63/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8772 - accuracy: 0.7160 - val_loss: 1.6350 - val_accuracy: 0.6041\n",
            "Epoch 64/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8454 - accuracy: 0.6820 - val_loss: 1.6228 - val_accuracy: 0.6102\n",
            "Epoch 65/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8039 - accuracy: 0.7180 - val_loss: 1.5984 - val_accuracy: 0.6236\n",
            "Epoch 66/150\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.8123 - accuracy: 0.7220 - val_loss: 1.5949 - val_accuracy: 0.6454\n",
            "Epoch 67/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8504 - accuracy: 0.7360 - val_loss: 1.5998 - val_accuracy: 0.6461\n",
            "Epoch 68/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.8212 - accuracy: 0.7100 - val_loss: 1.5957 - val_accuracy: 0.6363\n",
            "Epoch 69/150\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.7490 - accuracy: 0.7360 - val_loss: 1.5897 - val_accuracy: 0.6436\n",
            "Epoch 70/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.7613 - accuracy: 0.7500 - val_loss: 1.5880 - val_accuracy: 0.6468\n",
            "Epoch 71/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.8126 - accuracy: 0.7500 - val_loss: 1.6094 - val_accuracy: 0.6436\n",
            "Epoch 72/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.7489 - accuracy: 0.7660 - val_loss: 1.6235 - val_accuracy: 0.6258\n",
            "Epoch 73/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6683 - accuracy: 0.7640 - val_loss: 1.6216 - val_accuracy: 0.6117\n",
            "Epoch 74/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6959 - accuracy: 0.7120 - val_loss: 1.5656 - val_accuracy: 0.6338\n",
            "Epoch 75/150\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.7041 - accuracy: 0.7780 - val_loss: 1.5433 - val_accuracy: 0.6447\n",
            "Epoch 76/150\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.7417 - accuracy: 0.7760 - val_loss: 1.5439 - val_accuracy: 0.6552\n",
            "Epoch 77/150\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6797 - accuracy: 0.7820 - val_loss: 1.5455 - val_accuracy: 0.6570\n",
            "Epoch 78/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6191 - accuracy: 0.7820 - val_loss: 1.5796 - val_accuracy: 0.6454\n",
            "Epoch 79/150\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6610 - accuracy: 0.7540 - val_loss: 1.5709 - val_accuracy: 0.6603\n",
            "Epoch 80/150\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6676 - accuracy: 0.7760 - val_loss: 1.5530 - val_accuracy: 0.6693\n",
            "test obs. 500 accuracy 0.6715010877447426\n",
            "test obs. 500 b_accuracy 0.6366273481392114\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 4.5116 - accuracy: 0.0100 - val_loss: 4.2454 - val_accuracy: 0.0025\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 4.2729 - accuracy: 0.0360 - val_loss: 4.0726 - val_accuracy: 0.0468\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 4.1348 - accuracy: 0.0620 - val_loss: 3.9495 - val_accuracy: 0.0486\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.9649 - accuracy: 0.0630 - val_loss: 3.8335 - val_accuracy: 0.0642\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 3.7828 - accuracy: 0.1010 - val_loss: 3.6856 - val_accuracy: 0.1059\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.6209 - accuracy: 0.0860 - val_loss: 3.5325 - val_accuracy: 0.0950\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.4282 - accuracy: 0.1160 - val_loss: 3.3656 - val_accuracy: 0.1769\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.3443 - accuracy: 0.1600 - val_loss: 3.2595 - val_accuracy: 0.1875\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.0880 - accuracy: 0.1790 - val_loss: 3.1015 - val_accuracy: 0.2208\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.0244 - accuracy: 0.1860 - val_loss: 2.9696 - val_accuracy: 0.2299\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.8287 - accuracy: 0.2040 - val_loss: 2.8699 - val_accuracy: 0.2951\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.6531 - accuracy: 0.2790 - val_loss: 2.7555 - val_accuracy: 0.3299\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.5142 - accuracy: 0.2770 - val_loss: 2.6354 - val_accuracy: 0.3303\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.3729 - accuracy: 0.3210 - val_loss: 2.5199 - val_accuracy: 0.3648\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.2720 - accuracy: 0.3420 - val_loss: 2.4190 - val_accuracy: 0.4039\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.1468 - accuracy: 0.3660 - val_loss: 2.3233 - val_accuracy: 0.4101\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.0779 - accuracy: 0.3890 - val_loss: 2.2111 - val_accuracy: 0.4558\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.9627 - accuracy: 0.3820 - val_loss: 2.1343 - val_accuracy: 0.4460\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.9225 - accuracy: 0.4420 - val_loss: 2.0699 - val_accuracy: 0.4822\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.8396 - accuracy: 0.4310 - val_loss: 1.9988 - val_accuracy: 0.5083\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.7096 - accuracy: 0.4560 - val_loss: 1.9568 - val_accuracy: 0.5109\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.6772 - accuracy: 0.4680 - val_loss: 1.8681 - val_accuracy: 0.5504\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.5853 - accuracy: 0.4960 - val_loss: 1.7763 - val_accuracy: 0.5801\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.5587 - accuracy: 0.5160 - val_loss: 1.7431 - val_accuracy: 0.5725\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.4748 - accuracy: 0.5140 - val_loss: 1.7063 - val_accuracy: 0.5747\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.5257 - accuracy: 0.5210 - val_loss: 1.6439 - val_accuracy: 0.5910\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.4186 - accuracy: 0.5600 - val_loss: 1.5796 - val_accuracy: 0.6149\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.3810 - accuracy: 0.5740 - val_loss: 1.5607 - val_accuracy: 0.6211\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.3319 - accuracy: 0.6030 - val_loss: 1.4948 - val_accuracy: 0.6360\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.2557 - accuracy: 0.6040 - val_loss: 1.4706 - val_accuracy: 0.6342\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.2658 - accuracy: 0.6000 - val_loss: 1.4811 - val_accuracy: 0.6342\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.2101 - accuracy: 0.5830 - val_loss: 1.4373 - val_accuracy: 0.6508\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.1491 - accuracy: 0.6360 - val_loss: 1.3925 - val_accuracy: 0.6646\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.1610 - accuracy: 0.6430 - val_loss: 1.3698 - val_accuracy: 0.6606\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.0757 - accuracy: 0.6590 - val_loss: 1.3829 - val_accuracy: 0.6613\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.0644 - accuracy: 0.6470 - val_loss: 1.3262 - val_accuracy: 0.6885\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.0266 - accuracy: 0.6600 - val_loss: 1.2910 - val_accuracy: 0.6878\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.9819 - accuracy: 0.6930 - val_loss: 1.2956 - val_accuracy: 0.6838\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.0556 - accuracy: 0.6880 - val_loss: 1.3031 - val_accuracy: 0.6820\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.9354 - accuracy: 0.6930 - val_loss: 1.2741 - val_accuracy: 0.6791\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.0082 - accuracy: 0.6550 - val_loss: 1.2497 - val_accuracy: 0.6878\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.9388 - accuracy: 0.6910 - val_loss: 1.2329 - val_accuracy: 0.6976\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.9187 - accuracy: 0.6890 - val_loss: 1.2377 - val_accuracy: 0.6918\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.8663 - accuracy: 0.7330 - val_loss: 1.2007 - val_accuracy: 0.7081\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.8171 - accuracy: 0.7520 - val_loss: 1.1643 - val_accuracy: 0.7208\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.8130 - accuracy: 0.7390 - val_loss: 1.1578 - val_accuracy: 0.7252\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.8091 - accuracy: 0.7460 - val_loss: 1.1556 - val_accuracy: 0.7353\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.7830 - accuracy: 0.7470 - val_loss: 1.1217 - val_accuracy: 0.7353\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.7159 - accuracy: 0.7660 - val_loss: 1.1170 - val_accuracy: 0.7331\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.7475 - accuracy: 0.7660 - val_loss: 1.1074 - val_accuracy: 0.7313\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.7738 - accuracy: 0.7350 - val_loss: 1.1038 - val_accuracy: 0.7476\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.7362 - accuracy: 0.7580 - val_loss: 1.1077 - val_accuracy: 0.7447\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.6730 - accuracy: 0.7750 - val_loss: 1.1088 - val_accuracy: 0.7371\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6806 - accuracy: 0.7870 - val_loss: 1.0706 - val_accuracy: 0.7531\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6794 - accuracy: 0.7740 - val_loss: 1.0653 - val_accuracy: 0.7571\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6500 - accuracy: 0.8000 - val_loss: 1.0571 - val_accuracy: 0.7531\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6021 - accuracy: 0.7890 - val_loss: 1.0719 - val_accuracy: 0.7560\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6440 - accuracy: 0.7990 - val_loss: 1.0456 - val_accuracy: 0.7759\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.5778 - accuracy: 0.8110 - val_loss: 1.0322 - val_accuracy: 0.7777\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.6217 - accuracy: 0.8070 - val_loss: 1.0299 - val_accuracy: 0.7734\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.6125 - accuracy: 0.7900 - val_loss: 1.0285 - val_accuracy: 0.7701\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5962 - accuracy: 0.8090 - val_loss: 1.0337 - val_accuracy: 0.7611\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5450 - accuracy: 0.8070 - val_loss: 1.0325 - val_accuracy: 0.7676\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5511 - accuracy: 0.8200 - val_loss: 1.0279 - val_accuracy: 0.7698\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.5414 - accuracy: 0.8380 - val_loss: 1.0285 - val_accuracy: 0.7748\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5526 - accuracy: 0.8260 - val_loss: 1.0244 - val_accuracy: 0.7796\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5240 - accuracy: 0.8430 - val_loss: 1.0136 - val_accuracy: 0.7817\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5004 - accuracy: 0.8520 - val_loss: 1.0005 - val_accuracy: 0.7883\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.5055 - accuracy: 0.8330 - val_loss: 0.9862 - val_accuracy: 0.7839\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4921 - accuracy: 0.8600 - val_loss: 0.9814 - val_accuracy: 0.7919\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4727 - accuracy: 0.8450 - val_loss: 0.9829 - val_accuracy: 0.7915\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4804 - accuracy: 0.8450 - val_loss: 0.9834 - val_accuracy: 0.7872\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4419 - accuracy: 0.8620 - val_loss: 0.9855 - val_accuracy: 0.7883\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4784 - accuracy: 0.8340 - val_loss: 0.9918 - val_accuracy: 0.7814\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4382 - accuracy: 0.8570 - val_loss: 0.9881 - val_accuracy: 0.7922\n",
            "test obs. 1000 accuracy 0.7828136330674402\n",
            "test obs. 1000 b_accuracy 0.7257023340185118\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 4.3962 - accuracy: 0.0105 - val_loss: 4.2187 - val_accuracy: 0.0334\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.2012 - accuracy: 0.0485 - val_loss: 3.9062 - val_accuracy: 0.0613\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.9395 - accuracy: 0.0870 - val_loss: 3.6179 - val_accuracy: 0.1414\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.6785 - accuracy: 0.1085 - val_loss: 3.3307 - val_accuracy: 0.1972\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.3604 - accuracy: 0.1600 - val_loss: 3.0925 - val_accuracy: 0.1991\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.0328 - accuracy: 0.1955 - val_loss: 2.7015 - val_accuracy: 0.3390\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.7246 - accuracy: 0.2640 - val_loss: 2.5332 - val_accuracy: 0.3542\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.5456 - accuracy: 0.2925 - val_loss: 2.2844 - val_accuracy: 0.4561\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.3597 - accuracy: 0.3350 - val_loss: 2.1257 - val_accuracy: 0.4779\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.2255 - accuracy: 0.3645 - val_loss: 1.9679 - val_accuracy: 0.5141\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.0002 - accuracy: 0.4200 - val_loss: 1.8033 - val_accuracy: 0.5261\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.8885 - accuracy: 0.4325 - val_loss: 1.6775 - val_accuracy: 0.5736\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.7274 - accuracy: 0.4860 - val_loss: 1.5527 - val_accuracy: 0.6298\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.6403 - accuracy: 0.5000 - val_loss: 1.4219 - val_accuracy: 0.6653\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.5659 - accuracy: 0.5285 - val_loss: 1.3958 - val_accuracy: 0.6447\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.4872 - accuracy: 0.5415 - val_loss: 1.3566 - val_accuracy: 0.6468\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.4551 - accuracy: 0.5740 - val_loss: 1.2524 - val_accuracy: 0.7121\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.3574 - accuracy: 0.5945 - val_loss: 1.1827 - val_accuracy: 0.7136\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.2656 - accuracy: 0.6140 - val_loss: 1.1130 - val_accuracy: 0.7244\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.2555 - accuracy: 0.6270 - val_loss: 1.1268 - val_accuracy: 0.7146\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.1913 - accuracy: 0.6400 - val_loss: 1.0702 - val_accuracy: 0.7516\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.1594 - accuracy: 0.6730 - val_loss: 1.0034 - val_accuracy: 0.7520\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.0696 - accuracy: 0.6655 - val_loss: 0.9731 - val_accuracy: 0.7625\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.0454 - accuracy: 0.6890 - val_loss: 0.9495 - val_accuracy: 0.7687\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.9929 - accuracy: 0.7095 - val_loss: 0.9194 - val_accuracy: 0.7759\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.9554 - accuracy: 0.7085 - val_loss: 0.8869 - val_accuracy: 0.7825\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.9110 - accuracy: 0.7035 - val_loss: 0.8531 - val_accuracy: 0.7995\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.8639 - accuracy: 0.7240 - val_loss: 0.8265 - val_accuracy: 0.7999\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.8805 - accuracy: 0.7235 - val_loss: 0.8291 - val_accuracy: 0.7879\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.8215 - accuracy: 0.7280 - val_loss: 0.7876 - val_accuracy: 0.8107\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.8269 - accuracy: 0.7425 - val_loss: 0.7868 - val_accuracy: 0.8176\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.8096 - accuracy: 0.7450 - val_loss: 0.7737 - val_accuracy: 0.8144\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.7987 - accuracy: 0.7665 - val_loss: 0.7700 - val_accuracy: 0.8082\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.7051 - accuracy: 0.7810 - val_loss: 0.7433 - val_accuracy: 0.8118\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.7255 - accuracy: 0.7740 - val_loss: 0.7366 - val_accuracy: 0.8151\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.6873 - accuracy: 0.7940 - val_loss: 0.7113 - val_accuracy: 0.8260\n",
            "Epoch 37/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.6490 - accuracy: 0.7965 - val_loss: 0.7038 - val_accuracy: 0.8212\n",
            "Epoch 38/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.6583 - accuracy: 0.7880 - val_loss: 0.6864 - val_accuracy: 0.8390\n",
            "Epoch 39/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.6454 - accuracy: 0.7825 - val_loss: 0.6843 - val_accuracy: 0.8416\n",
            "Epoch 40/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.6313 - accuracy: 0.7925 - val_loss: 0.6906 - val_accuracy: 0.8350\n",
            "Epoch 41/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.5555 - accuracy: 0.8105 - val_loss: 0.6607 - val_accuracy: 0.8466\n",
            "Epoch 42/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5679 - accuracy: 0.8285 - val_loss: 0.6503 - val_accuracy: 0.8448\n",
            "Epoch 43/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.5565 - accuracy: 0.8230 - val_loss: 0.6572 - val_accuracy: 0.8423\n",
            "Epoch 44/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5479 - accuracy: 0.8355 - val_loss: 0.6475 - val_accuracy: 0.8481\n",
            "Epoch 45/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.8365 - val_loss: 0.6383 - val_accuracy: 0.8445\n",
            "Epoch 46/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5386 - accuracy: 0.8170 - val_loss: 0.6405 - val_accuracy: 0.8336\n",
            "Epoch 47/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.5155 - accuracy: 0.8350 - val_loss: 0.6463 - val_accuracy: 0.8455\n",
            "Epoch 48/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.5128 - accuracy: 0.8350 - val_loss: 0.6281 - val_accuracy: 0.8528\n",
            "Epoch 49/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4994 - accuracy: 0.8435 - val_loss: 0.6160 - val_accuracy: 0.8561\n",
            "Epoch 50/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4701 - accuracy: 0.8600 - val_loss: 0.6077 - val_accuracy: 0.8590\n",
            "Epoch 51/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4589 - accuracy: 0.8470 - val_loss: 0.6114 - val_accuracy: 0.8513\n",
            "Epoch 52/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4405 - accuracy: 0.8580 - val_loss: 0.6003 - val_accuracy: 0.8495\n",
            "Epoch 53/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4835 - accuracy: 0.8425 - val_loss: 0.6093 - val_accuracy: 0.8586\n",
            "Epoch 54/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5102 - accuracy: 0.8485 - val_loss: 0.6227 - val_accuracy: 0.8452\n",
            "Epoch 55/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4514 - accuracy: 0.8540 - val_loss: 0.6190 - val_accuracy: 0.8445\n",
            "Epoch 56/150\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4537 - accuracy: 0.8590 - val_loss: 0.6083 - val_accuracy: 0.8564\n",
            "Epoch 57/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.4075 - accuracy: 0.8650 - val_loss: 0.5978 - val_accuracy: 0.8582\n",
            "Epoch 58/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4252 - accuracy: 0.8625 - val_loss: 0.5774 - val_accuracy: 0.8677\n",
            "Epoch 59/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3917 - accuracy: 0.8725 - val_loss: 0.5840 - val_accuracy: 0.8666\n",
            "Epoch 60/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3866 - accuracy: 0.8695 - val_loss: 0.5876 - val_accuracy: 0.8600\n",
            "Epoch 61/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.4017 - accuracy: 0.8620 - val_loss: 0.5692 - val_accuracy: 0.8706\n",
            "Epoch 62/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3729 - accuracy: 0.8795 - val_loss: 0.5694 - val_accuracy: 0.8608\n",
            "Epoch 63/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3547 - accuracy: 0.8790 - val_loss: 0.5579 - val_accuracy: 0.8655\n",
            "Epoch 64/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3361 - accuracy: 0.8865 - val_loss: 0.5687 - val_accuracy: 0.8691\n",
            "Epoch 65/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3594 - accuracy: 0.8830 - val_loss: 0.5656 - val_accuracy: 0.8691\n",
            "Epoch 66/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3585 - accuracy: 0.8775 - val_loss: 0.5630 - val_accuracy: 0.8691\n",
            "Epoch 67/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3571 - accuracy: 0.8740 - val_loss: 0.5532 - val_accuracy: 0.8680\n",
            "Epoch 68/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3475 - accuracy: 0.8920 - val_loss: 0.5600 - val_accuracy: 0.8687\n",
            "Epoch 69/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3223 - accuracy: 0.8920 - val_loss: 0.5599 - val_accuracy: 0.8756\n",
            "Epoch 70/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3104 - accuracy: 0.9030 - val_loss: 0.5510 - val_accuracy: 0.8731\n",
            "Epoch 71/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2918 - accuracy: 0.9045 - val_loss: 0.5309 - val_accuracy: 0.8753\n",
            "Epoch 72/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3026 - accuracy: 0.8970 - val_loss: 0.5361 - val_accuracy: 0.8742\n",
            "Epoch 73/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2943 - accuracy: 0.8920 - val_loss: 0.5446 - val_accuracy: 0.8753\n",
            "Epoch 74/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3116 - accuracy: 0.8985 - val_loss: 0.5620 - val_accuracy: 0.8673\n",
            "Epoch 75/150\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.3190 - accuracy: 0.8905 - val_loss: 0.5526 - val_accuracy: 0.8727\n",
            "Epoch 76/150\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.2945 - accuracy: 0.9115 - val_loss: 0.5446 - val_accuracy: 0.8716\n",
            "test obs. 2000 accuracy 0.8792603335750544\n",
            "test obs. 2000 b_accuracy 0.8213016213382975\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 4.2703 - accuracy: 0.0590 - val_loss: 3.7557 - val_accuracy: 0.1178\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 3.7336 - accuracy: 0.1106 - val_loss: 3.0921 - val_accuracy: 0.2578\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 3.1429 - accuracy: 0.2106 - val_loss: 2.6154 - val_accuracy: 0.3912\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2.6540 - accuracy: 0.2946 - val_loss: 2.1012 - val_accuracy: 0.5330\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2.2766 - accuracy: 0.3568 - val_loss: 1.7841 - val_accuracy: 0.5402\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2.0199 - accuracy: 0.4224 - val_loss: 1.5864 - val_accuracy: 0.5946\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.8250 - accuracy: 0.4836 - val_loss: 1.3840 - val_accuracy: 0.6759\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.7259 - accuracy: 0.4956 - val_loss: 1.2636 - val_accuracy: 0.7009\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1.5784 - accuracy: 0.5534 - val_loss: 1.1485 - val_accuracy: 0.7284\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.4471 - accuracy: 0.5756 - val_loss: 1.0685 - val_accuracy: 0.7466\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.3649 - accuracy: 0.6088 - val_loss: 1.0159 - val_accuracy: 0.7462\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.3652 - accuracy: 0.6142 - val_loss: 0.9655 - val_accuracy: 0.7752\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1.2090 - accuracy: 0.6566 - val_loss: 0.8803 - val_accuracy: 0.7908\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.1548 - accuracy: 0.6596 - val_loss: 0.8286 - val_accuracy: 0.7984\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.1313 - accuracy: 0.6826 - val_loss: 0.7836 - val_accuracy: 0.8046\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.0148 - accuracy: 0.6914 - val_loss: 0.7582 - val_accuracy: 0.8209\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.9448 - accuracy: 0.7224 - val_loss: 0.7242 - val_accuracy: 0.8234\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.9206 - accuracy: 0.7214 - val_loss: 0.7001 - val_accuracy: 0.8285\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.9018 - accuracy: 0.7384 - val_loss: 0.6675 - val_accuracy: 0.8459\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.8794 - accuracy: 0.7430 - val_loss: 0.6444 - val_accuracy: 0.8510\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.8188 - accuracy: 0.7570 - val_loss: 0.6403 - val_accuracy: 0.8408\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7845 - accuracy: 0.7592 - val_loss: 0.6156 - val_accuracy: 0.8608\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7277 - accuracy: 0.7782 - val_loss: 0.5972 - val_accuracy: 0.8557\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7736 - accuracy: 0.7762 - val_loss: 0.6038 - val_accuracy: 0.8568\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7180 - accuracy: 0.7884 - val_loss: 0.5836 - val_accuracy: 0.8575\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6760 - accuracy: 0.7918 - val_loss: 0.5567 - val_accuracy: 0.8655\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7668 - accuracy: 0.7886 - val_loss: 0.5552 - val_accuracy: 0.8702\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6587 - accuracy: 0.8130 - val_loss: 0.5476 - val_accuracy: 0.8658\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.7002 - accuracy: 0.8018 - val_loss: 0.5270 - val_accuracy: 0.8687\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6167 - accuracy: 0.8192 - val_loss: 0.5433 - val_accuracy: 0.8608\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5965 - accuracy: 0.8176 - val_loss: 0.5016 - val_accuracy: 0.8785\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5449 - accuracy: 0.8212 - val_loss: 0.4980 - val_accuracy: 0.8789\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5464 - accuracy: 0.8390 - val_loss: 0.4941 - val_accuracy: 0.8716\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5278 - accuracy: 0.8380 - val_loss: 0.5102 - val_accuracy: 0.8764\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5067 - accuracy: 0.8372 - val_loss: 0.4763 - val_accuracy: 0.8851\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4993 - accuracy: 0.8486 - val_loss: 0.4684 - val_accuracy: 0.8843\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4984 - accuracy: 0.8462 - val_loss: 0.4660 - val_accuracy: 0.8861\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4971 - accuracy: 0.8542 - val_loss: 0.4478 - val_accuracy: 0.8854\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4792 - accuracy: 0.8516 - val_loss: 0.4579 - val_accuracy: 0.8894\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4596 - accuracy: 0.8604 - val_loss: 0.4519 - val_accuracy: 0.8916\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4535 - accuracy: 0.8596 - val_loss: 0.4509 - val_accuracy: 0.8934\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4401 - accuracy: 0.8604 - val_loss: 0.4461 - val_accuracy: 0.8923\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4159 - accuracy: 0.8754 - val_loss: 0.4366 - val_accuracy: 0.8996\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4564 - accuracy: 0.8636 - val_loss: 0.4425 - val_accuracy: 0.9007\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4138 - accuracy: 0.8726 - val_loss: 0.4394 - val_accuracy: 0.8949\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4187 - accuracy: 0.8682 - val_loss: 0.4299 - val_accuracy: 0.9003\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4016 - accuracy: 0.8792 - val_loss: 0.4290 - val_accuracy: 0.8974\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4141 - accuracy: 0.8730 - val_loss: 0.4299 - val_accuracy: 0.8992\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3914 - accuracy: 0.8748 - val_loss: 0.4219 - val_accuracy: 0.9021\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3843 - accuracy: 0.8748 - val_loss: 0.4224 - val_accuracy: 0.9021\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3724 - accuracy: 0.8786 - val_loss: 0.4164 - val_accuracy: 0.9068\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3801 - accuracy: 0.8760 - val_loss: 0.4072 - val_accuracy: 0.9028\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3524 - accuracy: 0.8862 - val_loss: 0.4144 - val_accuracy: 0.8974\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3446 - accuracy: 0.8910 - val_loss: 0.4124 - val_accuracy: 0.9025\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3630 - accuracy: 0.8918 - val_loss: 0.4180 - val_accuracy: 0.9036\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3381 - accuracy: 0.8926 - val_loss: 0.3977 - val_accuracy: 0.9036\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.3466 - accuracy: 0.8868 - val_loss: 0.3983 - val_accuracy: 0.9057\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3195 - accuracy: 0.9008 - val_loss: 0.3937 - val_accuracy: 0.9097\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3271 - accuracy: 0.8944 - val_loss: 0.4047 - val_accuracy: 0.9075\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3056 - accuracy: 0.8978 - val_loss: 0.4043 - val_accuracy: 0.9065\n",
            "Epoch 61/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3112 - accuracy: 0.8972 - val_loss: 0.3939 - val_accuracy: 0.9094\n",
            "Epoch 62/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3237 - accuracy: 0.8884 - val_loss: 0.4023 - val_accuracy: 0.9075\n",
            "Epoch 63/150\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3019 - accuracy: 0.9028 - val_loss: 0.3942 - val_accuracy: 0.9090\n",
            "test obs. 5000 accuracy 0.916243654822335\n",
            "test obs. 5000 b_accuracy 0.8621818374884698\n",
            "Epoch 1/150\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 4.0737 - accuracy: 0.1175 - val_loss: 3.1163 - val_accuracy: 0.3216\n",
            "Epoch 2/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 3.1562 - accuracy: 0.2279 - val_loss: 2.3189 - val_accuracy: 0.4300\n",
            "Epoch 3/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 2.4462 - accuracy: 0.3365 - val_loss: 1.8053 - val_accuracy: 0.5653\n",
            "Epoch 4/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 2.0144 - accuracy: 0.4324 - val_loss: 1.4248 - val_accuracy: 0.6487\n",
            "Epoch 5/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.7019 - accuracy: 0.5017 - val_loss: 1.1501 - val_accuracy: 0.7194\n",
            "Epoch 6/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.5222 - accuracy: 0.5653 - val_loss: 1.0626 - val_accuracy: 0.7288\n",
            "Epoch 7/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.3735 - accuracy: 0.6010 - val_loss: 0.9225 - val_accuracy: 0.7716\n",
            "Epoch 8/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.2292 - accuracy: 0.6397 - val_loss: 0.8606 - val_accuracy: 0.7897\n",
            "Epoch 9/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 1.1547 - accuracy: 0.6641 - val_loss: 0.7961 - val_accuracy: 0.8064\n",
            "Epoch 10/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 1.0641 - accuracy: 0.6788 - val_loss: 0.7259 - val_accuracy: 0.8437\n",
            "Epoch 11/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9577 - accuracy: 0.7217 - val_loss: 0.6696 - val_accuracy: 0.8361\n",
            "Epoch 12/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.9574 - accuracy: 0.7143 - val_loss: 0.6232 - val_accuracy: 0.8561\n",
            "Epoch 13/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8997 - accuracy: 0.7448 - val_loss: 0.6010 - val_accuracy: 0.8662\n",
            "Epoch 14/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.8595 - accuracy: 0.7460 - val_loss: 0.5782 - val_accuracy: 0.8735\n",
            "Epoch 15/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.8166 - accuracy: 0.7661 - val_loss: 0.5356 - val_accuracy: 0.8756\n",
            "Epoch 16/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7833 - accuracy: 0.7640 - val_loss: 0.5268 - val_accuracy: 0.8782\n",
            "Epoch 17/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.7243 - accuracy: 0.7888 - val_loss: 0.5079 - val_accuracy: 0.8785\n",
            "Epoch 18/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.6827 - accuracy: 0.7953 - val_loss: 0.4992 - val_accuracy: 0.8872\n",
            "Epoch 19/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.6675 - accuracy: 0.7990 - val_loss: 0.4885 - val_accuracy: 0.8785\n",
            "Epoch 20/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6461 - accuracy: 0.8120 - val_loss: 0.4571 - val_accuracy: 0.8956\n",
            "Epoch 21/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.6091 - accuracy: 0.8217 - val_loss: 0.4504 - val_accuracy: 0.8876\n",
            "Epoch 22/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.6093 - accuracy: 0.8214 - val_loss: 0.4269 - val_accuracy: 0.8996\n",
            "Epoch 23/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5764 - accuracy: 0.8304 - val_loss: 0.4330 - val_accuracy: 0.8999\n",
            "Epoch 24/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5670 - accuracy: 0.8320 - val_loss: 0.4142 - val_accuracy: 0.8996\n",
            "Epoch 25/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5432 - accuracy: 0.8364 - val_loss: 0.4116 - val_accuracy: 0.9054\n",
            "Epoch 26/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5264 - accuracy: 0.8453 - val_loss: 0.3889 - val_accuracy: 0.9075\n",
            "Epoch 27/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5269 - accuracy: 0.8473 - val_loss: 0.3820 - val_accuracy: 0.9061\n",
            "Epoch 28/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.5166 - accuracy: 0.8435 - val_loss: 0.3805 - val_accuracy: 0.9083\n",
            "Epoch 29/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4763 - accuracy: 0.8559 - val_loss: 0.3700 - val_accuracy: 0.9072\n",
            "Epoch 30/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.5396 - accuracy: 0.8514 - val_loss: 0.3781 - val_accuracy: 0.9083\n",
            "Epoch 31/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.4662 - accuracy: 0.8644 - val_loss: 0.3575 - val_accuracy: 0.9162\n",
            "Epoch 32/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4641 - accuracy: 0.8642 - val_loss: 0.3481 - val_accuracy: 0.9191\n",
            "Epoch 33/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4559 - accuracy: 0.8700 - val_loss: 0.3570 - val_accuracy: 0.9191\n",
            "Epoch 34/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4268 - accuracy: 0.8739 - val_loss: 0.3490 - val_accuracy: 0.9184\n",
            "Epoch 35/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4115 - accuracy: 0.8749 - val_loss: 0.3520 - val_accuracy: 0.9173\n",
            "Epoch 36/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.4595 - accuracy: 0.8596 - val_loss: 0.3371 - val_accuracy: 0.9195\n",
            "Epoch 37/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3927 - accuracy: 0.8781 - val_loss: 0.3267 - val_accuracy: 0.9239\n",
            "Epoch 38/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8802 - val_loss: 0.3354 - val_accuracy: 0.9210\n",
            "Epoch 39/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3940 - accuracy: 0.8804 - val_loss: 0.3358 - val_accuracy: 0.9231\n",
            "Epoch 40/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3695 - accuracy: 0.8788 - val_loss: 0.3280 - val_accuracy: 0.9206\n",
            "Epoch 41/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3580 - accuracy: 0.8887 - val_loss: 0.3247 - val_accuracy: 0.9246\n",
            "Epoch 42/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3739 - accuracy: 0.8877 - val_loss: 0.3284 - val_accuracy: 0.9235\n",
            "Epoch 43/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3594 - accuracy: 0.8935 - val_loss: 0.3233 - val_accuracy: 0.9249\n",
            "Epoch 44/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3458 - accuracy: 0.8914 - val_loss: 0.3178 - val_accuracy: 0.9257\n",
            "Epoch 45/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3414 - accuracy: 0.8919 - val_loss: 0.3167 - val_accuracy: 0.9282\n",
            "Epoch 46/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3356 - accuracy: 0.8945 - val_loss: 0.3184 - val_accuracy: 0.9282\n",
            "Epoch 47/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3299 - accuracy: 0.8952 - val_loss: 0.3148 - val_accuracy: 0.9307\n",
            "Epoch 48/150\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3209 - accuracy: 0.8988 - val_loss: 0.3058 - val_accuracy: 0.9249\n",
            "Epoch 49/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3206 - accuracy: 0.9003 - val_loss: 0.3002 - val_accuracy: 0.9282\n",
            "Epoch 50/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2978 - accuracy: 0.9058 - val_loss: 0.2958 - val_accuracy: 0.9297\n",
            "Epoch 51/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3257 - accuracy: 0.9033 - val_loss: 0.3083 - val_accuracy: 0.9260\n",
            "Epoch 52/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3316 - accuracy: 0.9000 - val_loss: 0.3143 - val_accuracy: 0.9249\n",
            "Epoch 53/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3041 - accuracy: 0.9032 - val_loss: 0.3096 - val_accuracy: 0.9278\n",
            "Epoch 54/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3214 - accuracy: 0.8998 - val_loss: 0.3068 - val_accuracy: 0.9289\n",
            "Epoch 55/150\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2963 - accuracy: 0.9062 - val_loss: 0.3035 - val_accuracy: 0.9315\n",
            "test obs. 10000 accuracy 0.9321972443799855\n",
            "test obs. 10000 b_accuracy 0.8746855186084933\n",
            "Epoch 1/150\n",
            "59/59 [==============================] - 1s 12ms/step - loss: 3.7860 - accuracy: 0.1320 - val_loss: 2.6523 - val_accuracy: 0.3677\n",
            "Epoch 2/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 2.4328 - accuracy: 0.3492 - val_loss: 1.5960 - val_accuracy: 0.6160\n",
            "Epoch 3/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 1.7594 - accuracy: 0.5071 - val_loss: 1.1605 - val_accuracy: 0.7197\n",
            "Epoch 4/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 1.4359 - accuracy: 0.5864 - val_loss: 0.9362 - val_accuracy: 0.7603\n",
            "Epoch 5/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 1.2288 - accuracy: 0.6587 - val_loss: 0.7841 - val_accuracy: 0.8107\n",
            "Epoch 6/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 1.0493 - accuracy: 0.6979 - val_loss: 0.6660 - val_accuracy: 0.8318\n",
            "Epoch 7/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.9336 - accuracy: 0.7343 - val_loss: 0.6540 - val_accuracy: 0.8437\n",
            "Epoch 8/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.8614 - accuracy: 0.7574 - val_loss: 0.5667 - val_accuracy: 0.8600\n",
            "Epoch 9/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.7635 - accuracy: 0.7746 - val_loss: 0.5341 - val_accuracy: 0.8662\n",
            "Epoch 10/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.7452 - accuracy: 0.7877 - val_loss: 0.4778 - val_accuracy: 0.8789\n",
            "Epoch 11/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.6711 - accuracy: 0.8048 - val_loss: 0.4664 - val_accuracy: 0.8818\n",
            "Epoch 12/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.6021 - accuracy: 0.8251 - val_loss: 0.4476 - val_accuracy: 0.8923\n",
            "Epoch 13/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.5941 - accuracy: 0.8303 - val_loss: 0.4419 - val_accuracy: 0.8927\n",
            "Epoch 14/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.5558 - accuracy: 0.8343 - val_loss: 0.4031 - val_accuracy: 0.9065\n",
            "Epoch 15/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.5185 - accuracy: 0.8432 - val_loss: 0.3956 - val_accuracy: 0.9086\n",
            "Epoch 16/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.5064 - accuracy: 0.8477 - val_loss: 0.3924 - val_accuracy: 0.9061\n",
            "Epoch 17/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4891 - accuracy: 0.8595 - val_loss: 0.3816 - val_accuracy: 0.9112\n",
            "Epoch 18/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4933 - accuracy: 0.8571 - val_loss: 0.3653 - val_accuracy: 0.9115\n",
            "Epoch 19/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4448 - accuracy: 0.8659 - val_loss: 0.3595 - val_accuracy: 0.9133\n",
            "Epoch 20/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4212 - accuracy: 0.8716 - val_loss: 0.3582 - val_accuracy: 0.9213\n",
            "Epoch 21/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4292 - accuracy: 0.8717 - val_loss: 0.3617 - val_accuracy: 0.9137\n",
            "Epoch 22/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.4166 - accuracy: 0.8791 - val_loss: 0.3419 - val_accuracy: 0.9173\n",
            "Epoch 23/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3938 - accuracy: 0.8822 - val_loss: 0.3355 - val_accuracy: 0.9177\n",
            "Epoch 24/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3804 - accuracy: 0.8857 - val_loss: 0.3240 - val_accuracy: 0.9282\n",
            "Epoch 25/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3815 - accuracy: 0.8877 - val_loss: 0.3178 - val_accuracy: 0.9253\n",
            "Epoch 26/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3592 - accuracy: 0.8928 - val_loss: 0.3077 - val_accuracy: 0.9264\n",
            "Epoch 27/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3374 - accuracy: 0.8963 - val_loss: 0.3087 - val_accuracy: 0.9304\n",
            "Epoch 28/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3360 - accuracy: 0.8983 - val_loss: 0.3034 - val_accuracy: 0.9242\n",
            "Epoch 29/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3306 - accuracy: 0.8965 - val_loss: 0.3005 - val_accuracy: 0.9275\n",
            "Epoch 30/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3268 - accuracy: 0.8984 - val_loss: 0.2918 - val_accuracy: 0.9315\n",
            "Epoch 31/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3026 - accuracy: 0.9028 - val_loss: 0.3052 - val_accuracy: 0.9293\n",
            "Epoch 32/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2916 - accuracy: 0.9093 - val_loss: 0.2969 - val_accuracy: 0.9289\n",
            "Epoch 33/150\n",
            "59/59 [==============================] - 1s 10ms/step - loss: 0.3186 - accuracy: 0.9058 - val_loss: 0.2954 - val_accuracy: 0.9344\n",
            "Epoch 34/150\n",
            "59/59 [==============================] - 1s 16ms/step - loss: 0.3060 - accuracy: 0.9083 - val_loss: 0.2928 - val_accuracy: 0.9358\n",
            "Epoch 35/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2901 - accuracy: 0.9111 - val_loss: 0.2883 - val_accuracy: 0.9318\n",
            "Epoch 36/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2676 - accuracy: 0.9136 - val_loss: 0.2881 - val_accuracy: 0.9336\n",
            "Epoch 37/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.3020 - accuracy: 0.9089 - val_loss: 0.2759 - val_accuracy: 0.9318\n",
            "Epoch 38/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2580 - accuracy: 0.9169 - val_loss: 0.2907 - val_accuracy: 0.9340\n",
            "Epoch 39/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2791 - accuracy: 0.9154 - val_loss: 0.2894 - val_accuracy: 0.9347\n",
            "Epoch 40/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2529 - accuracy: 0.9203 - val_loss: 0.2799 - val_accuracy: 0.9380\n",
            "Epoch 41/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2418 - accuracy: 0.9207 - val_loss: 0.2750 - val_accuracy: 0.9333\n",
            "Epoch 42/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2507 - accuracy: 0.9212 - val_loss: 0.2774 - val_accuracy: 0.9365\n",
            "Epoch 43/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2343 - accuracy: 0.9244 - val_loss: 0.2724 - val_accuracy: 0.9355\n",
            "Epoch 44/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2448 - accuracy: 0.9240 - val_loss: 0.2791 - val_accuracy: 0.9358\n",
            "Epoch 45/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2355 - accuracy: 0.9241 - val_loss: 0.2777 - val_accuracy: 0.9362\n",
            "Epoch 46/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2312 - accuracy: 0.9239 - val_loss: 0.2691 - val_accuracy: 0.9365\n",
            "Epoch 47/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2294 - accuracy: 0.9295 - val_loss: 0.2630 - val_accuracy: 0.9380\n",
            "Epoch 48/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2246 - accuracy: 0.9249 - val_loss: 0.2632 - val_accuracy: 0.9431\n",
            "Epoch 49/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2255 - accuracy: 0.9287 - val_loss: 0.2721 - val_accuracy: 0.9376\n",
            "Epoch 50/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2078 - accuracy: 0.9329 - val_loss: 0.2715 - val_accuracy: 0.9413\n",
            "Epoch 51/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2134 - accuracy: 0.9318 - val_loss: 0.2691 - val_accuracy: 0.9373\n",
            "Epoch 52/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2080 - accuracy: 0.9299 - val_loss: 0.2505 - val_accuracy: 0.9420\n",
            "Epoch 53/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.1992 - accuracy: 0.9355 - val_loss: 0.2624 - val_accuracy: 0.9431\n",
            "Epoch 54/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2022 - accuracy: 0.9337 - val_loss: 0.2577 - val_accuracy: 0.9409\n",
            "Epoch 55/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2068 - accuracy: 0.9345 - val_loss: 0.2638 - val_accuracy: 0.9376\n",
            "Epoch 56/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2231 - accuracy: 0.9333 - val_loss: 0.2581 - val_accuracy: 0.9438\n",
            "Epoch 57/150\n",
            "59/59 [==============================] - 1s 9ms/step - loss: 0.2052 - accuracy: 0.9335 - val_loss: 0.2608 - val_accuracy: 0.9416\n",
            "test obs. 15000 accuracy 0.9528643944887599\n",
            "test obs. 15000 b_accuracy 0.9156223890936294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV-P8u5Cnt1p",
        "colab_type": "text"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcY8yFVzijpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "4ffaddf8-f6bf-44ec-9113-e63cf67711ff"
      },
      "source": [
        "for obs in [500,1000,2000,5000,10000,15000]:\n",
        "    run_RNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3520c8d55712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_enc_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_enc_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_pad_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_matrix_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight_dict_de\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-a6d15458f14f>\u001b[0m in \u001b[0;36mrun_RNN\u001b[0;34m(X_train_pad, y_train_enc, X_val_pad, y_val_enc, X_test_pad, y_test, vocab_size, embedding_matrix, class_weight_dict, no)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0membedd_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlstm_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecurrent_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecurrent_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedd_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdrop_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpred_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_layer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, kernel_regularizer=l1_l2(0.001)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Bidirectional' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3UXIengmold",
        "colab_type": "text"
      },
      "source": [
        "## Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHaqJZZ2mq__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "import os, datetime\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        " \n",
        "def run_CNN_best(X_train_pad,y_train_enc,X_val_pad,y_val_enc,X_test_pad,y_test,vocab_size,embedding_matrix,class_weight_dict):\n",
        "    \n",
        "    \n",
        "    dropout_rate= .5\n",
        "    filter_sizes = [1,2,3,4,5]\n",
        "    num_filters = 15\n",
        "\n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    x = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable = True)(input_layer)\n",
        "    x = Reshape((seq_len, embedding_dim, 1))(x)\n",
        "\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embedding_dim),\n",
        "                                      kernel_initializer='he_normal', activation='relu')(x)\n",
        "        maxpool_pool.append(MaxPool2D(pool_size=(seq_len - filter_sizes[i] + 1, 1))(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "\n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn2d = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "    #de_cnn2d.summary()\n",
        "    lr = .001\n",
        "    opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "    de_cnn2d.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = de_cnn2d.fit(x = X_train_pad, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_pad, y_val_enc), \\\n",
        "                    epochs = 100, batch_size = 256, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping,tensorboard_callback])\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test = de_cnn2d.predict(X_test_pad)\n",
        "    y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "    y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "    print('test obs.','accuracy %s' % accuracy_score(y_pred_test, y_test))\n",
        "    print('test obs.','b_accuracy %s' % balanced_accuracy_score(y_pred_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i2b-lIxm5o1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_CNN_best(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,vocab_size_de,embedding_matrix_de,class_weight_dict_de)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t6ZEVE7KRxxI"
      },
      "source": [
        "# Single Language Classifier French"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wG6eoMcYRxxY"
      },
      "source": [
        "##LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jtpfbZ1IRxxZ",
        "colab": {}
      },
      "source": [
        "stra = False\n",
        "for obs in [250,500,1000,2000,5000]:\n",
        "    tf_idf_log_reg(X_train_de,y_train_de,X_test_de,y_test_de,obs,class_weight_dict_de)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uQOx-1YTRxxf"
      },
      "source": [
        "##CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nc-BPUUHRxxj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37472edd-2f5b-47eb-f444-4c2c744f4342"
      },
      "source": [
        "for obs in [500,1000,2000,5000]:\n",
        "     run_CNN(X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,vocab_size_fr,embedding_matrix_fr,class_weight_dict_fr,obs)\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 4.3703 - accuracy: 0.0140 - val_loss: 4.1991 - val_accuracy: 0.0410\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.9923 - accuracy: 0.0400 - val_loss: 4.1825 - val_accuracy: 0.0266\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.7929 - accuracy: 0.0340 - val_loss: 4.1002 - val_accuracy: 0.0664\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 3.6397 - accuracy: 0.0540 - val_loss: 4.0258 - val_accuracy: 0.0797\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.3768 - accuracy: 0.1300 - val_loss: 3.8679 - val_accuracy: 0.2326\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 3.1458 - accuracy: 0.2140 - val_loss: 3.7470 - val_accuracy: 0.2337\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.8600 - accuracy: 0.2560 - val_loss: 3.6081 - val_accuracy: 0.2702\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.6264 - accuracy: 0.3280 - val_loss: 3.3792 - val_accuracy: 0.3942\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3796 - accuracy: 0.4320 - val_loss: 3.1483 - val_accuracy: 0.4064\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.0753 - accuracy: 0.5280 - val_loss: 2.9343 - val_accuracy: 0.4551\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.7730 - accuracy: 0.5820 - val_loss: 2.7256 - val_accuracy: 0.5083\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.5423 - accuracy: 0.6180 - val_loss: 2.5017 - val_accuracy: 0.5626\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.3902 - accuracy: 0.6780 - val_loss: 2.3074 - val_accuracy: 0.5748\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.0995 - accuracy: 0.7540 - val_loss: 2.1375 - val_accuracy: 0.5914\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.8992 - accuracy: 0.8060 - val_loss: 1.9893 - val_accuracy: 0.6168\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7820 - accuracy: 0.8160 - val_loss: 1.8638 - val_accuracy: 0.6390\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.5908 - accuracy: 0.8600 - val_loss: 1.7603 - val_accuracy: 0.6545\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.4678 - accuracy: 0.9060 - val_loss: 1.6837 - val_accuracy: 0.6656\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4130 - accuracy: 0.8900 - val_loss: 1.6283 - val_accuracy: 0.6788\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2887 - accuracy: 0.9260 - val_loss: 1.5924 - val_accuracy: 0.6888\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2681 - accuracy: 0.9320 - val_loss: 1.5751 - val_accuracy: 0.6899\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2510 - accuracy: 0.9440 - val_loss: 1.5642 - val_accuracy: 0.6910\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2203 - accuracy: 0.9360 - val_loss: 1.5536 - val_accuracy: 0.6899\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1854 - accuracy: 0.9480 - val_loss: 1.5381 - val_accuracy: 0.6966\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1138 - accuracy: 0.9660 - val_loss: 1.5277 - val_accuracy: 0.7021\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1156 - accuracy: 0.9720 - val_loss: 1.5213 - val_accuracy: 0.7043\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0980 - accuracy: 0.9700 - val_loss: 1.5194 - val_accuracy: 0.7087\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0880 - accuracy: 0.9660 - val_loss: 1.5203 - val_accuracy: 0.7087\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0698 - accuracy: 0.9780 - val_loss: 1.5277 - val_accuracy: 0.7132\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0832 - accuracy: 0.9840 - val_loss: 1.5412 - val_accuracy: 0.7087\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0827 - accuracy: 0.9700 - val_loss: 1.5574 - val_accuracy: 0.7076\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0760 - accuracy: 0.9800 - val_loss: 1.5721 - val_accuracy: 0.7021\n",
            "test obs. 500 accuracy 0.7300884955752213\n",
            "test obs. 500 b_accuracy 0.6752508557162241\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 4.5736 - accuracy: 0.0210 - val_loss: 4.2682 - val_accuracy: 0.0122\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 4.1578 - accuracy: 0.0350 - val_loss: 3.9886 - val_accuracy: 0.1229\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 3.7688 - accuracy: 0.1160 - val_loss: 3.7612 - val_accuracy: 0.2724\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.3709 - accuracy: 0.2540 - val_loss: 3.3649 - val_accuracy: 0.3588\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.8154 - accuracy: 0.3710 - val_loss: 2.9170 - val_accuracy: 0.4707\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.3555 - accuracy: 0.4690 - val_loss: 2.4873 - val_accuracy: 0.5759\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.8721 - accuracy: 0.5960 - val_loss: 2.0588 - val_accuracy: 0.6157\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.4156 - accuracy: 0.6820 - val_loss: 1.6844 - val_accuracy: 0.6755\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.0970 - accuracy: 0.7600 - val_loss: 1.4345 - val_accuracy: 0.7187\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.8207 - accuracy: 0.8010 - val_loss: 1.3201 - val_accuracy: 0.7353\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.6682 - accuracy: 0.8350 - val_loss: 1.2299 - val_accuracy: 0.7464\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.5013 - accuracy: 0.8630 - val_loss: 1.1689 - val_accuracy: 0.7464\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4275 - accuracy: 0.8790 - val_loss: 1.1188 - val_accuracy: 0.7641\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3260 - accuracy: 0.9060 - val_loss: 1.0726 - val_accuracy: 0.7674\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.2337 - accuracy: 0.9340 - val_loss: 1.0498 - val_accuracy: 0.7708\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1792 - accuracy: 0.9590 - val_loss: 1.0400 - val_accuracy: 0.7730\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1689 - accuracy: 0.9610 - val_loss: 1.0570 - val_accuracy: 0.7708\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1756 - accuracy: 0.9560 - val_loss: 1.0619 - val_accuracy: 0.7730\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.1288 - accuracy: 0.9680 - val_loss: 1.0639 - val_accuracy: 0.7719\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1052 - accuracy: 0.9680 - val_loss: 1.0702 - val_accuracy: 0.7730\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1096 - accuracy: 0.9710 - val_loss: 1.0725 - val_accuracy: 0.7697\n",
            "test obs. 1000 accuracy 0.8019911504424779\n",
            "test obs. 1000 b_accuracy 0.7215024413698192\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 4.3674 - accuracy: 0.0265 - val_loss: 4.0520 - val_accuracy: 0.1827\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3.7788 - accuracy: 0.1485 - val_loss: 3.4727 - val_accuracy: 0.3477\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.0161 - accuracy: 0.3200 - val_loss: 2.5447 - val_accuracy: 0.5615\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.1751 - accuracy: 0.5365 - val_loss: 1.6956 - val_accuracy: 0.6744\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.5265 - accuracy: 0.6545 - val_loss: 1.2309 - val_accuracy: 0.7497\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.0700 - accuracy: 0.7490 - val_loss: 1.0233 - val_accuracy: 0.7630\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7904 - accuracy: 0.7870 - val_loss: 0.8860 - val_accuracy: 0.8007\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5757 - accuracy: 0.8550 - val_loss: 0.7651 - val_accuracy: 0.8228\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4626 - accuracy: 0.8695 - val_loss: 0.7432 - val_accuracy: 0.8295\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.3476 - accuracy: 0.8990 - val_loss: 0.6809 - val_accuracy: 0.8549\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.2615 - accuracy: 0.9190 - val_loss: 0.6513 - val_accuracy: 0.8671\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.2292 - accuracy: 0.9370 - val_loss: 0.6547 - val_accuracy: 0.8583\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.1891 - accuracy: 0.9470 - val_loss: 0.6388 - val_accuracy: 0.8583\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1609 - accuracy: 0.9550 - val_loss: 0.6315 - val_accuracy: 0.8594\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.1141 - accuracy: 0.9650 - val_loss: 0.6450 - val_accuracy: 0.8605\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.1076 - accuracy: 0.9675 - val_loss: 0.6619 - val_accuracy: 0.8594\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1023 - accuracy: 0.9725 - val_loss: 0.6565 - val_accuracy: 0.8594\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0987 - accuracy: 0.9700 - val_loss: 0.6517 - val_accuracy: 0.8594\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0772 - accuracy: 0.9780 - val_loss: 0.6738 - val_accuracy: 0.8560\n",
            "test obs. 2000 accuracy 0.8539823008849557\n",
            "test obs. 2000 b_accuracy 0.7562359899673096\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 4.0598 - accuracy: 0.1306 - val_loss: 3.0057 - val_accuracy: 0.5349\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 2.3209 - accuracy: 0.5394 - val_loss: 1.2303 - val_accuracy: 0.7231\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 1.1676 - accuracy: 0.7142 - val_loss: 0.8001 - val_accuracy: 0.8106\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.7208 - accuracy: 0.8040 - val_loss: 0.5759 - val_accuracy: 0.8505\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.4944 - accuracy: 0.8642 - val_loss: 0.4742 - val_accuracy: 0.8904\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.3495 - accuracy: 0.9012 - val_loss: 0.3987 - val_accuracy: 0.9003\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.2683 - accuracy: 0.9186 - val_loss: 0.3385 - val_accuracy: 0.9158\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.2077 - accuracy: 0.9342 - val_loss: 0.3026 - val_accuracy: 0.9225\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.1641 - accuracy: 0.9456 - val_loss: 0.2915 - val_accuracy: 0.9236\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.1319 - accuracy: 0.9588 - val_loss: 0.2610 - val_accuracy: 0.9291\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.1146 - accuracy: 0.9640 - val_loss: 0.2588 - val_accuracy: 0.9424\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0969 - accuracy: 0.9684 - val_loss: 0.2486 - val_accuracy: 0.9402\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0859 - accuracy: 0.9736 - val_loss: 0.2346 - val_accuracy: 0.9435\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0756 - accuracy: 0.9776 - val_loss: 0.2506 - val_accuracy: 0.9413\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0690 - accuracy: 0.9790 - val_loss: 0.2324 - val_accuracy: 0.9491\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0630 - accuracy: 0.9792 - val_loss: 0.2320 - val_accuracy: 0.9491\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0570 - accuracy: 0.9824 - val_loss: 0.2406 - val_accuracy: 0.9480\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0558 - accuracy: 0.9824 - val_loss: 0.2404 - val_accuracy: 0.9480\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0483 - accuracy: 0.9834 - val_loss: 0.2367 - val_accuracy: 0.9546\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.2557 - val_accuracy: 0.9502\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.2656 - val_accuracy: 0.9535\n",
            "test obs. 5000 accuracy 0.9513274336283186\n",
            "test obs. 5000 b_accuracy 0.932029599813809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuMmlUmAophZ",
        "colab_type": "text"
      },
      "source": [
        "## CNN2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k3B0O9lopuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2a95a42-2ef7-45d7-ae7a-00960d918c16"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000]:\n",
        "     run_CNN2D(X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\n",
        "               vocab_size_fr,embedding_matrix_fr,class_weight_dict_fr,obs,True,True)\n"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 4.7230 - accuracy: 0.0100 - val_loss: 4.7953 - val_accuracy: 0.0033\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3.9353 - accuracy: 0.0200 - val_loss: 4.8001 - val_accuracy: 0.0078\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3.5554 - accuracy: 0.0500 - val_loss: 4.7393 - val_accuracy: 0.0133\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3.2288 - accuracy: 0.0800 - val_loss: 4.7224 - val_accuracy: 0.0565\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.8704 - accuracy: 0.3100 - val_loss: 4.7637 - val_accuracy: 0.0487\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5683 - accuracy: 0.3300 - val_loss: 4.7124 - val_accuracy: 0.0908\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2017 - accuracy: 0.5200 - val_loss: 4.6579 - val_accuracy: 0.1373\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.8484 - accuracy: 0.6100 - val_loss: 4.6143 - val_accuracy: 0.1561\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.5122 - accuracy: 0.6400 - val_loss: 4.5319 - val_accuracy: 0.2027\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.1897 - accuracy: 0.7400 - val_loss: 4.4194 - val_accuracy: 0.2536\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.9042 - accuracy: 0.8500 - val_loss: 4.3017 - val_accuracy: 0.3068\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6496 - accuracy: 0.9400 - val_loss: 4.1841 - val_accuracy: 0.3965\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4469 - accuracy: 0.9600 - val_loss: 4.0741 - val_accuracy: 0.4363\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.2953 - accuracy: 0.9900 - val_loss: 3.9997 - val_accuracy: 0.4751\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1900 - accuracy: 1.0000 - val_loss: 3.9810 - val_accuracy: 0.4873\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 4.0089 - val_accuracy: 0.4839\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 4.0624 - val_accuracy: 0.4862\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 4.1317 - val_accuracy: 0.4895\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 4.2142 - val_accuracy: 0.4950\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 4.3064 - val_accuracy: 0.4994\n",
            "test obs. 100 accuracy 0.48783185840707965\n",
            "test obs. 100 b_accuracy 0.47106011857479535\n",
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 4.5732 - accuracy: 0.0040 - val_loss: 4.6696 - val_accuracy: 0.0177\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3.9207 - accuracy: 0.0320 - val_loss: 4.6324 - val_accuracy: 0.0210\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.6417 - accuracy: 0.0560 - val_loss: 4.6115 - val_accuracy: 0.0122\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3.4515 - accuracy: 0.0480 - val_loss: 4.3497 - val_accuracy: 0.0620\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3.1783 - accuracy: 0.1960 - val_loss: 4.0939 - val_accuracy: 0.1063\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.8966 - accuracy: 0.3040 - val_loss: 3.9038 - val_accuracy: 0.2060\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.6295 - accuracy: 0.5200 - val_loss: 3.7734 - val_accuracy: 0.3178\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3526 - accuracy: 0.6880 - val_loss: 3.6659 - val_accuracy: 0.3710\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.0623 - accuracy: 0.7480 - val_loss: 3.5620 - val_accuracy: 0.3876\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.7715 - accuracy: 0.7520 - val_loss: 3.4426 - val_accuracy: 0.3920\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.4888 - accuracy: 0.7760 - val_loss: 3.2826 - val_accuracy: 0.4252\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.2094 - accuracy: 0.8440 - val_loss: 3.0928 - val_accuracy: 0.4740\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.9540 - accuracy: 0.8800 - val_loss: 2.8792 - val_accuracy: 0.5194\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.7262 - accuracy: 0.9160 - val_loss: 2.6626 - val_accuracy: 0.5725\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5334 - accuracy: 0.9320 - val_loss: 2.4731 - val_accuracy: 0.6002\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3784 - accuracy: 0.9640 - val_loss: 2.3339 - val_accuracy: 0.6080\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.2641 - accuracy: 0.9720 - val_loss: 2.2500 - val_accuracy: 0.6146\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1826 - accuracy: 0.9760 - val_loss: 2.2107 - val_accuracy: 0.6157\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1290 - accuracy: 0.9840 - val_loss: 2.1998 - val_accuracy: 0.6213\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0900 - accuracy: 0.9800 - val_loss: 2.2034 - val_accuracy: 0.6224\n",
            "Epoch 21/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0637 - accuracy: 0.9840 - val_loss: 2.2145 - val_accuracy: 0.6268\n",
            "Epoch 22/150\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0456 - accuracy: 0.9880 - val_loss: 2.2305 - val_accuracy: 0.6257\n",
            "Epoch 23/150\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0320 - accuracy: 0.9880 - val_loss: 2.2516 - val_accuracy: 0.6213\n",
            "Epoch 24/150\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0235 - accuracy: 0.9960 - val_loss: 2.2773 - val_accuracy: 0.6246\n",
            "test obs. 250 accuracy 0.6150442477876106\n",
            "test obs. 250 b_accuracy 0.6402438916498115\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 4.7019 - accuracy: 0.0080 - val_loss: 4.3311 - val_accuracy: 0.0476\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 4.0871 - accuracy: 0.0520 - val_loss: 4.0823 - val_accuracy: 0.0819\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.7048 - accuracy: 0.1960 - val_loss: 3.8921 - val_accuracy: 0.2071\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 3.3502 - accuracy: 0.3960 - val_loss: 3.6633 - val_accuracy: 0.2558\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.8626 - accuracy: 0.4940 - val_loss: 3.3985 - val_accuracy: 0.3444\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.3663 - accuracy: 0.6260 - val_loss: 3.1034 - val_accuracy: 0.4408\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.8772 - accuracy: 0.7280 - val_loss: 2.6819 - val_accuracy: 0.5482\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.3871 - accuracy: 0.8080 - val_loss: 2.2415 - val_accuracy: 0.5991\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.9616 - accuracy: 0.8720 - val_loss: 1.9085 - val_accuracy: 0.6312\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.6535 - accuracy: 0.9160 - val_loss: 1.6881 - val_accuracy: 0.6611\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.4182 - accuracy: 0.9320 - val_loss: 1.5313 - val_accuracy: 0.6877\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2720 - accuracy: 0.9460 - val_loss: 1.4577 - val_accuracy: 0.6932\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1722 - accuracy: 0.9640 - val_loss: 1.4154 - val_accuracy: 0.6966\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1080 - accuracy: 0.9740 - val_loss: 1.3889 - val_accuracy: 0.7054\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0665 - accuracy: 0.9860 - val_loss: 1.3859 - val_accuracy: 0.7121\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0411 - accuracy: 0.9900 - val_loss: 1.3978 - val_accuracy: 0.7132\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 1.4193 - val_accuracy: 0.7154\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0178 - accuracy: 0.9960 - val_loss: 1.4373 - val_accuracy: 0.7132\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.4562 - val_accuracy: 0.7087\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4762 - val_accuracy: 0.7099\n",
            "test obs. 500 accuracy 0.6913716814159292\n",
            "test obs. 500 b_accuracy 0.668142410992012\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 4.5910 - accuracy: 0.0170 - val_loss: 4.2009 - val_accuracy: 0.0609\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 3.8770 - accuracy: 0.1270 - val_loss: 3.6920 - val_accuracy: 0.3156\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 3.1429 - accuracy: 0.5070 - val_loss: 2.9785 - val_accuracy: 0.5903\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.3044 - accuracy: 0.7310 - val_loss: 2.2778 - val_accuracy: 0.6423\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.4340 - accuracy: 0.7960 - val_loss: 1.6424 - val_accuracy: 0.6788\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.8065 - accuracy: 0.8480 - val_loss: 1.2290 - val_accuracy: 0.7298\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4643 - accuracy: 0.8960 - val_loss: 1.0836 - val_accuracy: 0.7386\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.2709 - accuracy: 0.9270 - val_loss: 0.9826 - val_accuracy: 0.7586\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.1550 - accuracy: 0.9530 - val_loss: 0.9240 - val_accuracy: 0.7796\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0892 - accuracy: 0.9750 - val_loss: 0.9330 - val_accuracy: 0.7940\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.0523 - accuracy: 0.9850 - val_loss: 0.9161 - val_accuracy: 0.7940\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.0311 - accuracy: 0.9920 - val_loss: 0.9055 - val_accuracy: 0.7951\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.9085 - val_accuracy: 0.7885\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.9180 - val_accuracy: 0.7996\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.9334 - val_accuracy: 0.7996\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.9453 - val_accuracy: 0.7962\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9433 - val_accuracy: 0.7907\n",
            "test obs. 1000 accuracy 0.793141592920354\n",
            "test obs. 1000 b_accuracy 0.7567821131493643\n",
            "Epoch 1/150\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 4.4361 - accuracy: 0.0640 - val_loss: 3.7528 - val_accuracy: 0.2691\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.2555 - accuracy: 0.4035 - val_loss: 2.4478 - val_accuracy: 0.6080\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.7432 - accuracy: 0.7450 - val_loss: 1.2661 - val_accuracy: 0.7409\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.7932 - accuracy: 0.8250 - val_loss: 0.9052 - val_accuracy: 0.7841\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.4048 - accuracy: 0.8835 - val_loss: 0.7711 - val_accuracy: 0.8062\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.2052 - accuracy: 0.9315 - val_loss: 0.6784 - val_accuracy: 0.8328\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0986 - accuracy: 0.9730 - val_loss: 0.6642 - val_accuracy: 0.8461\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0571 - accuracy: 0.9855 - val_loss: 0.6486 - val_accuracy: 0.8450\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.6615 - val_accuracy: 0.8472\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0227 - accuracy: 0.9950 - val_loss: 0.6478 - val_accuracy: 0.8439\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.6510 - val_accuracy: 0.8494\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.6580 - val_accuracy: 0.8549\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.6642 - val_accuracy: 0.8505\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.6691 - val_accuracy: 0.8527\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.6759 - val_accuracy: 0.8527\n",
            "test obs. 2000 accuracy 0.8573008849557522\n",
            "test obs. 2000 b_accuracy 0.8193105575289842\n",
            "Epoch 1/150\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 3.5586 - accuracy: 0.3208 - val_loss: 1.7047 - val_accuracy: 0.7010\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.9948 - accuracy: 0.7738 - val_loss: 0.7467 - val_accuracy: 0.8239\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.3657 - accuracy: 0.8888 - val_loss: 0.4598 - val_accuracy: 0.8660\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.1418 - accuracy: 0.9518 - val_loss: 0.3308 - val_accuracy: 0.9092\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0668 - accuracy: 0.9738 - val_loss: 0.2547 - val_accuracy: 0.9369\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0365 - accuracy: 0.9848 - val_loss: 0.2008 - val_accuracy: 0.9491\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0217 - accuracy: 0.9902 - val_loss: 0.2073 - val_accuracy: 0.9557\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.1930 - val_accuracy: 0.9568\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.1950 - val_accuracy: 0.9579\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0092 - accuracy: 0.9962 - val_loss: 0.1902 - val_accuracy: 0.9590\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1887 - val_accuracy: 0.9601\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.1908 - val_accuracy: 0.9612\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1858 - val_accuracy: 0.9635\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.1894 - val_accuracy: 0.9635\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.1888 - val_accuracy: 0.9646\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.1897 - val_accuracy: 0.9623\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1910 - val_accuracy: 0.9657\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.1914 - val_accuracy: 0.9657\n",
            "test obs. 5000 accuracy 0.9469026548672567\n",
            "test obs. 5000 b_accuracy 0.931342363563024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhSLeKhZSyL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "f9e76107-2df1-445a-8764-9aa999dc1af3"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000]:\n",
        "     run_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n",
        "               vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs,False,False)\n"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-249-b85ec58890c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m      run_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n\u001b[0;32m----> 3\u001b[0;31m                vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs,False,False,0.4,0.03)\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: run_CNN2D() takes from 10 to 12 positional arguments but 14 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ak041rTCRxxl"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NWAf2EVxRxxn",
        "colab": {}
      },
      "source": [
        "for obs in [500,1000,2000,5000]:\n",
        "     run_RNN(X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,vocab_size_fr,embedding_matrix_fr,class_weight_dict_fr,obs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-j02O7MAFCg",
        "colab_type": "text"
      },
      "source": [
        "## Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzOVIfJ4ek88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_CNN2D(X_train_pad,y_train_enc,X_val_pad,y_val_enc,X_test_pad,y_test,\n",
        "              vocab_size,embedding_matrix,class_weight_dict,no,max=True,emb_train=False):\n",
        "    \n",
        "    dropout_rate= .3\n",
        "    filter_sizes = [1,2,5]\n",
        "    num_filters = 50\n",
        "\n",
        "\n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    x = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable = emb_train)(input_layer)\n",
        "    x = Reshape((seq_len, embedding_dim, 1))(x)\n",
        "\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embedding_dim),\n",
        "                                      kernel_initializer='he_normal', activation='relu')(x)\n",
        "        drop_layer = Dropout(.1)(conv)\n",
        "        if max:                              \n",
        "            maxpool_pool.append(MaxPool2D(pool_size=(seq_len - filter_sizes[i] + 1, 1))(drop_layer))\n",
        "        else:\n",
        "            maxpool_pool.append(AvgPool2D(pool_size=(seq_len - filter_sizes[i] + 1, 1))(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "\n",
        "    #conv_layer = Conv2D(filters=100,   kernel_size=(5,300),   padding='same',  activation='relu', strides=1,name='convolution')(x)\n",
        "    #pool_layer = MaxPool2D(pool_size = (35,1),name='max_pooling')(conv_layer)\n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn2d = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "    #de_cnn2d.summary()\n",
        "    lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/150)\n",
        "\n",
        "    de_cnn2d.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = de_cnn2d.fit(x = X_train_pad[:no], y = y_train_enc[:no],\\\n",
        "                    validation_data = (X_val_pad, y_val_enc), \\\n",
        "                    epochs = 150, batch_size = 32, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test = de_cnn2d.predict(X_test_pad)\n",
        "    y_pred_arg = y_pred_test.argmax(axis=1)\n",
        "    y_pred_test= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "    print('test obs.',no,'accuracy %s' % accuracy_score(y_pred_test, y_test))\n",
        "    print('test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test, y_test))"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM5trXPSDTQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90f4ca35-2aff-4735-d465-11e8f17dc3a1"
      },
      "source": [
        "run_CNN2D(X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\n",
        "          vocab_size_fr,embedding_matrix_fr,class_weight_dict_fr,5000)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 3.3416 - accuracy: 0.2846 - val_loss: 1.7709 - val_accuracy: 0.5792\n",
            "Epoch 2/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.3799 - accuracy: 0.6500 - val_loss: 1.0019 - val_accuracy: 0.7730\n",
            "Epoch 3/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.8595 - accuracy: 0.7476 - val_loss: 0.7785 - val_accuracy: 0.7929\n",
            "Epoch 4/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.6339 - accuracy: 0.7932 - val_loss: 0.6768 - val_accuracy: 0.8195\n",
            "Epoch 5/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4877 - accuracy: 0.8322 - val_loss: 0.5959 - val_accuracy: 0.8439\n",
            "Epoch 6/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3906 - accuracy: 0.8588 - val_loss: 0.5564 - val_accuracy: 0.8472\n",
            "Epoch 7/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8792 - val_loss: 0.4905 - val_accuracy: 0.8671\n",
            "Epoch 8/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2761 - accuracy: 0.8928 - val_loss: 0.4370 - val_accuracy: 0.8826\n",
            "Epoch 9/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2231 - accuracy: 0.9090 - val_loss: 0.4139 - val_accuracy: 0.8970\n",
            "Epoch 10/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.9182 - val_loss: 0.3868 - val_accuracy: 0.8937\n",
            "Epoch 11/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1818 - accuracy: 0.9260 - val_loss: 0.3653 - val_accuracy: 0.9092\n",
            "Epoch 12/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1578 - accuracy: 0.9308 - val_loss: 0.3195 - val_accuracy: 0.9247\n",
            "Epoch 13/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1454 - accuracy: 0.9360 - val_loss: 0.3461 - val_accuracy: 0.9147\n",
            "Epoch 14/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1451 - accuracy: 0.9336 - val_loss: 0.3317 - val_accuracy: 0.9192\n",
            "Epoch 15/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1227 - accuracy: 0.9428 - val_loss: 0.3194 - val_accuracy: 0.9236\n",
            "Epoch 16/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1133 - accuracy: 0.9468 - val_loss: 0.3040 - val_accuracy: 0.9336\n",
            "Epoch 17/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9524 - val_loss: 0.3126 - val_accuracy: 0.9291\n",
            "Epoch 18/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9590 - val_loss: 0.2939 - val_accuracy: 0.9402\n",
            "Epoch 19/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0839 - accuracy: 0.9656 - val_loss: 0.2972 - val_accuracy: 0.9424\n",
            "Epoch 20/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9570 - val_loss: 0.3166 - val_accuracy: 0.9291\n",
            "Epoch 21/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9652 - val_loss: 0.2854 - val_accuracy: 0.9446\n",
            "Epoch 22/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9626 - val_loss: 0.3136 - val_accuracy: 0.9302\n",
            "Epoch 23/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9660 - val_loss: 0.3150 - val_accuracy: 0.9380\n",
            "Epoch 24/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0673 - accuracy: 0.9686 - val_loss: 0.3086 - val_accuracy: 0.9424\n",
            "Epoch 25/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0542 - accuracy: 0.9734 - val_loss: 0.2800 - val_accuracy: 0.9424\n",
            "Epoch 26/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0573 - accuracy: 0.9762 - val_loss: 0.2936 - val_accuracy: 0.9480\n",
            "Epoch 27/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0652 - accuracy: 0.9696 - val_loss: 0.2847 - val_accuracy: 0.9491\n",
            "Epoch 28/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0482 - accuracy: 0.9754 - val_loss: 0.3092 - val_accuracy: 0.9480\n",
            "Epoch 29/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0539 - accuracy: 0.9750 - val_loss: 0.3025 - val_accuracy: 0.9491\n",
            "Epoch 30/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0659 - accuracy: 0.9728 - val_loss: 0.2782 - val_accuracy: 0.9435\n",
            "Epoch 31/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9780 - val_loss: 0.2704 - val_accuracy: 0.9468\n",
            "Epoch 32/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0480 - accuracy: 0.9752 - val_loss: 0.2714 - val_accuracy: 0.9568\n",
            "Epoch 33/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0410 - accuracy: 0.9796 - val_loss: 0.3126 - val_accuracy: 0.9413\n",
            "Epoch 34/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0439 - accuracy: 0.9788 - val_loss: 0.2689 - val_accuracy: 0.9557\n",
            "Epoch 35/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0547 - accuracy: 0.9754 - val_loss: 0.2776 - val_accuracy: 0.9557\n",
            "Epoch 36/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0483 - accuracy: 0.9748 - val_loss: 0.2811 - val_accuracy: 0.9513\n",
            "Epoch 37/150\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.0474 - accuracy: 0.9810 - val_loss: 0.3122 - val_accuracy: 0.9491\n",
            "Epoch 38/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9798 - val_loss: 0.3051 - val_accuracy: 0.9457\n",
            "Epoch 39/150\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.0415 - accuracy: 0.9808 - val_loss: 0.3002 - val_accuracy: 0.9524\n",
            "test obs. 5000 accuracy 0.9358407079646017\n",
            "test obs. 5000 b_accuracy 0.926155094870007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6K49N-YR5bA",
        "colab_type": "text"
      },
      "source": [
        "# Multilingual Transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTxZorK9mM3F",
        "colab_type": "text"
      },
      "source": [
        "load embedings  \n",
        "we only load a \"slim\" version of the embeddings, which are a subset of the vocab (less than 5%) the time loading the embeddings decreases from 15 min to 7 sec and colab is capable of loading more than two languages (embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjj7J65SZxsE",
        "colab_type": "text"
      },
      "source": [
        "### Co2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvdEBWzmZ2wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install experiment-impact-tracker\n",
        "#!mkdir logs\n",
        "#from experiment_impact_tracker.compute_tracker import ImpactTracker\n",
        "#tracker = ImpactTracker('logs')\n",
        "#tracker.launch_impact_monitor()\n",
        "#info = tracker.get_latest_info_and_check_for_errors()\n",
        "#!ls logs/impacttracker\n",
        "#!cat logs/impacttracker/impact_tracker_log.log\n",
        "#!wget 'https://raw.githubusercontent.com/ELehmann91/Thesis_Multilingual_Transferlearning/master/data/model.json'\n",
        "!create-compute-appendix logs/ --site_spec model.json --output_dir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RffXXZigrgGL",
        "colab_type": "text"
      },
      "source": [
        "### LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pATmz_dn5Sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(X_train_emb_de,axis=1).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFXurlup_V_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_idf_log_reg(X_train,y_train,X_test,y_test,no):\n",
        "    X_train_vec = np.mean(X_train[:no],axis=1)\n",
        "    y_train = y_train[:no]\n",
        "    X_test_vec = np.mean(X_test,axis=1)\n",
        "\n",
        "    logreg = LogisticRegression(C=0.9,max_iter=100, solver='saga',penalty='elasticnet',l1_ratio=.1)\n",
        "    logreg.fit(X_train_vec, y_train)\n",
        "\n",
        "    y_pred_train = logreg.predict(X_train_vec)\n",
        "    y_pred_test = logreg.predict(X_test_vec)\n",
        "\n",
        "    print('train obs.',no,'accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
        "    print('train obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_train, y_train))\n",
        "    print('test obs.',no,'accuracy %s' % accuracy_score(y_pred_test, y_test))\n",
        "    print('test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test, y_test))\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTZdxxjho_eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf_log_reg(X_train_emb_de,y_train_de,X_test_emb_fr,y_test_fr,30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSKd2GyTQsEC",
        "colab_type": "text"
      },
      "source": [
        "## CNN 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zGvt_MZUHXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee4ac15d-5362-4251-8063-19f063865de5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Bidirectional,LSTM, GlobalAveragePooling1D, Concatenate,Conv1D,BatchNormalization,Add,Masking,GlobalMaxPooling1D,LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.regularizers import l1,l2\n",
        "dropout_rate=.1\n",
        "\n",
        "input_layer = Input(shape = (seq_len,embedding_dim,), name='text_input')\n",
        "pool_layer = GlobalAveragePooling1D(name='avg_pooling')(input_layer)\n",
        "#dens_layer = Dense(155, activation='relu',name='dense150')(pool_layer)\n",
        "drop_layer = Dropout(dropout_rate,name='drop')(pool_layer)\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_avg_pool = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "de_avg_pool.summary()\n",
        "lr = .005\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "de_avg_pool.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "hist = de_avg_pool.fit(x = X_train_emb_de, y = y_train_enc_de,\\\n",
        "                validation_data = (X_val_emb_de, y_val_enc_de), \\\n",
        "                epochs = 100, batch_size = 256, shuffle = True, \\\n",
        "                class_weight = class_weight_dict_de, \\\n",
        "                callbacks = [early_stopping])"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_57\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 39, 300)]         0         \n",
            "_________________________________________________________________\n",
            "avg_pooling (GlobalAveragePo (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "output_de (Dense)            (None, 74)                22274     \n",
            "=================================================================\n",
            "Total params: 22,274\n",
            "Trainable params: 22,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "65/65 [==============================] - 1s 10ms/step - loss: 4.2168 - accuracy: 0.1957 - val_loss: 4.0281 - val_accuracy: 0.4039\n",
            "Epoch 2/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 4.0338 - accuracy: 0.4711 - val_loss: 3.8140 - val_accuracy: 0.5442\n",
            "Epoch 3/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 3.8682 - accuracy: 0.5105 - val_loss: 3.6378 - val_accuracy: 0.5874\n",
            "Epoch 4/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 3.7167 - accuracy: 0.6078 - val_loss: 3.4744 - val_accuracy: 0.6048\n",
            "Epoch 5/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 3.5755 - accuracy: 0.5986 - val_loss: 3.3324 - val_accuracy: 0.6160\n",
            "Epoch 6/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 3.4470 - accuracy: 0.6065 - val_loss: 3.2025 - val_accuracy: 0.6349\n",
            "Epoch 7/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 3.3262 - accuracy: 0.6352 - val_loss: 3.0869 - val_accuracy: 0.6588\n",
            "Epoch 8/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 3.2128 - accuracy: 0.6392 - val_loss: 2.9765 - val_accuracy: 0.6570\n",
            "Epoch 9/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 3.1056 - accuracy: 0.6543 - val_loss: 2.8731 - val_accuracy: 0.6838\n",
            "Epoch 10/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 3.0065 - accuracy: 0.6654 - val_loss: 2.7765 - val_accuracy: 0.6965\n",
            "Epoch 11/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.9128 - accuracy: 0.6755 - val_loss: 2.6922 - val_accuracy: 0.6965\n",
            "Epoch 12/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.8237 - accuracy: 0.6900 - val_loss: 2.6107 - val_accuracy: 0.7067\n",
            "Epoch 13/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.7393 - accuracy: 0.6942 - val_loss: 2.5396 - val_accuracy: 0.7049\n",
            "Epoch 14/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.6616 - accuracy: 0.7022 - val_loss: 2.4616 - val_accuracy: 0.7219\n",
            "Epoch 15/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.5882 - accuracy: 0.7113 - val_loss: 2.3958 - val_accuracy: 0.7219\n",
            "Epoch 16/100\n",
            "65/65 [==============================] - 1s 10ms/step - loss: 2.5173 - accuracy: 0.7204 - val_loss: 2.3306 - val_accuracy: 0.7335\n",
            "Epoch 17/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.4489 - accuracy: 0.7271 - val_loss: 2.2699 - val_accuracy: 0.7353\n",
            "Epoch 18/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.3876 - accuracy: 0.7321 - val_loss: 2.2196 - val_accuracy: 0.7426\n",
            "Epoch 19/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.3285 - accuracy: 0.7439 - val_loss: 2.1585 - val_accuracy: 0.7440\n",
            "Epoch 20/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.2698 - accuracy: 0.7392 - val_loss: 2.1050 - val_accuracy: 0.7491\n",
            "Epoch 21/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.2183 - accuracy: 0.7464 - val_loss: 2.0526 - val_accuracy: 0.7563\n",
            "Epoch 22/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.1673 - accuracy: 0.7524 - val_loss: 2.0048 - val_accuracy: 0.7621\n",
            "Epoch 23/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.1193 - accuracy: 0.7580 - val_loss: 1.9640 - val_accuracy: 0.7672\n",
            "Epoch 24/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.0698 - accuracy: 0.7548 - val_loss: 1.9228 - val_accuracy: 0.7705\n",
            "Epoch 25/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 2.0272 - accuracy: 0.7612 - val_loss: 1.8792 - val_accuracy: 0.7723\n",
            "Epoch 26/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.9838 - accuracy: 0.7694 - val_loss: 1.8410 - val_accuracy: 0.7781\n",
            "Epoch 27/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.9458 - accuracy: 0.7699 - val_loss: 1.8058 - val_accuracy: 0.7825\n",
            "Epoch 28/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.9049 - accuracy: 0.7709 - val_loss: 1.7708 - val_accuracy: 0.7828\n",
            "Epoch 29/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.8695 - accuracy: 0.7773 - val_loss: 1.7343 - val_accuracy: 0.7864\n",
            "Epoch 30/100\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 1.8333 - accuracy: 0.7831 - val_loss: 1.7034 - val_accuracy: 0.7897\n",
            "Epoch 31/100\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 1.7980 - accuracy: 0.7831 - val_loss: 1.6722 - val_accuracy: 0.7893\n",
            "Epoch 32/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.7663 - accuracy: 0.7841 - val_loss: 1.6415 - val_accuracy: 0.7966\n",
            "Epoch 33/100\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 1.7358 - accuracy: 0.7920 - val_loss: 1.6126 - val_accuracy: 0.7977\n",
            "Epoch 34/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.7063 - accuracy: 0.7885 - val_loss: 1.5844 - val_accuracy: 0.8013\n",
            "Epoch 35/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.6731 - accuracy: 0.7938 - val_loss: 1.5543 - val_accuracy: 0.8046\n",
            "Epoch 36/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.6456 - accuracy: 0.8000 - val_loss: 1.5301 - val_accuracy: 0.8024\n",
            "Epoch 37/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.6195 - accuracy: 0.7983 - val_loss: 1.5064 - val_accuracy: 0.8046\n",
            "Epoch 38/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.5941 - accuracy: 0.8022 - val_loss: 1.4811 - val_accuracy: 0.8046\n",
            "Epoch 39/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.5691 - accuracy: 0.8021 - val_loss: 1.4578 - val_accuracy: 0.8049\n",
            "Epoch 40/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.5461 - accuracy: 0.8049 - val_loss: 1.4357 - val_accuracy: 0.8060\n",
            "Epoch 41/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.5190 - accuracy: 0.8018 - val_loss: 1.4127 - val_accuracy: 0.8093\n",
            "Epoch 42/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.4979 - accuracy: 0.8077 - val_loss: 1.3936 - val_accuracy: 0.8140\n",
            "Epoch 43/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.4789 - accuracy: 0.8130 - val_loss: 1.3754 - val_accuracy: 0.8136\n",
            "Epoch 44/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.4554 - accuracy: 0.8119 - val_loss: 1.3528 - val_accuracy: 0.8140\n",
            "Epoch 45/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.4351 - accuracy: 0.8120 - val_loss: 1.3321 - val_accuracy: 0.8162\n",
            "Epoch 46/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.4178 - accuracy: 0.8127 - val_loss: 1.3139 - val_accuracy: 0.8198\n",
            "Epoch 47/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.3984 - accuracy: 0.8153 - val_loss: 1.3000 - val_accuracy: 0.8205\n",
            "Epoch 48/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.3786 - accuracy: 0.8179 - val_loss: 1.2801 - val_accuracy: 0.8205\n",
            "Epoch 49/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.3598 - accuracy: 0.8197 - val_loss: 1.2625 - val_accuracy: 0.8212\n",
            "Epoch 50/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.3426 - accuracy: 0.8191 - val_loss: 1.2466 - val_accuracy: 0.8238\n",
            "Epoch 51/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.3270 - accuracy: 0.8211 - val_loss: 1.2300 - val_accuracy: 0.8263\n",
            "Epoch 52/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.3099 - accuracy: 0.8234 - val_loss: 1.2160 - val_accuracy: 0.8249\n",
            "Epoch 53/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.2934 - accuracy: 0.8235 - val_loss: 1.2004 - val_accuracy: 0.8278\n",
            "Epoch 54/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.2768 - accuracy: 0.8253 - val_loss: 1.1844 - val_accuracy: 0.8307\n",
            "Epoch 55/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.2641 - accuracy: 0.8243 - val_loss: 1.1682 - val_accuracy: 0.8318\n",
            "Epoch 56/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.2501 - accuracy: 0.8281 - val_loss: 1.1577 - val_accuracy: 0.8321\n",
            "Epoch 57/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.2352 - accuracy: 0.8295 - val_loss: 1.1411 - val_accuracy: 0.8332\n",
            "Epoch 58/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.2201 - accuracy: 0.8278 - val_loss: 1.1314 - val_accuracy: 0.8321\n",
            "Epoch 59/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.2075 - accuracy: 0.8287 - val_loss: 1.1179 - val_accuracy: 0.8328\n",
            "Epoch 60/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1962 - accuracy: 0.8329 - val_loss: 1.1052 - val_accuracy: 0.8379\n",
            "Epoch 61/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1824 - accuracy: 0.8335 - val_loss: 1.0942 - val_accuracy: 0.8365\n",
            "Epoch 62/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1698 - accuracy: 0.8340 - val_loss: 1.0822 - val_accuracy: 0.8376\n",
            "Epoch 63/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1564 - accuracy: 0.8355 - val_loss: 1.0703 - val_accuracy: 0.8394\n",
            "Epoch 64/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1448 - accuracy: 0.8376 - val_loss: 1.0605 - val_accuracy: 0.8390\n",
            "Epoch 65/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1304 - accuracy: 0.8377 - val_loss: 1.0505 - val_accuracy: 0.8387\n",
            "Epoch 66/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1233 - accuracy: 0.8373 - val_loss: 1.0388 - val_accuracy: 0.8408\n",
            "Epoch 67/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1108 - accuracy: 0.8423 - val_loss: 1.0276 - val_accuracy: 0.8430\n",
            "Epoch 68/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.1029 - accuracy: 0.8406 - val_loss: 1.0186 - val_accuracy: 0.8434\n",
            "Epoch 69/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0866 - accuracy: 0.8403 - val_loss: 1.0075 - val_accuracy: 0.8448\n",
            "Epoch 70/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0781 - accuracy: 0.8458 - val_loss: 0.9991 - val_accuracy: 0.8448\n",
            "Epoch 71/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0685 - accuracy: 0.8416 - val_loss: 0.9869 - val_accuracy: 0.8484\n",
            "Epoch 72/100\n",
            "65/65 [==============================] - 1s 10ms/step - loss: 1.0580 - accuracy: 0.8467 - val_loss: 0.9804 - val_accuracy: 0.8481\n",
            "Epoch 73/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0511 - accuracy: 0.8458 - val_loss: 0.9713 - val_accuracy: 0.8474\n",
            "Epoch 74/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0357 - accuracy: 0.8464 - val_loss: 0.9610 - val_accuracy: 0.8510\n",
            "Epoch 75/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0269 - accuracy: 0.8483 - val_loss: 0.9520 - val_accuracy: 0.8517\n",
            "Epoch 76/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0204 - accuracy: 0.8496 - val_loss: 0.9443 - val_accuracy: 0.8521\n",
            "Epoch 77/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0143 - accuracy: 0.8509 - val_loss: 0.9388 - val_accuracy: 0.8499\n",
            "Epoch 78/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 1.0009 - accuracy: 0.8486 - val_loss: 0.9271 - val_accuracy: 0.8517\n",
            "Epoch 79/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9963 - accuracy: 0.8496 - val_loss: 0.9212 - val_accuracy: 0.8557\n",
            "Epoch 80/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9850 - accuracy: 0.8518 - val_loss: 0.9123 - val_accuracy: 0.8550\n",
            "Epoch 81/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9794 - accuracy: 0.8536 - val_loss: 0.9025 - val_accuracy: 0.8568\n",
            "Epoch 82/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9716 - accuracy: 0.8522 - val_loss: 0.8973 - val_accuracy: 0.8550\n",
            "Epoch 83/100\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 0.9615 - accuracy: 0.8552 - val_loss: 0.8905 - val_accuracy: 0.8571\n",
            "Epoch 84/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9554 - accuracy: 0.8544 - val_loss: 0.8829 - val_accuracy: 0.8597\n",
            "Epoch 85/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9497 - accuracy: 0.8544 - val_loss: 0.8772 - val_accuracy: 0.8593\n",
            "Epoch 86/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9410 - accuracy: 0.8536 - val_loss: 0.8708 - val_accuracy: 0.8604\n",
            "Epoch 87/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9319 - accuracy: 0.8587 - val_loss: 0.8631 - val_accuracy: 0.8608\n",
            "Epoch 88/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9277 - accuracy: 0.8570 - val_loss: 0.8567 - val_accuracy: 0.8644\n",
            "Epoch 89/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9198 - accuracy: 0.8594 - val_loss: 0.8499 - val_accuracy: 0.8615\n",
            "Epoch 90/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9093 - accuracy: 0.8596 - val_loss: 0.8422 - val_accuracy: 0.8597\n",
            "Epoch 91/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9048 - accuracy: 0.8609 - val_loss: 0.8375 - val_accuracy: 0.8644\n",
            "Epoch 92/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.9007 - accuracy: 0.8599 - val_loss: 0.8328 - val_accuracy: 0.8684\n",
            "Epoch 93/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.8909 - accuracy: 0.8618 - val_loss: 0.8263 - val_accuracy: 0.8615\n",
            "Epoch 94/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.8852 - accuracy: 0.8636 - val_loss: 0.8200 - val_accuracy: 0.8644\n",
            "Epoch 95/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.8780 - accuracy: 0.8616 - val_loss: 0.8143 - val_accuracy: 0.8677\n",
            "Epoch 96/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.8745 - accuracy: 0.8623 - val_loss: 0.8076 - val_accuracy: 0.8640\n",
            "Epoch 97/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.8701 - accuracy: 0.8654 - val_loss: 0.8050 - val_accuracy: 0.8684\n",
            "Epoch 98/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.8623 - accuracy: 0.8640 - val_loss: 0.7978 - val_accuracy: 0.8684\n",
            "Epoch 99/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.8557 - accuracy: 0.8642 - val_loss: 0.7959 - val_accuracy: 0.8687\n",
            "Epoch 100/100\n",
            "65/65 [==============================] - 1s 9ms/step - loss: 0.8502 - accuracy: 0.8655 - val_loss: 0.7885 - val_accuracy: 0.8684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3dRH7T9qyNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,balanced_accuracy_score,confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def test_xy(X,y,string,model):\n",
        "    y_pred = model.predict([X])\n",
        "    y_pred_arg = y_pred.argmax(axis=1)\n",
        "    pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "    print('accuracy %s'% string,accuracy_score(pred,y))\n",
        "    print('b_accuracy %s'%  string,balanced_accuracy_score(pred, y))\n",
        "\n",
        "\n",
        "test_xy(X_test_emb_de,y_test_de,'german',de_avg_pool)\n",
        "test_xy(X_test_emb_fr,y_test_fr,'french',de_avg_pool)\n",
        "test_xy(X_val_emb_fr,y_val_fr,'french',de_avg_pool)\n",
        "test_xy(X_train_emb_fr,y_train_fr,'french',de_avg_pool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eszN0r_mWfF9",
        "colab_type": "text"
      },
      "source": [
        "### deeper prediction analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm1x9GSS-aIW",
        "colab_type": "text"
      },
      "source": [
        "Prediction / Certainty Treshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-69cpC97SWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_xy(X,y,string,model,z,ret=False):\n",
        "    obs = len(X)\n",
        "    y_pred = model.predict([X])\n",
        "    y_pred_arg = y_pred.argmax(axis=1)\n",
        "    y_pred_max = y_pred.max(axis=1)\n",
        "    pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "    df_pred = pd.DataFrame(zip(X,pred,y,y_pred_max),columns=['embed','pred','y','y_pred_max'])\n",
        "    df_pred = df_pred[df_pred['y_pred_max']>z]\n",
        "    print('accuracy %s'% string,accuracy_score(df_pred['pred'],df_pred['y']))\n",
        "    print('b_accuracy %s'%  string,balanced_accuracy_score(df_pred['pred'],df_pred['y']))\n",
        "    print(len(df_pred),'of',len(X),int(len(df_pred)/len(X)*100),'%',len(df_pred.pred.unique()))\n",
        "    if ret:\n",
        "        return df_pred\n",
        "test_xy(X_test_emb_de,y_test_de,'german',de_avg_pool,.65)\n",
        "test_xy(X_traprint(classification_report(y,pred))in_emb_fr,y_train_fr,'french',de_avg_pool,.8)\n",
        "    #return pred, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhFro1C3m_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYl0oREB_DEd",
        "colab_type": "text"
      },
      "source": [
        "Accuracy for higher hirachies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiZ2S_iaAry2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('coicop_5_4.txt') as json_file:#\n",
        "    coicop_5_4 = json.load(json_file)\n",
        "\n",
        "with open('coicop_5_3.txt') as json_file:#\n",
        "    coicop_5_3 = json.load(json_file)\n",
        "\n",
        "y_pred = de_avg_pool.predict([X_test_emb_fr])\n",
        "y_pred_arg = y_pred.argmax(axis=1)\n",
        "pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "y_pr_lab3 = [coicop_5_3[cc5] for cc5 in pred]\n",
        "y_pr_lab4 = [coicop_5_4[cc5] for cc5 in pred]\n",
        "y_lab3 = [coicop_5_3[cc5] for cc5 in y_test_fr]\n",
        "y_lab4 = [coicop_5_4[cc5] for cc5 in y_test_fr]\n",
        "print('accuracy %s'% accuracy_score(y_pr_lab3,y_lab3))\n",
        "print('b_accuracy %s'%  balanced_accuracy_score(y_pr_lab3, y_lab3))\n",
        "print('accuracy %s'% accuracy_score(y_pr_lab4,y_lab4))\n",
        "print('b_accuracy %s'%  balanced_accuracy_score(y_pr_lab4, y_lab4))\n",
        "#print(classification_report(y_lab4,y_pr_lab4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8L2OqDn3DZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "y_pred = de_avg_pool.predict([X_test_emb_fr])\n",
        "y_pred_arg = y_pred.argmax(axis=1)\n",
        "pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "y_pr_lab4 = [coicop_5_4[cc5] for cc5 in pred]\n",
        "y_lab4 = [coicop_5_4[cc5] for cc5 in y_test_fr]\n",
        "\n",
        "label = pd.Series(y_lab4).unique()\n",
        "label.sort()\n",
        "cm = confusion_matrix(y_lab4,y_pr_lab4,labels=label)#, normalize='true')\n",
        "\n",
        "df_cm = pd.DataFrame(cm, label,label)\n",
        "plt.figure(figsize=(15,15))\n",
        "sn.set(font_scale=.7) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 9}) # font size\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FVqFByYZkAd",
        "colab_type": "text"
      },
      "source": [
        "### Transferlearning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRS98lLSeovB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "few_shot = 1000\n",
        "\n",
        "lr = .005\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "inp = de_avg_pool.input\n",
        "out = de_avg_pool.output #get_layer('output_de').output\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_new = Model(inp, out)\n",
        "model_new.summary()\n",
        "model_new.get_layer('convolution').trainable = False\n",
        "model_new.get_layer('drop').rate = .5\n",
        "\n",
        "model_new.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "model_new.fit(x = X_train_emb_fr[:few_shot], y = y_train_enc_fr[:few_shot],\\\n",
        "                validation_data = (X_val_emb_fr, y_val_enc_fr), \\\n",
        "                epochs = 100, batch_size = 32, shuffle = True, \\\n",
        "                class_weight = class_weight_dict_fr, \\\n",
        "                callbacks = [early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiUvZ67RtYdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_xy(X_test_emb_de,y_test_de,'german',model_new)\n",
        "test_xy(X_test_emb_fr,y_test_fr,'french',model_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "771mi_iCz_bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "y_pred = model_new.predict([X_test_emb_fr])\n",
        "y_pred_arg = y_pred.argmax(axis=1)\n",
        "pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "y_pr_lab4 = [coicop_5_4[cc5] for cc5 in pred]\n",
        "y_lab4 = [coicop_5_4[cc5] for cc5 in y_test_fr]\n",
        "print('accuracy %s'% accuracy_score(y_pr_lab4,y_lab4))\n",
        "print('b_accuracy %s'%  balanced_accuracy_score(y_pr_lab4, y_lab4))\n",
        "\n",
        "label = pd.Series(y_test_fr).unique()\n",
        "label.sort()\n",
        "cm = confusion_matrix(y_test_fr,pred,labels=label)#, normalize='true')\n",
        "\n",
        "df_cm = pd.DataFrame(cm, label,label)\n",
        "plt.figure(figsize=(15,15))\n",
        "sn.set(font_scale=.7) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 9}) # font size\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZNTUwp4oGKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_xy(X_test_emb_de,y_test_de,'german',de_avg_pool_2)\n",
        "test_xy(X_test_emb_fr,y_test_fr,'french',de_avg_pool_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO2e65uFcFqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(classification_report(pred, df_acc['cc5']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO1wYCsJeTkT",
        "colab_type": "text"
      },
      "source": [
        "## CCN 2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VagmlBtNeV1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc261ce5-cea8-44e1-da9e-2a368f138ca8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten,Reshape, GlobalAveragePooling1D,MaxPool2D,AvgPool2D, Concatenate,Conv1D,Conv2D,BatchNormalization,Add,Masking,GlobalMaxPooling1D,LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.regularizers import l1,l2\n",
        "dropout_rate=.20\n",
        "filter_sizes = [1,2,5]\n",
        "num_filters = 75\n",
        "\n",
        "input_layer = Input(shape = (seq_len,embedding_dim,), name='text_input')\n",
        "x = Reshape((seq_len, embedding_dim, 1))(input_layer)\n",
        "\n",
        "maxpool_pool = []\n",
        "for i in range(len(filter_sizes)):\n",
        "    conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embedding_dim),\n",
        "                                  kernel_initializer='he_normal', activation='relu')(x)\n",
        "    maxpool_pool.append(AvgPool2D(pool_size=(seq_len - filter_sizes[i] + 1, 1))(conv))\n",
        "\n",
        "pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "\n",
        "#conv_layer = Conv2D(filters=100,   kernel_size=(5,300),   padding='same',  activation='relu', strides=1,name='convolution')(x)\n",
        "#pool_layer = MaxPool2D(pool_size = (35,1),name='max_pooling')(conv_layer)\n",
        "falt_layer = Flatten(name='flat')(pool_layer)\n",
        "drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "de_cnn2d = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "de_cnn2d.summary()\n",
        "lr = .005\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "de_cnn2d.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "hist = de_cnn2d.fit(x = X_train_emb_de, y = y_train_enc_de,\\\n",
        "                validation_data = (X_val_emb_de, y_val_enc_de), \\\n",
        "                epochs = 150, batch_size = 32, shuffle = True, \\\n",
        "                class_weight = class_weight_dict_de, \\\n",
        "                callbacks = [early_stopping])"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_105\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 32, 300)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_68 (Reshape)            (None, 32, 300, 1)   0           text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 32, 1, 75)    22575       reshape_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 31, 1, 75)    45075       reshape_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 28, 1, 75)    112575      reshape_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_30 (AveragePo (None, 1, 1, 75)     0           conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_31 (AveragePo (None, 1, 1, 75)     0           conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 1, 1, 75)     0           conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 3, 1, 75)     0           average_pooling2d_30[0][0]       \n",
            "                                                                 average_pooling2d_31[0][0]       \n",
            "                                                                 average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 74)           16724       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 196,949\n",
            "Trainable params: 196,949\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 2.5473 - accuracy: 0.4465 - val_loss: 1.2450 - val_accuracy: 0.6371\n",
            "Epoch 2/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 1.0700 - accuracy: 0.7492 - val_loss: 0.6422 - val_accuracy: 0.8513\n",
            "Epoch 3/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.7373 - accuracy: 0.8222 - val_loss: 0.5111 - val_accuracy: 0.8557\n",
            "Epoch 4/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.5471 - accuracy: 0.8657 - val_loss: 0.4054 - val_accuracy: 0.9007\n",
            "Epoch 5/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.4584 - accuracy: 0.8860 - val_loss: 0.3585 - val_accuracy: 0.9025\n",
            "Epoch 6/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.4053 - accuracy: 0.9007 - val_loss: 0.3125 - val_accuracy: 0.9268\n",
            "Epoch 7/150\n",
            "518/518 [==============================] - 3s 6ms/step - loss: 0.3408 - accuracy: 0.9153 - val_loss: 0.3008 - val_accuracy: 0.9260\n",
            "Epoch 8/150\n",
            "518/518 [==============================] - 3s 6ms/step - loss: 0.3022 - accuracy: 0.9205 - val_loss: 0.2508 - val_accuracy: 0.9384\n",
            "Epoch 9/150\n",
            "518/518 [==============================] - 3s 6ms/step - loss: 0.2701 - accuracy: 0.9261 - val_loss: 0.2482 - val_accuracy: 0.9416\n",
            "Epoch 10/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.2395 - accuracy: 0.9359 - val_loss: 0.2225 - val_accuracy: 0.9460\n",
            "Epoch 11/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9415 - val_loss: 0.2012 - val_accuracy: 0.9529\n",
            "Epoch 12/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9465 - val_loss: 0.1987 - val_accuracy: 0.9496\n",
            "Epoch 13/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.1763 - accuracy: 0.9505 - val_loss: 0.1915 - val_accuracy: 0.9521\n",
            "Epoch 14/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.1514 - accuracy: 0.9542 - val_loss: 0.1896 - val_accuracy: 0.9511\n",
            "Epoch 15/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.1451 - accuracy: 0.9562 - val_loss: 0.1856 - val_accuracy: 0.9500\n",
            "Epoch 16/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.9606 - val_loss: 0.1801 - val_accuracy: 0.9558\n",
            "Epoch 17/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.1405 - accuracy: 0.9617 - val_loss: 0.1715 - val_accuracy: 0.9572\n",
            "Epoch 18/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9651 - val_loss: 0.1730 - val_accuracy: 0.9569\n",
            "Epoch 19/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.1050 - accuracy: 0.9659 - val_loss: 0.1712 - val_accuracy: 0.9590\n",
            "Epoch 20/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0999 - accuracy: 0.9689 - val_loss: 0.1640 - val_accuracy: 0.9608\n",
            "Epoch 21/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0923 - accuracy: 0.9709 - val_loss: 0.1684 - val_accuracy: 0.9601\n",
            "Epoch 22/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0991 - accuracy: 0.9700 - val_loss: 0.1749 - val_accuracy: 0.9612\n",
            "Epoch 23/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0837 - accuracy: 0.9723 - val_loss: 0.1552 - val_accuracy: 0.9663\n",
            "Epoch 24/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0740 - accuracy: 0.9774 - val_loss: 0.1499 - val_accuracy: 0.9627\n",
            "Epoch 25/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0721 - accuracy: 0.9769 - val_loss: 0.1536 - val_accuracy: 0.9656\n",
            "Epoch 26/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0642 - accuracy: 0.9788 - val_loss: 0.1571 - val_accuracy: 0.9601\n",
            "Epoch 27/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0646 - accuracy: 0.9782 - val_loss: 0.1501 - val_accuracy: 0.9645\n",
            "Epoch 28/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0683 - accuracy: 0.9807 - val_loss: 0.1623 - val_accuracy: 0.9601\n",
            "Epoch 29/150\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0611 - accuracy: 0.9805 - val_loss: 0.1538 - val_accuracy: 0.9648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvo_CMKtgpv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6696299d-639e-4240-f7a9-645dbdf775da"
      },
      "source": [
        "def test_xy(X,y,string,model):\n",
        "    y_pred = model.predict([X])\n",
        "    y_pred_arg = y_pred.argmax(axis=1)\n",
        "    pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "    print('accuracy %s'% string,accuracy_score(pred,y))\n",
        "    print('b_accuracy %s'%  string,balanced_accuracy_score(pred, y))\n",
        "\n",
        "test_xy(X_test_emb_de,y_test_de,'german',de_cnn2d)\n",
        "test_xy(X_test_emb_fr,y_test_fr,'french',de_cnn2d)\n",
        "test_xy(X_val_emb_fr,y_val_fr,'french',de_cnn2d)\n",
        "test_xy(X_train_emb_fr,y_train_fr,'french',de_cnn2d)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy german 0.9579405366207396\n",
            "b_accuracy german 0.9375609831814934\n",
            "accuracy french 0.42146017699115046\n",
            "b_accuracy french 0.410995792197681\n",
            "accuracy french 0.3875968992248062\n",
            "b_accuracy french 0.36765761277635794\n",
            "accuracy french 0.3992248062015504\n",
            "b_accuracy french 0.37931973980999184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldjtfbp8p-44",
        "colab_type": "text"
      },
      "source": [
        "### Transferlearning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhuTpfU2hrWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transfer_cnn(few_shot,freeze):\n",
        "\n",
        "    lr = .005\n",
        "    opt = Adam(lr=lr, decay=lr/100)\n",
        "    inp = de_cnn2d.input\n",
        "    out = de_cnn2d.output #get_layer('output_de').output\n",
        "\n",
        "    # create a new network between inp and out\n",
        "    de_cnn2d_transfer = Model(inp, out)\n",
        "    #de_cnn2d_transfer.summary()\n",
        "    #de_cnn2d_transfer.get_layer('flat').trainable = False\n",
        "    #de_cnn2d_transfer.get_layer('drop').rate = .6\n",
        "    \n",
        "\n",
        "    de_cnn2d_transfer.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    #freeze\n",
        "    for l , layer in enumerate(de_cnn2d_transfer.layers[:-3]):\n",
        "        de_cnn2d_transfer.layers[l].trainable = (freeze==False)\n",
        "\n",
        "    idx = np.random.randint(len(X_train_emb_fr), size=few_shot)\n",
        "\n",
        "    de_cnn2d_transfer.fit(x = X_train_emb_fr[idx,:,:], y = y_train_enc_fr[idx,:],\\\n",
        "                    validation_data = (X_val_emb_fr, y_val_enc_fr), \\\n",
        "                    epochs = 150, batch_size = 8, shuffle = True, \\\n",
        "                    class_weight = class_weight_dict_fr, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    print(few_shot)\n",
        "    print(test_xy(X_test_emb_de,y_test_de,'german',de_cnn2d_transfer))\n",
        "    print(test_xy(X_test_emb_fr,y_test_fr,'french test',de_cnn2d_transfer))\n",
        "    print(test_xy(X_val_emb_fr,y_val_fr,'french val',de_cnn2d_transfer))\n",
        "    print(test_xy(X_train_emb_fr,y_train_fr,'french train',de_cnn2d_transfer))"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTa7r3Rmk_ox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62888709-e245-4b43-8d00-6739b7684e91"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000]:\n",
        "    transfer_cnn(obs,True)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 44ms/step - loss: 9.5598 - accuracy: 0.3800 - val_loss: 4.2515 - val_accuracy: 0.4131\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 4.3884 - accuracy: 0.4900 - val_loss: 3.8911 - val_accuracy: 0.3976\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 2.8908 - accuracy: 0.5300 - val_loss: 3.7162 - val_accuracy: 0.4142\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 0s 34ms/step - loss: 2.4009 - accuracy: 0.5800 - val_loss: 3.6578 - val_accuracy: 0.4341\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 1.8735 - accuracy: 0.6500 - val_loss: 3.4944 - val_accuracy: 0.4551\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 1.7849 - accuracy: 0.6700 - val_loss: 3.4522 - val_accuracy: 0.4529\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 1.2731 - accuracy: 0.7100 - val_loss: 3.3637 - val_accuracy: 0.4695\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.9373 - accuracy: 0.7000 - val_loss: 3.3053 - val_accuracy: 0.4928\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.7281 - accuracy: 0.7600 - val_loss: 3.2683 - val_accuracy: 0.4983\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.5290 - accuracy: 0.8000 - val_loss: 3.2056 - val_accuracy: 0.5150\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.4227 - accuracy: 0.8300 - val_loss: 3.3024 - val_accuracy: 0.5006\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.4540 - accuracy: 0.8400 - val_loss: 3.3075 - val_accuracy: 0.5017\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.3814 - accuracy: 0.8400 - val_loss: 3.2068 - val_accuracy: 0.5127\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.3488 - accuracy: 0.8300 - val_loss: 3.1692 - val_accuracy: 0.5371\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.2739 - accuracy: 0.9100 - val_loss: 3.1749 - val_accuracy: 0.5349\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.3748 - accuracy: 0.8700 - val_loss: 3.1673 - val_accuracy: 0.5349\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.1800 - accuracy: 0.9200 - val_loss: 3.1040 - val_accuracy: 0.5316\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.1901 - accuracy: 0.9200 - val_loss: 3.1252 - val_accuracy: 0.5260\n",
            "Epoch 19/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 3.1437 - val_accuracy: 0.5305\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.1224 - accuracy: 0.9600 - val_loss: 3.1912 - val_accuracy: 0.5393\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.1838 - accuracy: 0.9200 - val_loss: 3.1922 - val_accuracy: 0.5393\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.1093 - accuracy: 0.9500 - val_loss: 3.2899 - val_accuracy: 0.5227\n",
            "100\n",
            "accuracy german 0.9071791153009428\n",
            "b_accuracy german 0.8979589217968261\n",
            "None\n",
            "accuracy french test 0.5320796460176991\n",
            "b_accuracy french test 0.49607248714116775\n",
            "None\n",
            "accuracy french val 0.5227021040974529\n",
            "b_accuracy french val 0.4860904829026858\n",
            "None\n",
            "accuracy french train 0.5295311923218899\n",
            "b_accuracy french train 0.503035891596726\n",
            "None\n",
            "Epoch 1/150\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 3.4214 - accuracy: 0.5440 - val_loss: 2.7366 - val_accuracy: 0.5537\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 2.5713 - accuracy: 0.5600 - val_loss: 2.4471 - val_accuracy: 0.5670\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 2.2835 - accuracy: 0.5840 - val_loss: 2.3512 - val_accuracy: 0.5626\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.7082 - accuracy: 0.5920 - val_loss: 2.2848 - val_accuracy: 0.5714\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.6381 - accuracy: 0.6200 - val_loss: 2.3243 - val_accuracy: 0.5836\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.3553 - accuracy: 0.6200 - val_loss: 2.3199 - val_accuracy: 0.5781\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.4173 - accuracy: 0.6080 - val_loss: 2.2809 - val_accuracy: 0.5914\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.3341 - accuracy: 0.6120 - val_loss: 2.2803 - val_accuracy: 0.5736\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.4036 - accuracy: 0.6400 - val_loss: 2.2753 - val_accuracy: 0.5825\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0492 - accuracy: 0.6640 - val_loss: 2.2636 - val_accuracy: 0.5969\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.1676 - accuracy: 0.6400 - val_loss: 2.2687 - val_accuracy: 0.5969\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.9384 - accuracy: 0.7000 - val_loss: 2.2535 - val_accuracy: 0.6035\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.0111 - accuracy: 0.7200 - val_loss: 2.2497 - val_accuracy: 0.5991\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.9437 - accuracy: 0.7160 - val_loss: 2.2192 - val_accuracy: 0.6202\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.8762 - accuracy: 0.7280 - val_loss: 2.2607 - val_accuracy: 0.6024\n",
            "Epoch 16/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.8171 - accuracy: 0.7240 - val_loss: 2.2405 - val_accuracy: 0.6113\n",
            "Epoch 17/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.7553 - accuracy: 0.7320 - val_loss: 2.2626 - val_accuracy: 0.6135\n",
            "Epoch 18/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.6765 - accuracy: 0.7560 - val_loss: 2.2455 - val_accuracy: 0.6135\n",
            "Epoch 19/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.6045 - accuracy: 0.7800 - val_loss: 2.2779 - val_accuracy: 0.6135\n",
            "250\n",
            "accuracy german 0.8788977519941987\n",
            "b_accuracy german 0.8703119687093619\n",
            "None\n",
            "accuracy french test 0.6515486725663717\n",
            "b_accuracy french test 0.6166027002727887\n",
            "None\n",
            "accuracy french val 0.6135105204872646\n",
            "b_accuracy french val 0.5916112410432701\n",
            "None\n",
            "accuracy french train 0.6323366555924695\n",
            "b_accuracy french train 0.6436314577279219\n",
            "None\n",
            "Epoch 1/150\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 2.9970 - accuracy: 0.5960 - val_loss: 2.0972 - val_accuracy: 0.6357\n",
            "Epoch 2/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2.4974 - accuracy: 0.6080 - val_loss: 1.9382 - val_accuracy: 0.6545\n",
            "Epoch 3/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2.3163 - accuracy: 0.6200 - val_loss: 1.8724 - val_accuracy: 0.6512\n",
            "Epoch 4/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.8452 - accuracy: 0.6260 - val_loss: 1.8783 - val_accuracy: 0.6545\n",
            "Epoch 5/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.7465 - accuracy: 0.6280 - val_loss: 1.8178 - val_accuracy: 0.6622\n",
            "Epoch 6/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.4949 - accuracy: 0.6680 - val_loss: 1.8240 - val_accuracy: 0.6700\n",
            "Epoch 7/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.4217 - accuracy: 0.6800 - val_loss: 1.8252 - val_accuracy: 0.6656\n",
            "Epoch 8/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.2952 - accuracy: 0.6620 - val_loss: 1.8169 - val_accuracy: 0.6589\n",
            "Epoch 9/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.1404 - accuracy: 0.6800 - val_loss: 1.7965 - val_accuracy: 0.6667\n",
            "Epoch 10/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1.2340 - accuracy: 0.6880 - val_loss: 1.8015 - val_accuracy: 0.6733\n",
            "Epoch 11/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.1156 - accuracy: 0.7240 - val_loss: 1.7999 - val_accuracy: 0.6711\n",
            "Epoch 12/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.0603 - accuracy: 0.6860 - val_loss: 1.8232 - val_accuracy: 0.6711\n",
            "Epoch 13/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.9586 - accuracy: 0.7360 - val_loss: 1.7793 - val_accuracy: 0.6766\n",
            "Epoch 14/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.9340 - accuracy: 0.7300 - val_loss: 1.7967 - val_accuracy: 0.6777\n",
            "Epoch 15/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.8354 - accuracy: 0.7440 - val_loss: 1.7544 - val_accuracy: 0.6811\n",
            "Epoch 16/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.8436 - accuracy: 0.7280 - val_loss: 1.7405 - val_accuracy: 0.6921\n",
            "Epoch 17/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.7624 - accuracy: 0.7500 - val_loss: 1.7532 - val_accuracy: 0.6833\n",
            "Epoch 18/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.7534 - accuracy: 0.7540 - val_loss: 1.7398 - val_accuracy: 0.6855\n",
            "Epoch 19/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.7520 - accuracy: 0.7620 - val_loss: 1.7204 - val_accuracy: 0.6899\n",
            "Epoch 20/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.7577 - accuracy: 0.7400 - val_loss: 1.7456 - val_accuracy: 0.6844\n",
            "Epoch 21/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.6722 - accuracy: 0.7520 - val_loss: 1.7130 - val_accuracy: 0.6921\n",
            "Epoch 22/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.6147 - accuracy: 0.7880 - val_loss: 1.6651 - val_accuracy: 0.7021\n",
            "Epoch 23/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5927 - accuracy: 0.7820 - val_loss: 1.6889 - val_accuracy: 0.6988\n",
            "Epoch 24/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.6128 - accuracy: 0.7920 - val_loss: 1.6582 - val_accuracy: 0.7076\n",
            "Epoch 25/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.5530 - accuracy: 0.7900 - val_loss: 1.6769 - val_accuracy: 0.7010\n",
            "Epoch 26/150\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.5727 - accuracy: 0.8020 - val_loss: 1.6972 - val_accuracy: 0.7043\n",
            "Epoch 27/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5748 - accuracy: 0.8100 - val_loss: 1.6932 - val_accuracy: 0.7054\n",
            "Epoch 28/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5411 - accuracy: 0.7940 - val_loss: 1.7026 - val_accuracy: 0.7076\n",
            "Epoch 29/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.4946 - accuracy: 0.7940 - val_loss: 1.6749 - val_accuracy: 0.7065\n",
            "500\n",
            "accuracy german 0.8444525018129079\n",
            "b_accuracy german 0.8641500089986652\n",
            "None\n",
            "accuracy french test 0.7046460176991151\n",
            "b_accuracy french test 0.6426235594634533\n",
            "None\n",
            "accuracy french val 0.7065337763012182\n",
            "b_accuracy french val 0.6849432482428415\n",
            "None\n",
            "accuracy french train 0.7229605020302695\n",
            "b_accuracy french train 0.6884273174440779\n",
            "None\n",
            "Epoch 1/150\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 2.6932 - accuracy: 0.6740 - val_loss: 1.5203 - val_accuracy: 0.7087\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.9476 - accuracy: 0.6760 - val_loss: 1.4242 - val_accuracy: 0.7320\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.6274 - accuracy: 0.6910 - val_loss: 1.4218 - val_accuracy: 0.7298\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.4337 - accuracy: 0.6970 - val_loss: 1.3931 - val_accuracy: 0.7220\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.2397 - accuracy: 0.7110 - val_loss: 1.3490 - val_accuracy: 0.7209\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0369 - accuracy: 0.7410 - val_loss: 1.3274 - val_accuracy: 0.7287\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0583 - accuracy: 0.7400 - val_loss: 1.3325 - val_accuracy: 0.7464\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1.0605 - accuracy: 0.7360 - val_loss: 1.3293 - val_accuracy: 0.7475\n",
            "Epoch 9/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.9445 - accuracy: 0.7490 - val_loss: 1.2960 - val_accuracy: 0.7431\n",
            "Epoch 10/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.9187 - accuracy: 0.7540 - val_loss: 1.3062 - val_accuracy: 0.7608\n",
            "Epoch 11/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.8758 - accuracy: 0.7680 - val_loss: 1.2882 - val_accuracy: 0.7475\n",
            "Epoch 12/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.8232 - accuracy: 0.7550 - val_loss: 1.2734 - val_accuracy: 0.7519\n",
            "Epoch 13/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.7159 - accuracy: 0.7680 - val_loss: 1.2743 - val_accuracy: 0.7442\n",
            "Epoch 14/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.7511 - accuracy: 0.7850 - val_loss: 1.2443 - val_accuracy: 0.7564\n",
            "Epoch 15/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6799 - accuracy: 0.7970 - val_loss: 1.2784 - val_accuracy: 0.7586\n",
            "Epoch 16/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6336 - accuracy: 0.7760 - val_loss: 1.2771 - val_accuracy: 0.7542\n",
            "Epoch 17/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6963 - accuracy: 0.7850 - val_loss: 1.2891 - val_accuracy: 0.7564\n",
            "Epoch 18/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5682 - accuracy: 0.7780 - val_loss: 1.2189 - val_accuracy: 0.7796\n",
            "Epoch 19/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5707 - accuracy: 0.7980 - val_loss: 1.2055 - val_accuracy: 0.7719\n",
            "Epoch 20/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.8220 - val_loss: 1.2485 - val_accuracy: 0.7674\n",
            "Epoch 21/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4873 - accuracy: 0.8260 - val_loss: 1.2466 - val_accuracy: 0.7741\n",
            "Epoch 22/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5385 - accuracy: 0.8110 - val_loss: 1.2758 - val_accuracy: 0.7685\n",
            "Epoch 23/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4984 - accuracy: 0.8170 - val_loss: 1.2605 - val_accuracy: 0.7719\n",
            "Epoch 24/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5377 - accuracy: 0.8190 - val_loss: 1.2738 - val_accuracy: 0.7608\n",
            "1000\n",
            "accuracy german 0.859680928208847\n",
            "b_accuracy german 0.8314596346269574\n",
            "None\n",
            "accuracy french test 0.7754424778761062\n",
            "b_accuracy french test 0.7142836815764273\n",
            "None\n",
            "accuracy french val 0.760797342192691\n",
            "b_accuracy french val 0.719874396881029\n",
            "None\n",
            "accuracy french train 0.7899593946105574\n",
            "b_accuracy french train 0.753120548534644\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.7574 - accuracy: 0.7250 - val_loss: 1.2540 - val_accuracy: 0.7386\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 1.4929 - accuracy: 0.7120 - val_loss: 1.1466 - val_accuracy: 0.7741\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 1.3521 - accuracy: 0.7285 - val_loss: 1.1036 - val_accuracy: 0.7697\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 1.1562 - accuracy: 0.7475 - val_loss: 1.0682 - val_accuracy: 0.7774\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 1.0044 - accuracy: 0.7515 - val_loss: 1.0189 - val_accuracy: 0.7785\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 1.0384 - accuracy: 0.7455 - val_loss: 1.0477 - val_accuracy: 0.7652\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.8899 - accuracy: 0.7590 - val_loss: 1.0529 - val_accuracy: 0.7697\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.7727 - accuracy: 0.7755 - val_loss: 0.9699 - val_accuracy: 0.7973\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.7871 - accuracy: 0.7745 - val_loss: 1.0135 - val_accuracy: 0.7874\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.7890 - val_loss: 0.9834 - val_accuracy: 0.7852\n",
            "Epoch 11/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.7266 - accuracy: 0.7750 - val_loss: 0.9538 - val_accuracy: 0.7940\n",
            "Epoch 12/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6421 - accuracy: 0.7955 - val_loss: 0.9585 - val_accuracy: 0.7940\n",
            "Epoch 13/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6268 - accuracy: 0.8005 - val_loss: 0.9429 - val_accuracy: 0.8073\n",
            "Epoch 14/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5737 - accuracy: 0.8060 - val_loss: 0.9856 - val_accuracy: 0.7940\n",
            "Epoch 15/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5703 - accuracy: 0.8055 - val_loss: 0.9129 - val_accuracy: 0.8151\n",
            "Epoch 16/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5905 - accuracy: 0.7995 - val_loss: 0.9839 - val_accuracy: 0.7940\n",
            "Epoch 17/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5370 - accuracy: 0.8165 - val_loss: 0.9210 - val_accuracy: 0.8095\n",
            "Epoch 18/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5752 - accuracy: 0.8015 - val_loss: 0.9097 - val_accuracy: 0.8151\n",
            "Epoch 19/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5131 - accuracy: 0.8150 - val_loss: 0.9096 - val_accuracy: 0.8051\n",
            "Epoch 20/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4870 - accuracy: 0.8270 - val_loss: 0.9398 - val_accuracy: 0.7951\n",
            "Epoch 21/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5289 - accuracy: 0.8140 - val_loss: 0.9419 - val_accuracy: 0.8029\n",
            "Epoch 22/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4943 - accuracy: 0.8225 - val_loss: 0.9072 - val_accuracy: 0.8051\n",
            "Epoch 23/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4730 - accuracy: 0.8285 - val_loss: 0.9263 - val_accuracy: 0.8106\n",
            "Epoch 24/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4966 - accuracy: 0.8230 - val_loss: 0.9653 - val_accuracy: 0.7929\n",
            "Epoch 25/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4488 - accuracy: 0.8210 - val_loss: 0.9038 - val_accuracy: 0.8106\n",
            "Epoch 26/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3968 - accuracy: 0.8365 - val_loss: 0.9214 - val_accuracy: 0.8117\n",
            "Epoch 27/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.8240 - val_loss: 0.9150 - val_accuracy: 0.8095\n",
            "Epoch 28/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4163 - accuracy: 0.8365 - val_loss: 0.9107 - val_accuracy: 0.8084\n",
            "Epoch 29/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4194 - accuracy: 0.8530 - val_loss: 0.9141 - val_accuracy: 0.8018\n",
            "Epoch 30/150\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4566 - accuracy: 0.8320 - val_loss: 0.9335 - val_accuracy: 0.7907\n",
            "2000\n",
            "accuracy german 0.7320522117476432\n",
            "b_accuracy german 0.744997259949071\n",
            "None\n",
            "accuracy french test 0.790929203539823\n",
            "b_accuracy french test 0.7475486669724889\n",
            "None\n",
            "accuracy french val 0.7906976744186046\n",
            "b_accuracy french val 0.7549357770013473\n",
            "None\n",
            "accuracy french train 0.8224437061646364\n",
            "b_accuracy french train 0.7847105482271458\n",
            "None\n",
            "Epoch 1/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.8879 - accuracy: 0.7726 - val_loss: 0.8830 - val_accuracy: 0.8117\n",
            "Epoch 2/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.7661 - accuracy: 0.7826 - val_loss: 0.8349 - val_accuracy: 0.8151\n",
            "Epoch 3/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6648 - accuracy: 0.7928 - val_loss: 0.8047 - val_accuracy: 0.8317\n",
            "Epoch 4/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6272 - accuracy: 0.8048 - val_loss: 0.7764 - val_accuracy: 0.8295\n",
            "Epoch 5/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5761 - accuracy: 0.8094 - val_loss: 0.7895 - val_accuracy: 0.8128\n",
            "Epoch 6/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5514 - accuracy: 0.8142 - val_loss: 0.7717 - val_accuracy: 0.8250\n",
            "Epoch 7/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.4885 - accuracy: 0.8224 - val_loss: 0.7592 - val_accuracy: 0.8272\n",
            "Epoch 8/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.4687 - accuracy: 0.8294 - val_loss: 0.7689 - val_accuracy: 0.8184\n",
            "Epoch 9/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.4542 - accuracy: 0.8290 - val_loss: 0.7811 - val_accuracy: 0.8173\n",
            "Epoch 10/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4159 - accuracy: 0.8392 - val_loss: 0.7890 - val_accuracy: 0.8106\n",
            "Epoch 11/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4217 - accuracy: 0.8324 - val_loss: 0.7581 - val_accuracy: 0.8339\n",
            "Epoch 12/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4054 - accuracy: 0.8398 - val_loss: 0.7521 - val_accuracy: 0.8261\n",
            "Epoch 13/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4063 - accuracy: 0.8354 - val_loss: 0.7435 - val_accuracy: 0.8239\n",
            "Epoch 14/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3891 - accuracy: 0.8460 - val_loss: 0.7801 - val_accuracy: 0.8140\n",
            "Epoch 15/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3835 - accuracy: 0.8404 - val_loss: 0.7406 - val_accuracy: 0.8283\n",
            "Epoch 16/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3665 - accuracy: 0.8504 - val_loss: 0.7569 - val_accuracy: 0.8328\n",
            "Epoch 17/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3606 - accuracy: 0.8560 - val_loss: 0.7886 - val_accuracy: 0.8339\n",
            "Epoch 18/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3565 - accuracy: 0.8560 - val_loss: 0.7530 - val_accuracy: 0.8217\n",
            "Epoch 19/150\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3548 - accuracy: 0.8484 - val_loss: 0.7643 - val_accuracy: 0.8283\n",
            "Epoch 20/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.3397 - accuracy: 0.8556 - val_loss: 0.7523 - val_accuracy: 0.8217\n",
            "5000\n",
            "accuracy german 0.6976069615663524\n",
            "b_accuracy german 0.7107704539308728\n",
            "None\n",
            "accuracy french test 0.8329646017699115\n",
            "b_accuracy french test 0.8048710669428552\n",
            "None\n",
            "accuracy french val 0.8217054263565892\n",
            "b_accuracy french val 0.7793138419829382\n",
            "None\n",
            "accuracy french train 0.88187523071244\n",
            "b_accuracy french train 0.863137383263782\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjowWaogDpDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ca16b6f-e246-4165-90ce-27232747c4d6"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000]:\n",
        "    transfer_cnn(obs,False)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 43ms/step - loss: 8.1236 - accuracy: 0.3000 - val_loss: 4.2636 - val_accuracy: 0.3920\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 3.7266 - accuracy: 0.3700 - val_loss: 3.9537 - val_accuracy: 0.3987\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 2.8236 - accuracy: 0.4100 - val_loss: 3.8319 - val_accuracy: 0.4097\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 2.0862 - accuracy: 0.4100 - val_loss: 3.6322 - val_accuracy: 0.4286\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 1.4078 - accuracy: 0.4900 - val_loss: 3.6037 - val_accuracy: 0.4086\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 1.0616 - accuracy: 0.5900 - val_loss: 3.5310 - val_accuracy: 0.4396\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.8586 - accuracy: 0.6600 - val_loss: 3.4907 - val_accuracy: 0.4374\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.7123 - accuracy: 0.7000 - val_loss: 3.4557 - val_accuracy: 0.4529\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.6314 - accuracy: 0.6700 - val_loss: 3.4419 - val_accuracy: 0.4507\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.6042 - accuracy: 0.6600 - val_loss: 3.3464 - val_accuracy: 0.4607\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.5828 - accuracy: 0.7700 - val_loss: 3.3012 - val_accuracy: 0.4740\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.5321 - accuracy: 0.7600 - val_loss: 3.2736 - val_accuracy: 0.4862\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 0.3326 - accuracy: 0.7900 - val_loss: 3.2715 - val_accuracy: 0.4895\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 0.3677 - accuracy: 0.8100 - val_loss: 3.2899 - val_accuracy: 0.4972\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.3406 - accuracy: 0.8700 - val_loss: 3.3192 - val_accuracy: 0.4939\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.2630 - accuracy: 0.8600 - val_loss: 3.3427 - val_accuracy: 0.4850\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.2437 - accuracy: 0.8300 - val_loss: 3.3493 - val_accuracy: 0.4873\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 0.1925 - accuracy: 0.8600 - val_loss: 3.3287 - val_accuracy: 0.4950\n",
            "100\n",
            "accuracy german 0.9202320522117476\n",
            "b_accuracy german 0.9090708291122745\n",
            "None\n",
            "accuracy french test 0.5398230088495575\n",
            "b_accuracy french test 0.5781125755101828\n",
            "None\n",
            "accuracy french val 0.4950166112956811\n",
            "b_accuracy french val 0.47633973981799327\n",
            "None\n",
            "accuracy french train 0.521594684385382\n",
            "b_accuracy french train 0.538611009654084\n",
            "None\n",
            "Epoch 1/150\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 4.4289 - accuracy: 0.4560 - val_loss: 2.3088 - val_accuracy: 0.5615\n",
            "Epoch 2/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 2.3065 - accuracy: 0.5080 - val_loss: 2.2246 - val_accuracy: 0.5460\n",
            "Epoch 3/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.5724 - accuracy: 0.6200 - val_loss: 1.9857 - val_accuracy: 0.5748\n",
            "Epoch 4/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.2261 - accuracy: 0.6480 - val_loss: 1.9702 - val_accuracy: 0.5604\n",
            "Epoch 5/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.9284 - accuracy: 0.6720 - val_loss: 1.8885 - val_accuracy: 0.6035\n",
            "Epoch 6/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.6347 - accuracy: 0.7640 - val_loss: 1.8825 - val_accuracy: 0.6135\n",
            "Epoch 7/150\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.6190 - accuracy: 0.7640 - val_loss: 1.9075 - val_accuracy: 0.6235\n",
            "Epoch 8/150\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.5823 - accuracy: 0.7840 - val_loss: 1.8958 - val_accuracy: 0.6202\n",
            "Epoch 9/150\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.4253 - accuracy: 0.8360 - val_loss: 1.8805 - val_accuracy: 0.6379\n",
            "Epoch 10/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.3496 - accuracy: 0.8480 - val_loss: 1.8438 - val_accuracy: 0.6423\n",
            "Epoch 11/150\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3222 - accuracy: 0.8720 - val_loss: 1.8736 - val_accuracy: 0.6467\n",
            "Epoch 12/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.2577 - accuracy: 0.8720 - val_loss: 1.8980 - val_accuracy: 0.6379\n",
            "Epoch 13/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.2629 - accuracy: 0.8880 - val_loss: 1.8416 - val_accuracy: 0.6656\n",
            "Epoch 14/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.2243 - accuracy: 0.9320 - val_loss: 1.8475 - val_accuracy: 0.6766\n",
            "Epoch 15/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1873 - accuracy: 0.9400 - val_loss: 1.8874 - val_accuracy: 0.6722\n",
            "Epoch 16/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1488 - accuracy: 0.9440 - val_loss: 1.8959 - val_accuracy: 0.6755\n",
            "Epoch 17/150\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1531 - accuracy: 0.9480 - val_loss: 1.9067 - val_accuracy: 0.6733\n",
            "Epoch 18/150\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1415 - accuracy: 0.9400 - val_loss: 1.8940 - val_accuracy: 0.6744\n",
            "250\n",
            "accuracy german 0.9147933284989123\n",
            "b_accuracy german 0.9036917754778249\n",
            "None\n",
            "accuracy french test 0.6780973451327433\n",
            "b_accuracy french test 0.6762455252081448\n",
            "None\n",
            "accuracy french val 0.6744186046511628\n",
            "b_accuracy french val 0.6557463991463549\n",
            "None\n",
            "accuracy french train 0.6904761904761905\n",
            "b_accuracy french train 0.7011949414289238\n",
            "None\n",
            "Epoch 1/150\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 2.0807 - accuracy: 0.6860 - val_loss: 1.4493 - val_accuracy: 0.6944\n",
            "Epoch 2/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.9878 - accuracy: 0.7580 - val_loss: 1.3213 - val_accuracy: 0.7121\n",
            "Epoch 3/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.8149 - accuracy: 0.7680 - val_loss: 1.2945 - val_accuracy: 0.7254\n",
            "Epoch 4/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5623 - accuracy: 0.8060 - val_loss: 1.2901 - val_accuracy: 0.7076\n",
            "Epoch 5/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.4392 - accuracy: 0.8540 - val_loss: 1.3042 - val_accuracy: 0.7021\n",
            "Epoch 6/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.3751 - accuracy: 0.8680 - val_loss: 1.3407 - val_accuracy: 0.7087\n",
            "Epoch 7/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.3064 - accuracy: 0.8800 - val_loss: 1.3438 - val_accuracy: 0.7110\n",
            "Epoch 8/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.2616 - accuracy: 0.8900 - val_loss: 1.3416 - val_accuracy: 0.7176\n",
            "Epoch 9/150\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.2404 - accuracy: 0.9000 - val_loss: 1.3508 - val_accuracy: 0.7220\n",
            "500\n",
            "accuracy german 0.9042784626540972\n",
            "b_accuracy german 0.9027537561722697\n",
            "None\n",
            "accuracy french test 0.745575221238938\n",
            "b_accuracy french test 0.6972245979397033\n",
            "None\n",
            "accuracy french val 0.7220376522702104\n",
            "b_accuracy french val 0.6982833956270971\n",
            "None\n",
            "accuracy french train 0.7596899224806202\n",
            "b_accuracy french train 0.7442781584127348\n",
            "None\n",
            "Epoch 1/150\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1.6422 - accuracy: 0.7160 - val_loss: 1.1407 - val_accuracy: 0.7309\n",
            "Epoch 2/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.9501 - accuracy: 0.7570 - val_loss: 1.0600 - val_accuracy: 0.7442\n",
            "Epoch 3/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6739 - accuracy: 0.7980 - val_loss: 1.0558 - val_accuracy: 0.7652\n",
            "Epoch 4/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4458 - accuracy: 0.8460 - val_loss: 1.0429 - val_accuracy: 0.7530\n",
            "Epoch 5/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3923 - accuracy: 0.8540 - val_loss: 1.0070 - val_accuracy: 0.7641\n",
            "Epoch 6/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3043 - accuracy: 0.8900 - val_loss: 1.0040 - val_accuracy: 0.7697\n",
            "Epoch 7/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2479 - accuracy: 0.8940 - val_loss: 0.9835 - val_accuracy: 0.7829\n",
            "Epoch 8/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1962 - accuracy: 0.9150 - val_loss: 0.9758 - val_accuracy: 0.7929\n",
            "Epoch 9/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2254 - accuracy: 0.9150 - val_loss: 1.0397 - val_accuracy: 0.7752\n",
            "Epoch 10/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.9300 - val_loss: 1.0447 - val_accuracy: 0.7752\n",
            "Epoch 11/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1504 - accuracy: 0.9290 - val_loss: 0.9791 - val_accuracy: 0.7829\n",
            "Epoch 12/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1132 - accuracy: 0.9430 - val_loss: 0.9987 - val_accuracy: 0.7829\n",
            "Epoch 13/150\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1293 - accuracy: 0.9410 - val_loss: 1.0051 - val_accuracy: 0.7818\n",
            "1000\n",
            "accuracy german 0.8897751994198695\n",
            "b_accuracy german 0.8701177472977338\n",
            "None\n",
            "accuracy french test 0.7997787610619469\n",
            "b_accuracy french test 0.7565773061700218\n",
            "None\n",
            "accuracy french val 0.7818383167220376\n",
            "b_accuracy french val 0.7546720790713006\n",
            "None\n",
            "accuracy french train 0.8305647840531561\n",
            "b_accuracy french train 0.8064340293157785\n",
            "None\n",
            "Epoch 1/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.0744 - accuracy: 0.7865 - val_loss: 0.8276 - val_accuracy: 0.8151\n",
            "Epoch 2/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.6083 - accuracy: 0.8195 - val_loss: 0.7733 - val_accuracy: 0.8117\n",
            "Epoch 3/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8595 - val_loss: 0.7788 - val_accuracy: 0.8106\n",
            "Epoch 4/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3391 - accuracy: 0.8770 - val_loss: 0.7611 - val_accuracy: 0.8073\n",
            "Epoch 5/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.2767 - accuracy: 0.8850 - val_loss: 0.7882 - val_accuracy: 0.8162\n",
            "Epoch 6/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.2280 - accuracy: 0.8990 - val_loss: 0.7328 - val_accuracy: 0.8261\n",
            "Epoch 7/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.2032 - accuracy: 0.9140 - val_loss: 0.7343 - val_accuracy: 0.8272\n",
            "Epoch 8/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.1550 - accuracy: 0.9325 - val_loss: 0.7536 - val_accuracy: 0.8239\n",
            "Epoch 9/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.1730 - accuracy: 0.9250 - val_loss: 0.8110 - val_accuracy: 0.8228\n",
            "Epoch 10/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.1534 - accuracy: 0.9285 - val_loss: 0.7425 - val_accuracy: 0.8295\n",
            "Epoch 11/150\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.1290 - accuracy: 0.9450 - val_loss: 0.7477 - val_accuracy: 0.8427\n",
            "2000\n",
            "accuracy german 0.889050036258158\n",
            "b_accuracy german 0.8784433077605613\n",
            "None\n",
            "accuracy french test 0.8584070796460177\n",
            "b_accuracy french test 0.8289639123923703\n",
            "None\n",
            "accuracy french val 0.8427464008859358\n",
            "b_accuracy french val 0.8137678409519846\n",
            "None\n",
            "accuracy french train 0.9008859357696567\n",
            "b_accuracy french train 0.8954537437910431\n",
            "None\n",
            "Epoch 1/150\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5110 - accuracy: 0.8632 - val_loss: 0.5421 - val_accuracy: 0.8605\n",
            "Epoch 2/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.2638 - accuracy: 0.9080 - val_loss: 0.4925 - val_accuracy: 0.8793\n",
            "Epoch 3/150\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2001 - accuracy: 0.9236 - val_loss: 0.4617 - val_accuracy: 0.8837\n",
            "Epoch 4/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1586 - accuracy: 0.9356 - val_loss: 0.4601 - val_accuracy: 0.8926\n",
            "Epoch 5/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1331 - accuracy: 0.9440 - val_loss: 0.4550 - val_accuracy: 0.8915\n",
            "Epoch 6/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1139 - accuracy: 0.9510 - val_loss: 0.4527 - val_accuracy: 0.8992\n",
            "Epoch 7/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9530 - val_loss: 0.4395 - val_accuracy: 0.9014\n",
            "Epoch 8/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0829 - accuracy: 0.9654 - val_loss: 0.4376 - val_accuracy: 0.9092\n",
            "Epoch 9/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0712 - accuracy: 0.9662 - val_loss: 0.4486 - val_accuracy: 0.9025\n",
            "Epoch 10/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9722 - val_loss: 0.4471 - val_accuracy: 0.9014\n",
            "Epoch 11/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0603 - accuracy: 0.9714 - val_loss: 0.4580 - val_accuracy: 0.8992\n",
            "Epoch 12/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0548 - accuracy: 0.9756 - val_loss: 0.4469 - val_accuracy: 0.9048\n",
            "Epoch 13/150\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0465 - accuracy: 0.9784 - val_loss: 0.4551 - val_accuracy: 0.8981\n",
            "5000\n",
            "accuracy german 0.8190717911530094\n",
            "b_accuracy german 0.820521534881595\n",
            "None\n",
            "accuracy french test 0.8882743362831859\n",
            "b_accuracy french test 0.881245316567617\n",
            "None\n",
            "accuracy french val 0.8981173864894795\n",
            "b_accuracy french val 0.8927606978023074\n",
            "None\n",
            "accuracy french train 0.9592100406053894\n",
            "b_accuracy french train 0.9605152222940453\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwiSgh6SjS1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_xy(X_test_emb_de,y_test_de,'german',de_cnn2d_transfer)\n",
        "test_xy(X_test_emb_fr,y_test_fr,'french',de_cnn2d_transfer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-alnrBeUhh9M",
        "colab_type": "text"
      },
      "source": [
        "2D trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0aMETWFnrKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class text_to_embed(object):\n",
        "    '''\n",
        "    takes text and embeddingmodel as input and outputs sequence of embeddings\n",
        "    '''\n",
        "    def __init__(self\n",
        "                 , text = None\n",
        "                 , embed_de = None\n",
        "                 , embed_fr = None\n",
        "                 , seq_len = None\n",
        "                 , rep_dict = rep_dict\n",
        "                 , embedding_dim=300):\n",
        "                 \n",
        "        self.text = text\n",
        "        self.embed_de = embed_de\n",
        "        self.embed_fr = embed_fr\n",
        "        self.seq_len = seq_len\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def t2s(self,line):\n",
        "        sen_embed = np.zeros((self.embedding_dim,self.seq_len))\n",
        "        words = line.split()\n",
        "        for w in range(0,self.seq_len):\n",
        "            try: \n",
        "                emb_fr = self.embed_fr[words[w]]\n",
        "                emb_de = self.embed_de[words[w]]\n",
        "                \n",
        "            except:\n",
        "                emb_de = np.zeros(embedding_dim)\n",
        "                emb_fr = np.zeros(embedding_dim)\n",
        "            #try: \n",
        "            #    emb_fr = self.embed_fr[words[w]]\n",
        "            #except:\n",
        "            #    emb_fr = np.zeros(embedding_dim)\n",
        "\n",
        "            emb_de = np.expand_dims(emb_de, axis=0)\n",
        "            emb_fr = np.expand_dims(emb_fr, axis=0)\n",
        "\n",
        "            if w == 0 :\n",
        "                sen_embed_de = emb_de\n",
        "                sen_embed_fr = emb_fr\n",
        "            else:\n",
        "                sen_embed_de = np.concatenate([sen_embed_de,emb_de],axis=0)\n",
        "                sen_embed_fr = np.concatenate([sen_embed_fr,emb_fr],axis=0)\n",
        "\n",
        "        sen_emb = np.stack([sen_embed_de,sen_embed_fr],axis=0)\n",
        "        return sen_emb #np.array(tokens)\n",
        "\n",
        "    def t2s_old(self,line):\n",
        "        #tokens = []\n",
        "        sen_embed = np.zeros((self.embedding_dim,self.seq_len))\n",
        "        words = line.split()\n",
        "        for w in range(0,self.seq_len):\n",
        "            try: \n",
        "              if la == 'de':\n",
        "                  emb = self.embed_de[words[w]]\n",
        "              elif la == 'fr':\n",
        "                  emb = self.embed_fr[words[w]]\n",
        "              else:\n",
        "                  print(la)\n",
        "                  emb = np.zeros(self.embedding_dim)\n",
        "            except:\n",
        "                emb = np.zeros(self.embedding_dim)\n",
        "            #tokens.append(tok)\n",
        "            sen_embed[:,w] = emb\n",
        "\n",
        "        sen_embed = np.swapaxes(sen_embed,0,1)\n",
        "        return sen_embed #np.array(tokens)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for line in tqdm(self.text):\n",
        "            line = self.t2s(line)\n",
        "            yield line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK7NG-6DovR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_emb_de = np.array(list(text_to_embed(X_train_de,  de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_val_emb_de = np.array(list(text_to_embed(X_val_de, de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_test_emb_de = np.array(list(text_to_embed(X_test_de, de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "\n",
        "X_train_emb_fr = np.array(list(text_to_embed(X_train_fr, de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_val_emb_fr = np.array(list(text_to_embed(X_val_fr, de_git_embed, fr_git_embed, seq_len=seq_len)))\n",
        "X_test_emb_fr = np.array(list(text_to_embed(X_test_fr, de_git_embed, fr_git_embed, seq_len=seq_len)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9l9t7lkXE_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('de',X_train_emb_de.shape, X_val_emb_de.shape, X_test_emb_de.shape)\n",
        "print('fr',X_train_emb_fr.shape, X_val_emb_fr.shape, X_test_emb_fr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqj8BjLldKm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_emb_de = np.swapaxes(X_train_emb_de,2,3)\n",
        "X_val_emb_de = np.swapaxes(X_val_emb_de,2,3)\n",
        "X_test_emb_de = np.swapaxes(X_test_emb_de,2,3)\n",
        "\n",
        "X_train_emb_fr = np.swapaxes(X_train_emb_fr,2,3)\n",
        "X_val_emb_fr = np.swapaxes(X_val_emb_fr,2,3)\n",
        "X_test_emb_fr = np.swapaxes(X_test_emb_fr,2,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t61BbGrZXEvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,GlobalAveragePooling2D,Dropout,Flatten,AveragePooling2D\n",
        "dropout_rate=.30\n",
        "\n",
        "input_layer = Input(shape = (2,embedding_dim,seq_len,), name='text_input')\n",
        "#pool_layer = AveragePooling2D(pool_size=(2, 1),name='avg_pooling2')(input_layer)\n",
        "conv_layer = Conv2D(10, kernel_size=(100, 10), activation='relu', padding=\"same\")(input_layer)\n",
        "pool_layer = AveragePooling2D(pool_size=(1, 5),name='avg_pooling3')(conv_layer)\n",
        "pool_layer = AveragePooling2D(pool_size=(2, 1),name='avg_pooling2')(pool_layer)\n",
        "conv_layer = Conv2D(5, kernel_size=(50, 2), activation='relu', padding=\"same\")(pool_layer)\n",
        "#pool_layer = AveragePooling2D(pool_size=(1, 5),name='avg_pooling3')(conv_layer)\n",
        "#conv_layer = Conv2D(50, kernel_size=(3, 3), activation='relu', padding=\"same\")(conv_layer)\n",
        "#conv_layer = AveragePooling2D(pool_size=(1, 3),name='avg_pooling3')(conv_layer)\n",
        "#mask_layer = Masking(mask_value=0.)(input_layer)\n",
        "#pool_layer = AveragePooling2D(pool_size=(2, 1),name='avg_pooling')(conv_layer)\n",
        "pool_layer = Flatten()(conv_layer)\n",
        "#pool_layer = GlobalAveragePooling2D(name='avg_pooling')(pool_layer)\n",
        "dens_layer = Dense(150, activation='relu',name='dense')(pool_layer)\n",
        "drop_layer = Dropout(dropout_rate)(pool_layer)\n",
        "pred_layer_3 = Dense(no_Classes, activation = 'softmax', name='out')(drop_layer) \n",
        "\n",
        "de_avg_pool = Model(inputs = [input_layer], outputs = [pred_layer_3])\n",
        "\n",
        "lr = .001\n",
        "opt = Adam(lr=lr, decay=lr/200)\n",
        "de_avg_pool.summary()\n",
        "de_avg_pool.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "hist = de_avg_pool.fit(x = X_train_emb_de, y = y_train_enc_de,\\\n",
        "                validation_data = (X_val_emb_de, y_val_enc_de), \\\n",
        "                epochs = 100, batch_size = 256, shuffle = True, \\\n",
        "                class_weight = class_weight_dict_de, \\\n",
        "                callbacks = [early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV1nqSl1XEr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,balanced_accuracy_score,confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def test_xy(X,y,string,model):\n",
        "    y_pred = model.predict([X])\n",
        "    y_pred_arg = y_pred.argmax(axis=1)\n",
        "    pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "    print('accuracy %s'% string,accuracy_score(pred,y))\n",
        "    print('b_accuracy %s'%  string,balanced_accuracy_score(pred, y))\n",
        "    #return pred, y\n",
        "\n",
        "#test_xy(X_test_emb_de,y_test_de,'together')\n",
        "test_xy(X_test_emb_de,y_test_de,'german',de_avg_pool)\n",
        "test_xy(X_test_emb_fr,y_test_fr,'french',de_avg_pool)\n",
        "#print(classification_report(y,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yho3MuOCQkNE",
        "colab_type": "text"
      },
      "source": [
        "aa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zESsGd7UHiw",
        "colab_type": "text"
      },
      "source": [
        "# Multilingual Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmpt9P4RQxqn",
        "colab_type": "text"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "150UxiyYfHBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_emb =  np.concatenate((X_train_emb_de, X_train_emb_fr))\n",
        "y_train_enc =  np.concatenate((y_train_enc_de, y_train_enc_fr))\n",
        "X_val_emb =  np.concatenate((X_val_emb_de, X_val_emb_fr))\n",
        "y_val_enc =  np.concatenate((y_val_enc_de, y_val_enc_fr))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVr10pC0E_Js",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c083312-0f98-44e8-bc67-7bd6e939dcac"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Bidirectional, GlobalAveragePooling1D, Concatenate,LSTM,BatchNormalization,Add,Masking,GlobalMaxPooling1D,Conv1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "dropout_rate=.7\n",
        "\n",
        "input_imbd_1 = Input(shape = (seq_len,embedding_dim,), name='text_input')\n",
        "mask_layer = Masking(mask_value=0.)(input_imbd_1)\n",
        "conv_layer = Conv1D(filters=200,   kernel_size= 10,   padding='valid',  activation='relu', strides=1)(input_imbd_1)\n",
        "#lstm_layer_1 = Bidirectional(LSTM(128,activation = 'tanh',recurrent_activation = 'sigmoid', dropout = dropout_rate,recurrent_dropout = 0, unroll = False,use_bias = True))(conv_layer)\n",
        "lstm_layer_1 = GlobalAveragePooling1D()(conv_layer)\n",
        "#lstm_layer_1 = GlobalMaxPooling1D()(conv_layer)\n",
        "dens_layer_1 = Dense(120, activation='relu')(lstm_layer_1)\n",
        "drop_layer_1 = Dropout(dropout_rate)(dens_layer_1)\n",
        "pred_layer_3 = Dense(74, activation = 'softmax', name='o3')(drop_layer_1) \n",
        "\n",
        "de_cnn_avg = Model(inputs = [input_imbd_1], outputs = [pred_layer_3])\n",
        "de_cnn_avg.summary()\n",
        "lr = .005\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "de_cnn_avg.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "de_cnn_avg.summary()\n",
        "hist = de_cnn_avg.fit(x = X_train_emb, y = y_train_enc,\\\n",
        "                validation_data = (X_val_emb, y_val_enc), \\\n",
        "                epochs = 150, batch_size = 64, shuffle = True, \\\n",
        "                class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 39, 300)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_37 (Conv1D)           (None, 30, 200)           600200    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_15  (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 120)               24120     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "o3 (Dense)                   (None, 74)                8954      \n",
            "=================================================================\n",
            "Total params: 633,274\n",
            "Trainable params: 633,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      [(None, 39, 300)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_37 (Conv1D)           (None, 30, 200)           600200    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_15  (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 120)               24120     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "o3 (Dense)                   (None, 74)                8954      \n",
            "=================================================================\n",
            "Total params: 633,274\n",
            "Trainable params: 633,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 3.6321 - accuracy: 0.1137 - val_loss: 2.2817 - val_accuracy: 0.4318\n",
            "Epoch 2/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 2.3228 - accuracy: 0.3193 - val_loss: 1.4740 - val_accuracy: 0.6012\n",
            "Epoch 3/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 1.7393 - accuracy: 0.4612 - val_loss: 1.0665 - val_accuracy: 0.6982\n",
            "Epoch 4/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 1.4035 - accuracy: 0.5578 - val_loss: 0.9405 - val_accuracy: 0.7326\n",
            "Epoch 5/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 1.1752 - accuracy: 0.6323 - val_loss: 0.7184 - val_accuracy: 0.8066\n",
            "Epoch 6/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 1.0420 - accuracy: 0.6732 - val_loss: 0.6473 - val_accuracy: 0.8170\n",
            "Epoch 7/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.9154 - accuracy: 0.7043 - val_loss: 0.5667 - val_accuracy: 0.8487\n",
            "Epoch 8/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.8332 - accuracy: 0.7346 - val_loss: 0.5361 - val_accuracy: 0.8487\n",
            "Epoch 9/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.7790 - accuracy: 0.7525 - val_loss: 0.4896 - val_accuracy: 0.8686\n",
            "Epoch 10/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.7156 - accuracy: 0.7765 - val_loss: 0.4577 - val_accuracy: 0.8746\n",
            "Epoch 11/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.6271 - accuracy: 0.7966 - val_loss: 0.4402 - val_accuracy: 0.8831\n",
            "Epoch 12/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.5936 - accuracy: 0.8087 - val_loss: 0.4167 - val_accuracy: 0.8861\n",
            "Epoch 13/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.5551 - accuracy: 0.8155 - val_loss: 0.4067 - val_accuracy: 0.8896\n",
            "Epoch 14/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.5130 - accuracy: 0.8293 - val_loss: 0.3741 - val_accuracy: 0.9063\n",
            "Epoch 15/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.4649 - accuracy: 0.8432 - val_loss: 0.3583 - val_accuracy: 0.9077\n",
            "Epoch 16/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.4627 - accuracy: 0.8450 - val_loss: 0.3766 - val_accuracy: 0.8970\n",
            "Epoch 17/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.4239 - accuracy: 0.8551 - val_loss: 0.3524 - val_accuracy: 0.9079\n",
            "Epoch 18/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.3986 - accuracy: 0.8607 - val_loss: 0.3365 - val_accuracy: 0.9134\n",
            "Epoch 19/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.3823 - accuracy: 0.8704 - val_loss: 0.3349 - val_accuracy: 0.9205\n",
            "Epoch 20/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.3558 - accuracy: 0.8776 - val_loss: 0.3482 - val_accuracy: 0.9186\n",
            "Epoch 21/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.3465 - accuracy: 0.8803 - val_loss: 0.3504 - val_accuracy: 0.9140\n",
            "Epoch 22/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.3256 - accuracy: 0.8834 - val_loss: 0.3551 - val_accuracy: 0.9172\n",
            "Epoch 23/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.3085 - accuracy: 0.8919 - val_loss: 0.3336 - val_accuracy: 0.9287\n",
            "Epoch 24/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.3045 - accuracy: 0.8907 - val_loss: 0.3181 - val_accuracy: 0.9323\n",
            "Epoch 25/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2874 - accuracy: 0.9034 - val_loss: 0.3283 - val_accuracy: 0.9241\n",
            "Epoch 26/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2849 - accuracy: 0.9018 - val_loss: 0.3184 - val_accuracy: 0.9298\n",
            "Epoch 27/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2484 - accuracy: 0.9102 - val_loss: 0.3134 - val_accuracy: 0.9331\n",
            "Epoch 28/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2420 - accuracy: 0.9153 - val_loss: 0.3129 - val_accuracy: 0.9325\n",
            "Epoch 29/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2317 - accuracy: 0.9178 - val_loss: 0.3283 - val_accuracy: 0.9320\n",
            "Epoch 30/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2219 - accuracy: 0.9181 - val_loss: 0.3124 - val_accuracy: 0.9383\n",
            "Epoch 31/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2041 - accuracy: 0.9245 - val_loss: 0.3311 - val_accuracy: 0.9366\n",
            "Epoch 32/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2015 - accuracy: 0.9295 - val_loss: 0.3215 - val_accuracy: 0.9364\n",
            "Epoch 33/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2079 - accuracy: 0.9257 - val_loss: 0.3196 - val_accuracy: 0.9394\n",
            "Epoch 34/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.2129 - accuracy: 0.9271 - val_loss: 0.3052 - val_accuracy: 0.9405\n",
            "Epoch 35/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.1935 - accuracy: 0.9319 - val_loss: 0.3102 - val_accuracy: 0.9410\n",
            "Epoch 36/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.1782 - accuracy: 0.9339 - val_loss: 0.3202 - val_accuracy: 0.9446\n",
            "Epoch 37/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.1851 - accuracy: 0.9335 - val_loss: 0.2991 - val_accuracy: 0.9467\n",
            "Epoch 38/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.1741 - accuracy: 0.9369 - val_loss: 0.3084 - val_accuracy: 0.9435\n",
            "Epoch 39/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.1705 - accuracy: 0.9388 - val_loss: 0.3232 - val_accuracy: 0.9396\n",
            "Epoch 40/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.1586 - accuracy: 0.9440 - val_loss: 0.3082 - val_accuracy: 0.9432\n",
            "Epoch 41/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.1596 - accuracy: 0.9413 - val_loss: 0.3117 - val_accuracy: 0.9451\n",
            "Epoch 42/150\n",
            "344/344 [==============================] - 2s 6ms/step - loss: 0.1570 - accuracy: 0.9442 - val_loss: 0.3359 - val_accuracy: 0.9372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RcuXJqptjaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f0016867-2118-4360-8ebc-45773751cc90"
      },
      "source": [
        "import json\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "def test_xy(X,y,string):\n",
        "    y_pred = de_cnn_avg.predict([X])\n",
        "    y_pred_arg = y_pred.argmax(axis=1)\n",
        "    pred= [encoder.classes_[y] for y in y_pred_arg]\n",
        "    print('accuracy %s'% string,accuracy_score(pred,y))\n",
        "    print('b_accuracy %s'%  string,balanced_accuracy_score(pred, y))\n",
        "\n",
        "test_xy(X_test_emb_de,y_test_de,'german')\n",
        "test_xy(X_test_emb_fr,y_test_fr,'french')\n",
        "#print(classification_report(pred, df_test['cc5']))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy german 0.9463379260333575\n",
            "b_accuracy german 0.9150452014553112\n",
            "accuracy french 0.9413716814159292\n",
            "b_accuracy french 0.9202670150344703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DYOFTWRwvRq",
        "colab_type": "text"
      },
      "source": [
        "## CNN with training embedding ayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn4dwTf0H7JD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        " def run_ml_CNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\n",
        "             vocab_size,embedding_matrix,class_weight_dict,no):\n",
        "   \n",
        "    X_train_pad =  np.concatenate((X_train_pad_de, X_train_pad_fr[:no]))\n",
        "    y_train_enc =  np.concatenate((y_train_enc_de, y_train_enc_fr[:no]))\n",
        "\n",
        "    imbala = int(len(X_train_pad_de)/no)\n",
        "    for n in range(1,imbala):\n",
        "        X_train_pad =  np.concatenate((X_train_pad, X_train_pad_fr[:no]))\n",
        "        y_train_enc =  np.concatenate((y_train_enc, y_train_enc_fr[:no]))\n",
        "    X_val_pad =  np.concatenate((X_val_pad_de, X_val_pad_fr))\n",
        "    y_val_enc =  np.concatenate((y_val_enc_de, y_val_enc_fr))\n",
        "    print(len(X_train_pad))\n",
        "\n",
        "    dropout_rate=.7\n",
        "    lr = .0003\n",
        "    opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "    input_layer = Input(shape = (seq_len,), dtype = 'float')\n",
        "    embedd_seq = Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "    norma_layer = BatchNormalization()(embedd_seq)\n",
        "    convo_layer = Conv1D(filters=300,   kernel_size= 5,   padding='valid',  activation='relu', strides=1)(norma_layer)\n",
        "    norma_layer = BatchNormalization()(convo_layer)\n",
        "    pool_layer = GlobalMaxPooling1D()(norma_layer)\n",
        "    #pool_layer = GlobalAveragePooling1D()(convo_layer)\n",
        "    dens_layer_1 = Dense(150, activation='relu')(pool_layer)\n",
        "    drop_layer = Dropout(dropout_rate)(dens_layer_1)\n",
        "    pred_layer = Dense(y_train_enc.shape[1], activation = 'softmax')(drop_layer) #, kernel_regularizer=l1_l2(0.001)\n",
        "\n",
        "    cnn_de_fr = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "    cnn_de_fr.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = cnn_de_fr.fit(x = X_train_pad, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_pad, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 256, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test_de = cnn_de_fr.predict(X_test_pad_de)\n",
        "    y_pred_arg_de = y_pred_test_de.argmax(axis=1)\n",
        "    y_pred_test_de = [encoder.classes_[y] for y in y_pred_arg_de]\n",
        "\n",
        "    y_pred_test_fr = cnn_de_fr.predict(X_test_pad_fr)\n",
        "    y_pred_arg_fr = y_pred_test_fr.argmax(axis=1)\n",
        "    y_pred_test_fr= [encoder.classes_[y] for y in y_pred_arg_fr]\n",
        "\n",
        "    print('de test obs.',no,'accuracy %s' % accuracy_score(y_pred_test_de, y_test_de))\n",
        "    print('de test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test_de, y_test_de))\n",
        "    print('fr test obs.',no,'accuracy %s' % accuracy_score(y_pred_test_fr, y_test_fr))\n",
        "    print('fr test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test_fr, y_test_fr))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3AiEmrgJrE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3ddd464-9233-45d8-8cc1-f11ed8ce6870"
      },
      "source": [
        "for obs in [500,1000,2000,5000]:\n",
        "     run_ml_CNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\n",
        "             vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33048\n",
            "Epoch 1/50\n",
            "130/130 [==============================] - 5s 40ms/step - loss: 4.8471 - accuracy: 0.0629 - val_loss: 4.2809 - val_accuracy: 0.0322\n",
            "Epoch 2/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 3.1449 - accuracy: 0.2092 - val_loss: 4.0271 - val_accuracy: 0.0904\n",
            "Epoch 3/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 2.3285 - accuracy: 0.3585 - val_loss: 3.4291 - val_accuracy: 0.3677\n",
            "Epoch 4/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 1.7939 - accuracy: 0.4870 - val_loss: 2.4378 - val_accuracy: 0.6657\n",
            "Epoch 5/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 1.3545 - accuracy: 0.6069 - val_loss: 1.4858 - val_accuracy: 0.7804\n",
            "Epoch 6/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 1.1214 - accuracy: 0.6773 - val_loss: 1.1629 - val_accuracy: 0.7845\n",
            "Epoch 7/50\n",
            "130/130 [==============================] - 5s 38ms/step - loss: 0.8804 - accuracy: 0.7403 - val_loss: 0.9480 - val_accuracy: 0.8170\n",
            "Epoch 8/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.8265 - accuracy: 0.7666 - val_loss: 0.8730 - val_accuracy: 0.8252\n",
            "Epoch 9/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.6881 - accuracy: 0.8011 - val_loss: 0.7583 - val_accuracy: 0.8462\n",
            "Epoch 10/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.5841 - accuracy: 0.8356 - val_loss: 0.7518 - val_accuracy: 0.8511\n",
            "Epoch 11/50\n",
            "130/130 [==============================] - 5s 38ms/step - loss: 0.5840 - accuracy: 0.8349 - val_loss: 0.7571 - val_accuracy: 0.8468\n",
            "Epoch 12/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.5118 - accuracy: 0.8534 - val_loss: 0.7519 - val_accuracy: 0.8462\n",
            "Epoch 13/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.4604 - accuracy: 0.8701 - val_loss: 0.6665 - val_accuracy: 0.8645\n",
            "Epoch 14/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.3668 - accuracy: 0.8912 - val_loss: 0.6382 - val_accuracy: 0.8749\n",
            "Epoch 15/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.3348 - accuracy: 0.9027 - val_loss: 0.6541 - val_accuracy: 0.8689\n",
            "Epoch 16/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.2864 - accuracy: 0.9137 - val_loss: 0.6708 - val_accuracy: 0.8754\n",
            "Epoch 17/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.2816 - accuracy: 0.9152 - val_loss: 0.6795 - val_accuracy: 0.8640\n",
            "Epoch 18/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.2864 - accuracy: 0.9168 - val_loss: 0.6401 - val_accuracy: 0.8757\n",
            "Epoch 19/50\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.2664 - accuracy: 0.9230 - val_loss: 0.7112 - val_accuracy: 0.8686\n",
            "de test obs. 500 accuracy 0.9376359680928209\n",
            "de test obs. 500 b_accuracy 0.908852051920183\n",
            "fr test obs. 500 accuracy 0.6404867256637168\n",
            "fr test obs. 500 b_accuracy 0.6502091772839098\n",
            "32548\n",
            "Epoch 1/50\n",
            "128/128 [==============================] - 5s 41ms/step - loss: 4.9475 - accuracy: 0.0453 - val_loss: 4.3086 - val_accuracy: 0.0180\n",
            "Epoch 2/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 3.4879 - accuracy: 0.1641 - val_loss: 4.1115 - val_accuracy: 0.0871\n",
            "Epoch 3/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 2.6596 - accuracy: 0.2971 - val_loss: 3.5320 - val_accuracy: 0.3130\n",
            "Epoch 4/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 2.0284 - accuracy: 0.4356 - val_loss: 2.6908 - val_accuracy: 0.4955\n",
            "Epoch 5/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 1.6328 - accuracy: 0.5410 - val_loss: 1.6627 - val_accuracy: 0.7462\n",
            "Epoch 6/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 1.2898 - accuracy: 0.6297 - val_loss: 1.1906 - val_accuracy: 0.7869\n",
            "Epoch 7/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 1.0485 - accuracy: 0.6964 - val_loss: 0.7756 - val_accuracy: 0.8580\n",
            "Epoch 8/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.8747 - accuracy: 0.7456 - val_loss: 0.8087 - val_accuracy: 0.8399\n",
            "Epoch 9/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.8355 - accuracy: 0.7532 - val_loss: 0.6611 - val_accuracy: 0.8727\n",
            "Epoch 10/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.6774 - accuracy: 0.7988 - val_loss: 0.5825 - val_accuracy: 0.8853\n",
            "Epoch 11/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 0.5623 - accuracy: 0.8363 - val_loss: 0.5707 - val_accuracy: 0.8894\n",
            "Epoch 12/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.5418 - accuracy: 0.8431 - val_loss: 0.5323 - val_accuracy: 0.8905\n",
            "Epoch 13/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.3955 - accuracy: 0.8796 - val_loss: 0.5649 - val_accuracy: 0.8924\n",
            "Epoch 14/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.4945 - accuracy: 0.8565 - val_loss: 0.5361 - val_accuracy: 0.9030\n",
            "Epoch 15/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 0.3615 - accuracy: 0.8898 - val_loss: 0.5368 - val_accuracy: 0.9022\n",
            "Epoch 16/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 0.3461 - accuracy: 0.8992 - val_loss: 0.5858 - val_accuracy: 0.8864\n",
            "Epoch 17/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.3220 - accuracy: 0.9018 - val_loss: 0.5300 - val_accuracy: 0.9011\n",
            "Epoch 18/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.2945 - accuracy: 0.9088 - val_loss: 0.5252 - val_accuracy: 0.9036\n",
            "Epoch 19/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.2953 - accuracy: 0.9161 - val_loss: 0.5385 - val_accuracy: 0.8981\n",
            "Epoch 20/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.2984 - accuracy: 0.9129 - val_loss: 0.5376 - val_accuracy: 0.9063\n",
            "Epoch 21/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.2658 - accuracy: 0.9243 - val_loss: 0.5523 - val_accuracy: 0.9039\n",
            "Epoch 22/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.2510 - accuracy: 0.9235 - val_loss: 0.5804 - val_accuracy: 0.9039\n",
            "Epoch 23/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.2062 - accuracy: 0.9368 - val_loss: 0.6463 - val_accuracy: 0.8976\n",
            "de test obs. 1000 accuracy 0.9405366207396664\n",
            "de test obs. 1000 b_accuracy 0.9125350520716138\n",
            "fr test obs. 1000 accuracy 0.745575221238938\n",
            "fr test obs. 1000 b_accuracy 0.7305826221328642\n",
            "32548\n",
            "Epoch 1/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 5.2612 - accuracy: 0.0371 - val_loss: 4.2786 - val_accuracy: 0.0423\n",
            "Epoch 2/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 3.8858 - accuracy: 0.1202 - val_loss: 4.1805 - val_accuracy: 0.0694\n",
            "Epoch 3/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 3.0377 - accuracy: 0.2359 - val_loss: 3.6348 - val_accuracy: 0.2707\n",
            "Epoch 4/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 2.3365 - accuracy: 0.3588 - val_loss: 2.6575 - val_accuracy: 0.5040\n",
            "Epoch 5/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 1.8399 - accuracy: 0.4737 - val_loss: 1.6596 - val_accuracy: 0.6837\n",
            "Epoch 6/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 1.4761 - accuracy: 0.5711 - val_loss: 1.2161 - val_accuracy: 0.7787\n",
            "Epoch 7/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 1.2859 - accuracy: 0.6185 - val_loss: 0.8328 - val_accuracy: 0.8358\n",
            "Epoch 8/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 1.1378 - accuracy: 0.6604 - val_loss: 0.8827 - val_accuracy: 0.8194\n",
            "Epoch 9/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 1.0378 - accuracy: 0.6862 - val_loss: 0.5878 - val_accuracy: 0.8823\n",
            "Epoch 10/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.7697 - accuracy: 0.7601 - val_loss: 0.5581 - val_accuracy: 0.8817\n",
            "Epoch 11/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.6979 - accuracy: 0.7831 - val_loss: 0.5014 - val_accuracy: 0.8957\n",
            "Epoch 12/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.7023 - accuracy: 0.7885 - val_loss: 0.8320 - val_accuracy: 0.7867\n",
            "Epoch 13/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.6979 - accuracy: 0.7854 - val_loss: 0.4704 - val_accuracy: 0.8987\n",
            "Epoch 14/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.5585 - accuracy: 0.8277 - val_loss: 0.4652 - val_accuracy: 0.9066\n",
            "Epoch 15/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.4767 - accuracy: 0.8503 - val_loss: 0.4204 - val_accuracy: 0.9205\n",
            "Epoch 16/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.4167 - accuracy: 0.8683 - val_loss: 0.4165 - val_accuracy: 0.9227\n",
            "Epoch 17/50\n",
            "128/128 [==============================] - 5s 39ms/step - loss: 0.4241 - accuracy: 0.8743 - val_loss: 0.4189 - val_accuracy: 0.9170\n",
            "Epoch 18/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.3838 - accuracy: 0.8813 - val_loss: 0.4170 - val_accuracy: 0.9194\n",
            "Epoch 19/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.3318 - accuracy: 0.8966 - val_loss: 0.4724 - val_accuracy: 0.9044\n",
            "Epoch 20/50\n",
            "128/128 [==============================] - 5s 38ms/step - loss: 0.3597 - accuracy: 0.8935 - val_loss: 0.4264 - val_accuracy: 0.9205\n",
            "Epoch 21/50\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.2932 - accuracy: 0.9099 - val_loss: 0.4365 - val_accuracy: 0.9183\n",
            "de test obs. 2000 accuracy 0.9394488759970994\n",
            "de test obs. 2000 b_accuracy 0.9127044884067377\n",
            "fr test obs. 2000 accuracy 0.8307522123893806\n",
            "fr test obs. 2000 b_accuracy 0.8335973208000368\n",
            "31548\n",
            "Epoch 1/50\n",
            "124/124 [==============================] - 5s 39ms/step - loss: 5.0602 - accuracy: 0.0347 - val_loss: 4.2569 - val_accuracy: 0.0595\n",
            "Epoch 2/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 3.8817 - accuracy: 0.1183 - val_loss: 4.0633 - val_accuracy: 0.0912\n",
            "Epoch 3/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 3.1616 - accuracy: 0.2144 - val_loss: 3.5299 - val_accuracy: 0.2538\n",
            "Epoch 4/50\n",
            "124/124 [==============================] - 5s 38ms/step - loss: 2.5272 - accuracy: 0.3337 - val_loss: 2.8058 - val_accuracy: 0.4043\n",
            "Epoch 5/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 2.0316 - accuracy: 0.4401 - val_loss: 1.7144 - val_accuracy: 0.6927\n",
            "Epoch 6/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 1.6664 - accuracy: 0.5314 - val_loss: 1.1587 - val_accuracy: 0.7880\n",
            "Epoch 7/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 1.3037 - accuracy: 0.6113 - val_loss: 0.7424 - val_accuracy: 0.8418\n",
            "Epoch 8/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 1.1665 - accuracy: 0.6517 - val_loss: 0.5755 - val_accuracy: 0.8719\n",
            "Epoch 9/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.9571 - accuracy: 0.7055 - val_loss: 0.5704 - val_accuracy: 0.8804\n",
            "Epoch 10/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.8921 - accuracy: 0.7260 - val_loss: 0.4914 - val_accuracy: 0.8921\n",
            "Epoch 11/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.8238 - accuracy: 0.7482 - val_loss: 0.4622 - val_accuracy: 0.9025\n",
            "Epoch 12/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.8067 - accuracy: 0.7561 - val_loss: 0.4873 - val_accuracy: 0.8847\n",
            "Epoch 13/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.6517 - accuracy: 0.7895 - val_loss: 0.3887 - val_accuracy: 0.9134\n",
            "Epoch 14/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.5517 - accuracy: 0.8230 - val_loss: 0.3588 - val_accuracy: 0.9181\n",
            "Epoch 15/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.5751 - accuracy: 0.8202 - val_loss: 0.3315 - val_accuracy: 0.9273\n",
            "Epoch 16/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.5008 - accuracy: 0.8421 - val_loss: 0.3159 - val_accuracy: 0.9314\n",
            "Epoch 17/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.4791 - accuracy: 0.8469 - val_loss: 0.3615 - val_accuracy: 0.9129\n",
            "Epoch 18/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.4607 - accuracy: 0.8587 - val_loss: 0.3076 - val_accuracy: 0.9342\n",
            "Epoch 19/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.4173 - accuracy: 0.8643 - val_loss: 0.2861 - val_accuracy: 0.9380\n",
            "Epoch 20/50\n",
            "124/124 [==============================] - 5s 38ms/step - loss: 0.3875 - accuracy: 0.8800 - val_loss: 0.2863 - val_accuracy: 0.9369\n",
            "Epoch 21/50\n",
            "124/124 [==============================] - 5s 39ms/step - loss: 0.3252 - accuracy: 0.8926 - val_loss: 0.2768 - val_accuracy: 0.9407\n",
            "Epoch 22/50\n",
            "124/124 [==============================] - 5s 39ms/step - loss: 0.2984 - accuracy: 0.9022 - val_loss: 0.2740 - val_accuracy: 0.9451\n",
            "Epoch 23/50\n",
            "124/124 [==============================] - 5s 38ms/step - loss: 0.3046 - accuracy: 0.9014 - val_loss: 0.2897 - val_accuracy: 0.9435\n",
            "Epoch 24/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.2810 - accuracy: 0.9108 - val_loss: 0.2897 - val_accuracy: 0.9418\n",
            "Epoch 25/50\n",
            "124/124 [==============================] - 5s 38ms/step - loss: 0.2384 - accuracy: 0.9215 - val_loss: 0.2742 - val_accuracy: 0.9478\n",
            "Epoch 26/50\n",
            "124/124 [==============================] - 5s 41ms/step - loss: 0.2322 - accuracy: 0.9230 - val_loss: 0.2840 - val_accuracy: 0.9481\n",
            "Epoch 27/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.2385 - accuracy: 0.9223 - val_loss: 0.2642 - val_accuracy: 0.9478\n",
            "Epoch 28/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.2991 - accuracy: 0.9131 - val_loss: 0.2947 - val_accuracy: 0.9448\n",
            "Epoch 29/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.2514 - accuracy: 0.9213 - val_loss: 0.2774 - val_accuracy: 0.9456\n",
            "Epoch 30/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.2613 - accuracy: 0.9216 - val_loss: 0.2652 - val_accuracy: 0.9476\n",
            "Epoch 31/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.2295 - accuracy: 0.9256 - val_loss: 0.3229 - val_accuracy: 0.9407\n",
            "Epoch 32/50\n",
            "124/124 [==============================] - 5s 37ms/step - loss: 0.2285 - accuracy: 0.9254 - val_loss: 0.2728 - val_accuracy: 0.9495\n",
            "de test obs. 5000 accuracy 0.9452501812907904\n",
            "de test obs. 5000 b_accuracy 0.9196836979430996\n",
            "fr test obs. 5000 accuracy 0.922566371681416\n",
            "fr test obs. 5000 b_accuracy 0.9235872549509422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKXvkCXbIxP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_CNN_best(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,vocab_size_de,embedding_matrix_de,class_weight_dict_de)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0m56K1rHIv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "dropout_rate=.6\n",
        "lr = .001\n",
        "opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "input_layer = Input(shape = (seq_len,), dtype = 'float')\n",
        "embedd_seq = Embedding(vocab_size_de_fr, embedding_dim, weights = [embedding_matrix_de_fr], input_length = seq_len, trainable = True, mask_zero=False)(input_layer)\n",
        "conv_layer = Conv1D(filters=100,   kernel_size= 5,   padding='valid',  activation='relu', strides=1)(embedd_seq)\n",
        "pool_layer = GlobalMaxPooling1D(name='max_pool')(conv_layer)\n",
        "#pool_layer = GlobalAveragePooling1D(name='avg_pooling')(conv_layer)\n",
        "dens_layer = Dense(150, activation='tanh',name='dense')(pool_layer)\n",
        "drop_layer = Dropout(dropout_rate)(dens_layer)\n",
        "pred_layer = Dense(y_train_enc.shape[1], activation = 'softmax')(drop_layer) #, kernel_regularizer=l1_l2(0.001)\n",
        "\n",
        "cnn_max_pool_mod = Model(inputs = [input_layer], outputs = pred_layer)\n",
        "cnn_max_pool_mod.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "#print(Ftext_pool.summary())\n",
        "early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "hist = cnn_max_pool_mod.fit(x = X_train_pad, y = y_train_enc,\\\n",
        "                validation_data = (X_val_pad, y_val_enc), \\\n",
        "                epochs = 50, batch_size = 256, shuffle = True, class_weight = class_weight_dict_de_fr, \\\n",
        "                callbacks = [early_stopping])\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "y_pred_t_de = cnn_max_pool_mod.predict(X_test_pad_de)\n",
        "y_pred_arg = y_pred_t_de.argmax(axis=1)\n",
        "y_pred_t_de= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "y_pred_t_fr = cnn_max_pool_mod.predict(X_test_pad_fr)\n",
        "y_pred_arg = y_pred_t_fr.argmax(axis=1)\n",
        "y_pred_t_fr= [encoder.classes_[y] for y in y_pred_arg]\n",
        "\n",
        "print('train obs.','accuracy %s' % accuracy_score(y_pred_t_de, y_test_de))\n",
        "print('train obs.','b_accuracy %s' % balanced_accuracy_score(y_pred_t_de, y_test_de))\n",
        "print('train obs.','accuracy %s' % accuracy_score(y_pred_t_fr, y_test_fr))\n",
        "print('train obs.','b_accuracy %s' % balanced_accuracy_score(y_pred_t_fr, y_test_fr))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jACPf0XjuYX4",
        "colab_type": "text"
      },
      "source": [
        "## CNN2D German - French"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8g0gDoySsWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten,Reshape, GlobalAveragePooling1D,MaxPool2D,AvgPool2D, Concatenate,Conv1D,Conv2D,BatchNormalization,Add,Masking,GlobalMaxPooling1D,LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.regularizers import l1,l2"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ3dKOUgubCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def run_ml_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\n",
        "             vocab_size,embedding_matrix,class_weight_dict,no):\n",
        "   \n",
        "    idx = np.random.randint(len(X_train_pad_fr), size=no)\n",
        "    idx_de = np.random.randint(len(X_train_pad_de), size=len(X_train_pad_fr))\n",
        "\n",
        "    X_train_pad =  np.concatenate((X_train_pad_de[idx_de,:], X_train_pad_fr[idx,:]))\n",
        "    y_train_enc =  np.concatenate((y_train_enc_de[idx_de,:], y_train_enc_fr[idx,:]))\n",
        "\n",
        "    imbala = int(len(X_train_pad_fr)/no)+1\n",
        "    for n in range(1,imbala):\n",
        "        X_train_pad =  np.concatenate((X_train_pad, X_train_pad_fr[idx,:]))\n",
        "        y_train_enc =  np.concatenate((y_train_enc, y_train_enc_fr[idx,:]))\n",
        "\n",
        "    X_val_pad =  np.concatenate((X_val_pad_de, X_val_pad_fr))\n",
        "    y_val_enc =  np.concatenate((y_val_enc_de, y_val_enc_fr))\n",
        "    print(imbala,len(X_train_pad_de),len(X_train_pad))\n",
        "\n",
        "    dropout_rate=.2\n",
        "    filter_sizes = [1,2,5]\n",
        "    num_filters = 75\n",
        "\n",
        "\n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    x = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable = False)(input_layer)\n",
        "    x = Reshape((seq_len, embedding_dim, 1))(x)\n",
        "\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embedding_dim),\n",
        "                                      kernel_initializer='he_normal', activation='relu')(x)                                    \n",
        "        maxpool_pool.append(MaxPool2D(pool_size=(seq_len - filter_sizes[i] + 1, 1))(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "\n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn2d_ml = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "    lr = .001\n",
        "\n",
        "    opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "    de_cnn2d_ml.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "    print(de_cnn2d_ml.summary())\n",
        "    hist = de_cnn2d_ml.fit(x = X_train_pad, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_pad, y_val_enc), \\\n",
        "                    epochs = 100, batch_size = 32, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test_de = de_cnn2d_ml.predict(X_test_pad_de)\n",
        "    y_pred_arg_de = y_pred_test_de.argmax(axis=1)\n",
        "    y_pred_test_de = [encoder.classes_[y] for y in y_pred_arg_de]\n",
        "\n",
        "    y_pred_test_fr = de_cnn2d_ml.predict(X_test_pad_fr)\n",
        "    y_pred_arg_fr = y_pred_test_fr.argmax(axis=1)\n",
        "    y_pred_test_fr= [encoder.classes_[y] for y in y_pred_arg_fr]\n",
        "\n",
        "    print('de test obs.',no,'accuracy %s' % accuracy_score(y_pred_test_de, y_test_de))\n",
        "    print('de test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test_de, y_test_de))\n",
        "    print('fr test obs.',no,'accuracy %s' % accuracy_score(y_pred_test_fr, y_test_fr))\n",
        "    print('fr test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test_fr, y_test_fr))"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qQMqvKEvANb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b6c8702-3b24-4399-e9b8-f0d6e6135de2"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000]:\n",
        "    run_ml_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n",
        "            X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\n",
        "            vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55 16548 10918\n",
            "Model: \"model_112\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_79 (Embedding)        (None, 32, 300)      3637800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_69 (Reshape)            (None, 32, 300, 1)   0           embedding_79[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 32, 1, 75)    22575       reshape_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 31, 1, 75)    45075       reshape_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 28, 1, 75)    112575      reshape_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_249 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_250 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_251 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 3, 1, 75)     0           max_pooling2d_249[0][0]          \n",
            "                                                                 max_pooling2d_250[0][0]          \n",
            "                                                                 max_pooling2d_251[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 74)           16724       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 3,834,749\n",
            "Trainable params: 196,949\n",
            "Non-trainable params: 3,637,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 3.4397 - accuracy: 0.2405 - val_loss: 3.3178 - val_accuracy: 0.2666\n",
            "Epoch 2/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 1.5946 - accuracy: 0.6367 - val_loss: 2.2996 - val_accuracy: 0.4999\n",
            "Epoch 3/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.9773 - accuracy: 0.7805 - val_loss: 1.8159 - val_accuracy: 0.6091\n",
            "Epoch 4/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.6571 - accuracy: 0.8469 - val_loss: 1.4938 - val_accuracy: 0.7004\n",
            "Epoch 5/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.4781 - accuracy: 0.8837 - val_loss: 1.3828 - val_accuracy: 0.7356\n",
            "Epoch 6/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.3790 - accuracy: 0.9112 - val_loss: 1.2627 - val_accuracy: 0.7574\n",
            "Epoch 7/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.2997 - accuracy: 0.9249 - val_loss: 1.1987 - val_accuracy: 0.7697\n",
            "Epoch 8/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.2403 - accuracy: 0.9436 - val_loss: 1.2032 - val_accuracy: 0.7886\n",
            "Epoch 9/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.2022 - accuracy: 0.9533 - val_loss: 1.1994 - val_accuracy: 0.7916\n",
            "Epoch 10/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1728 - accuracy: 0.9570 - val_loss: 1.1917 - val_accuracy: 0.7883\n",
            "Epoch 11/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1480 - accuracy: 0.9633 - val_loss: 1.1701 - val_accuracy: 0.7973\n",
            "Epoch 12/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1282 - accuracy: 0.9664 - val_loss: 1.1540 - val_accuracy: 0.8003\n",
            "Epoch 13/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1125 - accuracy: 0.9698 - val_loss: 1.1891 - val_accuracy: 0.8036\n",
            "Epoch 14/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1013 - accuracy: 0.9731 - val_loss: 1.1892 - val_accuracy: 0.8020\n",
            "Epoch 15/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0894 - accuracy: 0.9755 - val_loss: 1.1397 - val_accuracy: 0.8104\n",
            "Epoch 16/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0803 - accuracy: 0.9805 - val_loss: 1.2070 - val_accuracy: 0.8088\n",
            "Epoch 17/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0672 - accuracy: 0.9803 - val_loss: 1.1836 - val_accuracy: 0.8134\n",
            "Epoch 18/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0584 - accuracy: 0.9834 - val_loss: 1.2142 - val_accuracy: 0.8085\n",
            "Epoch 19/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0548 - accuracy: 0.9829 - val_loss: 1.1967 - val_accuracy: 0.8151\n",
            "Epoch 20/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0463 - accuracy: 0.9864 - val_loss: 1.2097 - val_accuracy: 0.8121\n",
            "de test obs. 100 accuracy 0.9260333575054387\n",
            "de test obs. 100 b_accuracy 0.9084614737644531\n",
            "fr test obs. 100 accuracy 0.4358407079646018\n",
            "fr test obs. 100 b_accuracy 0.3716205287308094\n",
            "22 16548 10918\n",
            "Model: \"model_113\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_80 (Embedding)        (None, 32, 300)      3637800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_70 (Reshape)            (None, 32, 300, 1)   0           embedding_80[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 32, 1, 75)    22575       reshape_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 31, 1, 75)    45075       reshape_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 28, 1, 75)    112575      reshape_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_252 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_253 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_254 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 3, 1, 75)     0           max_pooling2d_252[0][0]          \n",
            "                                                                 max_pooling2d_253[0][0]          \n",
            "                                                                 max_pooling2d_254[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 74)           16724       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 3,834,749\n",
            "Trainable params: 196,949\n",
            "Non-trainable params: 3,637,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 3.9410 - accuracy: 0.1592 - val_loss: 3.3345 - val_accuracy: 0.2505\n",
            "Epoch 2/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 2.0457 - accuracy: 0.5171 - val_loss: 2.2796 - val_accuracy: 0.5012\n",
            "Epoch 3/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 1.1865 - accuracy: 0.7142 - val_loss: 1.6688 - val_accuracy: 0.6452\n",
            "Epoch 4/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.7896 - accuracy: 0.8084 - val_loss: 1.3527 - val_accuracy: 0.7036\n",
            "Epoch 5/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.5559 - accuracy: 0.8630 - val_loss: 1.1320 - val_accuracy: 0.7531\n",
            "Epoch 6/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.4246 - accuracy: 0.8992 - val_loss: 1.0175 - val_accuracy: 0.7834\n",
            "Epoch 7/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.3258 - accuracy: 0.9233 - val_loss: 0.9518 - val_accuracy: 0.8063\n",
            "Epoch 8/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.2657 - accuracy: 0.9350 - val_loss: 0.9152 - val_accuracy: 0.8077\n",
            "Epoch 9/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.2223 - accuracy: 0.9451 - val_loss: 0.8754 - val_accuracy: 0.8235\n",
            "Epoch 10/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1851 - accuracy: 0.9542 - val_loss: 0.8785 - val_accuracy: 0.8214\n",
            "Epoch 11/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1574 - accuracy: 0.9615 - val_loss: 0.8538 - val_accuracy: 0.8274\n",
            "Epoch 12/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1360 - accuracy: 0.9667 - val_loss: 0.8477 - val_accuracy: 0.8331\n",
            "Epoch 13/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1123 - accuracy: 0.9706 - val_loss: 0.8310 - val_accuracy: 0.8386\n",
            "Epoch 14/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1010 - accuracy: 0.9736 - val_loss: 0.8756 - val_accuracy: 0.8306\n",
            "Epoch 15/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0901 - accuracy: 0.9748 - val_loss: 0.8379 - val_accuracy: 0.8364\n",
            "Epoch 16/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0793 - accuracy: 0.9802 - val_loss: 0.8683 - val_accuracy: 0.8391\n",
            "Epoch 17/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0708 - accuracy: 0.9798 - val_loss: 0.8351 - val_accuracy: 0.8435\n",
            "Epoch 18/100\n",
            "342/342 [==============================] - 2s 7ms/step - loss: 0.0608 - accuracy: 0.9840 - val_loss: 0.8530 - val_accuracy: 0.8440\n",
            "de test obs. 250 accuracy 0.9271211022480058\n",
            "de test obs. 250 b_accuracy 0.8982011360248924\n",
            "fr test obs. 250 accuracy 0.5796460176991151\n",
            "fr test obs. 250 b_accuracy 0.5413156988527489\n",
            "11 16548 10918\n",
            "Model: \"model_114\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_81 (Embedding)        (None, 32, 300)      3637800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_71 (Reshape)            (None, 32, 300, 1)   0           embedding_81[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 32, 1, 75)    22575       reshape_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 31, 1, 75)    45075       reshape_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 28, 1, 75)    112575      reshape_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_255 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_256 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_257 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 3, 1, 75)     0           max_pooling2d_255[0][0]          \n",
            "                                                                 max_pooling2d_256[0][0]          \n",
            "                                                                 max_pooling2d_257[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 74)           16724       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 3,834,749\n",
            "Trainable params: 196,949\n",
            "Non-trainable params: 3,637,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "342/342 [==============================] - 2s 7ms/step - loss: 4.2964 - accuracy: 0.1022 - val_loss: 3.5610 - val_accuracy: 0.2109\n",
            "Epoch 2/100\n",
            "342/342 [==============================] - 2s 7ms/step - loss: 2.5192 - accuracy: 0.3944 - val_loss: 2.3960 - val_accuracy: 0.4395\n",
            "Epoch 3/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 1.5031 - accuracy: 0.6149 - val_loss: 1.7071 - val_accuracy: 0.5922\n",
            "Epoch 4/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.9924 - accuracy: 0.7408 - val_loss: 1.3227 - val_accuracy: 0.6933\n",
            "Epoch 5/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.7114 - accuracy: 0.8139 - val_loss: 1.1690 - val_accuracy: 0.7206\n",
            "Epoch 6/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.5289 - accuracy: 0.8540 - val_loss: 0.9922 - val_accuracy: 0.7675\n",
            "Epoch 7/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.4167 - accuracy: 0.8883 - val_loss: 0.8984 - val_accuracy: 0.7902\n",
            "Epoch 8/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.3407 - accuracy: 0.9112 - val_loss: 0.8488 - val_accuracy: 0.7992\n",
            "Epoch 9/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.2816 - accuracy: 0.9270 - val_loss: 0.8231 - val_accuracy: 0.8113\n",
            "Epoch 10/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.2451 - accuracy: 0.9373 - val_loss: 0.7732 - val_accuracy: 0.8257\n",
            "Epoch 11/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1931 - accuracy: 0.9516 - val_loss: 0.7496 - val_accuracy: 0.8356\n",
            "Epoch 12/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1738 - accuracy: 0.9557 - val_loss: 0.7032 - val_accuracy: 0.8438\n",
            "Epoch 13/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1419 - accuracy: 0.9635 - val_loss: 0.6912 - val_accuracy: 0.8454\n",
            "Epoch 14/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1257 - accuracy: 0.9699 - val_loss: 0.6893 - val_accuracy: 0.8495\n",
            "Epoch 15/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.1138 - accuracy: 0.9690 - val_loss: 0.6786 - val_accuracy: 0.8509\n",
            "Epoch 16/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0990 - accuracy: 0.9766 - val_loss: 0.6848 - val_accuracy: 0.8500\n",
            "Epoch 17/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0863 - accuracy: 0.9768 - val_loss: 0.6797 - val_accuracy: 0.8528\n",
            "Epoch 18/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0758 - accuracy: 0.9776 - val_loss: 0.6803 - val_accuracy: 0.8541\n",
            "Epoch 19/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0703 - accuracy: 0.9810 - val_loss: 0.6686 - val_accuracy: 0.8588\n",
            "Epoch 20/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0598 - accuracy: 0.9840 - val_loss: 0.6720 - val_accuracy: 0.8645\n",
            "Epoch 21/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0593 - accuracy: 0.9840 - val_loss: 0.6838 - val_accuracy: 0.8612\n",
            "Epoch 22/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0504 - accuracy: 0.9864 - val_loss: 0.6730 - val_accuracy: 0.8653\n",
            "Epoch 23/100\n",
            "342/342 [==============================] - 2s 5ms/step - loss: 0.0423 - accuracy: 0.9897 - val_loss: 0.7027 - val_accuracy: 0.8577\n",
            "Epoch 24/100\n",
            "342/342 [==============================] - 2s 6ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.7185 - val_accuracy: 0.8541\n",
            "de test obs. 500 accuracy 0.9205946337926033\n",
            "de test obs. 500 b_accuracy 0.8991682618738344\n",
            "fr test obs. 500 accuracy 0.629424778761062\n",
            "fr test obs. 500 b_accuracy 0.6356129148481026\n",
            "6 16548 11418\n",
            "Model: \"model_115\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_82 (Embedding)        (None, 32, 300)      3637800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_72 (Reshape)            (None, 32, 300, 1)   0           embedding_82[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 32, 1, 75)    22575       reshape_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 31, 1, 75)    45075       reshape_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 28, 1, 75)    112575      reshape_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_258 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_259 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_260 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 3, 1, 75)     0           max_pooling2d_258[0][0]          \n",
            "                                                                 max_pooling2d_259[0][0]          \n",
            "                                                                 max_pooling2d_260[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 74)           16724       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 3,834,749\n",
            "Trainable params: 196,949\n",
            "Non-trainable params: 3,637,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 4.0421 - accuracy: 0.1195 - val_loss: 3.4081 - val_accuracy: 0.2497\n",
            "Epoch 2/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 2.4186 - accuracy: 0.4015 - val_loss: 2.2789 - val_accuracy: 0.4928\n",
            "Epoch 3/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 1.5348 - accuracy: 0.5908 - val_loss: 1.6287 - val_accuracy: 0.6526\n",
            "Epoch 4/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 1.0580 - accuracy: 0.7167 - val_loss: 1.2754 - val_accuracy: 0.7105\n",
            "Epoch 5/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.7781 - accuracy: 0.7837 - val_loss: 1.0931 - val_accuracy: 0.7569\n",
            "Epoch 6/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.5978 - accuracy: 0.8265 - val_loss: 0.9766 - val_accuracy: 0.7722\n",
            "Epoch 7/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.4729 - accuracy: 0.8648 - val_loss: 0.8390 - val_accuracy: 0.8129\n",
            "Epoch 8/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.3782 - accuracy: 0.8910 - val_loss: 0.7684 - val_accuracy: 0.8347\n",
            "Epoch 9/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.3098 - accuracy: 0.9101 - val_loss: 0.7595 - val_accuracy: 0.8304\n",
            "Epoch 10/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.2533 - accuracy: 0.9264 - val_loss: 0.6772 - val_accuracy: 0.8566\n",
            "Epoch 11/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.2293 - accuracy: 0.9369 - val_loss: 0.6651 - val_accuracy: 0.8539\n",
            "Epoch 12/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1848 - accuracy: 0.9482 - val_loss: 0.6397 - val_accuracy: 0.8637\n",
            "Epoch 13/100\n",
            "357/357 [==============================] - 2s 5ms/step - loss: 0.1557 - accuracy: 0.9555 - val_loss: 0.6250 - val_accuracy: 0.8694\n",
            "Epoch 14/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1368 - accuracy: 0.9620 - val_loss: 0.6143 - val_accuracy: 0.8719\n",
            "Epoch 15/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1366 - accuracy: 0.9646 - val_loss: 0.6297 - val_accuracy: 0.8629\n",
            "Epoch 16/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1078 - accuracy: 0.9709 - val_loss: 0.6076 - val_accuracy: 0.8694\n",
            "Epoch 17/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0952 - accuracy: 0.9744 - val_loss: 0.5932 - val_accuracy: 0.8798\n",
            "Epoch 18/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0826 - accuracy: 0.9771 - val_loss: 0.6002 - val_accuracy: 0.8754\n",
            "Epoch 19/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0759 - accuracy: 0.9802 - val_loss: 0.5986 - val_accuracy: 0.8776\n",
            "Epoch 20/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0710 - accuracy: 0.9804 - val_loss: 0.5919 - val_accuracy: 0.8817\n",
            "Epoch 21/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0765 - accuracy: 0.9813 - val_loss: 0.5969 - val_accuracy: 0.8825\n",
            "Epoch 22/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0604 - accuracy: 0.9840 - val_loss: 0.6116 - val_accuracy: 0.8733\n",
            "Epoch 23/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0476 - accuracy: 0.9862 - val_loss: 0.5902 - val_accuracy: 0.8858\n",
            "Epoch 24/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0455 - accuracy: 0.9878 - val_loss: 0.6072 - val_accuracy: 0.8886\n",
            "Epoch 25/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0370 - accuracy: 0.9894 - val_loss: 0.6130 - val_accuracy: 0.8850\n",
            "Epoch 26/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0427 - accuracy: 0.9891 - val_loss: 0.6232 - val_accuracy: 0.8825\n",
            "Epoch 27/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9910 - val_loss: 0.6164 - val_accuracy: 0.8902\n",
            "Epoch 28/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 0.6133 - val_accuracy: 0.8886\n",
            "de test obs. 1000 accuracy 0.9224075416968818\n",
            "de test obs. 1000 b_accuracy 0.892146860078943\n",
            "fr test obs. 1000 accuracy 0.7433628318584071\n",
            "fr test obs. 1000 b_accuracy 0.6950651188252002\n",
            "3 16548 11418\n",
            "Model: \"model_116\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_83 (Embedding)        (None, 32, 300)      3637800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_73 (Reshape)            (None, 32, 300, 1)   0           embedding_83[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 32, 1, 75)    22575       reshape_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 31, 1, 75)    45075       reshape_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 28, 1, 75)    112575      reshape_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_261 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_262 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_263 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 3, 1, 75)     0           max_pooling2d_261[0][0]          \n",
            "                                                                 max_pooling2d_262[0][0]          \n",
            "                                                                 max_pooling2d_263[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 74)           16724       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 3,834,749\n",
            "Trainable params: 196,949\n",
            "Non-trainable params: 3,637,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 4.3919 - accuracy: 0.0832 - val_loss: 3.5786 - val_accuracy: 0.2054\n",
            "Epoch 2/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 2.7366 - accuracy: 0.3602 - val_loss: 2.3786 - val_accuracy: 0.5031\n",
            "Epoch 3/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 1.7613 - accuracy: 0.5633 - val_loss: 1.7007 - val_accuracy: 0.6386\n",
            "Epoch 4/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 1.2537 - accuracy: 0.6704 - val_loss: 1.3218 - val_accuracy: 0.6979\n",
            "Epoch 5/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.9473 - accuracy: 0.7365 - val_loss: 1.0681 - val_accuracy: 0.7738\n",
            "Epoch 6/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.7523 - accuracy: 0.7864 - val_loss: 0.9342 - val_accuracy: 0.7689\n",
            "Epoch 7/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.6158 - accuracy: 0.8226 - val_loss: 0.8069 - val_accuracy: 0.8063\n",
            "Epoch 8/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.5018 - accuracy: 0.8519 - val_loss: 0.7457 - val_accuracy: 0.8266\n",
            "Epoch 9/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.4230 - accuracy: 0.8734 - val_loss: 0.6968 - val_accuracy: 0.8418\n",
            "Epoch 10/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.3581 - accuracy: 0.8925 - val_loss: 0.6185 - val_accuracy: 0.8547\n",
            "Epoch 11/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.3137 - accuracy: 0.9057 - val_loss: 0.5756 - val_accuracy: 0.8675\n",
            "Epoch 12/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.2572 - accuracy: 0.9205 - val_loss: 0.5674 - val_accuracy: 0.8656\n",
            "Epoch 13/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.2302 - accuracy: 0.9287 - val_loss: 0.5474 - val_accuracy: 0.8667\n",
            "Epoch 14/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1956 - accuracy: 0.9409 - val_loss: 0.5126 - val_accuracy: 0.8825\n",
            "Epoch 15/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1721 - accuracy: 0.9481 - val_loss: 0.5012 - val_accuracy: 0.8820\n",
            "Epoch 16/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1531 - accuracy: 0.9547 - val_loss: 0.4901 - val_accuracy: 0.8828\n",
            "Epoch 17/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1336 - accuracy: 0.9585 - val_loss: 0.4769 - val_accuracy: 0.8869\n",
            "Epoch 18/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1134 - accuracy: 0.9665 - val_loss: 0.4753 - val_accuracy: 0.8902\n",
            "Epoch 19/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.1022 - accuracy: 0.9708 - val_loss: 0.4706 - val_accuracy: 0.8937\n",
            "Epoch 20/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0996 - accuracy: 0.9692 - val_loss: 0.4771 - val_accuracy: 0.8894\n",
            "Epoch 21/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0889 - accuracy: 0.9740 - val_loss: 0.4660 - val_accuracy: 0.8913\n",
            "Epoch 22/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0745 - accuracy: 0.9785 - val_loss: 0.4589 - val_accuracy: 0.8943\n",
            "Epoch 23/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0684 - accuracy: 0.9795 - val_loss: 0.4618 - val_accuracy: 0.8973\n",
            "Epoch 24/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0596 - accuracy: 0.9823 - val_loss: 0.4596 - val_accuracy: 0.8989\n",
            "Epoch 25/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0572 - accuracy: 0.9833 - val_loss: 0.4483 - val_accuracy: 0.9000\n",
            "Epoch 26/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.4526 - val_accuracy: 0.9047\n",
            "Epoch 27/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.4606 - val_accuracy: 0.9003\n",
            "Epoch 28/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0456 - accuracy: 0.9866 - val_loss: 0.4560 - val_accuracy: 0.9025\n",
            "Epoch 29/100\n",
            "357/357 [==============================] - 2s 6ms/step - loss: 0.0393 - accuracy: 0.9891 - val_loss: 0.4617 - val_accuracy: 0.9052\n",
            "Epoch 30/100\n",
            "357/357 [==============================] - 2s 5ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.4666 - val_accuracy: 0.9049\n",
            "de test obs. 2000 accuracy 0.9325598259608412\n",
            "de test obs. 2000 b_accuracy 0.8942795862187991\n",
            "fr test obs. 2000 accuracy 0.8241150442477876\n",
            "fr test obs. 2000 b_accuracy 0.8289147202466319\n",
            "2 16548 15418\n",
            "Model: \"model_117\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_84 (Embedding)        (None, 32, 300)      3637800     text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_74 (Reshape)            (None, 32, 300, 1)   0           embedding_84[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 32, 1, 75)    22575       reshape_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 31, 1, 75)    45075       reshape_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 28, 1, 75)    112575      reshape_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_264 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_265 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_266 (MaxPooling2D (None, 1, 1, 75)     0           conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 3, 1, 75)     0           max_pooling2d_264[0][0]          \n",
            "                                                                 max_pooling2d_265[0][0]          \n",
            "                                                                 max_pooling2d_266[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flat (Flatten)                  (None, 225)          0           concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop (Dropout)                  (None, 225)          0           flat[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output_de (Dense)               (None, 74)           16724       drop[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 3,834,749\n",
            "Trainable params: 196,949\n",
            "Non-trainable params: 3,637,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "482/482 [==============================] - 3s 6ms/step - loss: 3.8644 - accuracy: 0.1751 - val_loss: 3.2269 - val_accuracy: 0.2267\n",
            "Epoch 2/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 2.0678 - accuracy: 0.4904 - val_loss: 2.0619 - val_accuracy: 0.5275\n",
            "Epoch 3/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 1.3519 - accuracy: 0.6555 - val_loss: 1.5125 - val_accuracy: 0.6408\n",
            "Epoch 4/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.9744 - accuracy: 0.7347 - val_loss: 1.1627 - val_accuracy: 0.7353\n",
            "Epoch 5/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.7418 - accuracy: 0.7912 - val_loss: 0.9605 - val_accuracy: 0.7725\n",
            "Epoch 6/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.5947 - accuracy: 0.8240 - val_loss: 0.8009 - val_accuracy: 0.8159\n",
            "Epoch 7/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.4802 - accuracy: 0.8545 - val_loss: 0.6824 - val_accuracy: 0.8413\n",
            "Epoch 8/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.3990 - accuracy: 0.8801 - val_loss: 0.6167 - val_accuracy: 0.8533\n",
            "Epoch 9/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.3406 - accuracy: 0.8960 - val_loss: 0.5694 - val_accuracy: 0.8607\n",
            "Epoch 10/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.2782 - accuracy: 0.9146 - val_loss: 0.5277 - val_accuracy: 0.8697\n",
            "Epoch 11/100\n",
            "482/482 [==============================] - 3s 6ms/step - loss: 0.2397 - accuracy: 0.9273 - val_loss: 0.4954 - val_accuracy: 0.8845\n",
            "Epoch 12/100\n",
            "482/482 [==============================] - 3s 6ms/step - loss: 0.2043 - accuracy: 0.9352 - val_loss: 0.4693 - val_accuracy: 0.8872\n",
            "Epoch 13/100\n",
            "482/482 [==============================] - 3s 6ms/step - loss: 0.1782 - accuracy: 0.9452 - val_loss: 0.4379 - val_accuracy: 0.8984\n",
            "Epoch 14/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.9504 - val_loss: 0.4444 - val_accuracy: 0.8927\n",
            "Epoch 15/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.1362 - accuracy: 0.9559 - val_loss: 0.4023 - val_accuracy: 0.9063\n",
            "Epoch 16/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.1180 - accuracy: 0.9630 - val_loss: 0.4036 - val_accuracy: 0.9014\n",
            "Epoch 17/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.1042 - accuracy: 0.9666 - val_loss: 0.3924 - val_accuracy: 0.9107\n",
            "Epoch 18/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0875 - accuracy: 0.9716 - val_loss: 0.4050 - val_accuracy: 0.9058\n",
            "Epoch 19/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0822 - accuracy: 0.9735 - val_loss: 0.3760 - val_accuracy: 0.9153\n",
            "Epoch 20/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0710 - accuracy: 0.9777 - val_loss: 0.3657 - val_accuracy: 0.9170\n",
            "Epoch 21/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0664 - accuracy: 0.9773 - val_loss: 0.3742 - val_accuracy: 0.9161\n",
            "Epoch 22/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0608 - accuracy: 0.9804 - val_loss: 0.3727 - val_accuracy: 0.9178\n",
            "Epoch 23/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 0.3549 - val_accuracy: 0.9241\n",
            "Epoch 24/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.3558 - val_accuracy: 0.9262\n",
            "Epoch 25/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0425 - accuracy: 0.9855 - val_loss: 0.3610 - val_accuracy: 0.9287\n",
            "Epoch 26/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0433 - accuracy: 0.9858 - val_loss: 0.3758 - val_accuracy: 0.9243\n",
            "Epoch 27/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 0.3553 - val_accuracy: 0.9235\n",
            "Epoch 28/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.3562 - val_accuracy: 0.9287\n",
            "de test obs. 5000 accuracy 0.934010152284264\n",
            "de test obs. 5000 b_accuracy 0.9184923260512577\n",
            "fr test obs. 5000 accuracy 0.8926991150442478\n",
            "fr test obs. 5000 b_accuracy 0.8746118794515927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsJoRUySFHfm",
        "colab_type": "text"
      },
      "source": [
        "## CNN2D French - German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkxVSQZyFMVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def run_ml_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\n",
        "             vocab_size,embedding_matrix,class_weight_dict,no):\n",
        "   \n",
        "    X_train_pad =  np.concatenate((X_train_pad_de[:no], X_train_pad_fr))\n",
        "    y_train_enc =  np.concatenate((y_train_enc_de[:no], y_train_enc_fr))\n",
        "\n",
        "    imbala = int(len(X_train_pad_fr)/no)\n",
        "    if imbala > 1:\n",
        "        for n in range(1,imbala):\n",
        "            X_train_pad =  np.concatenate((X_train_pad, X_train_pad_de[:no]))\n",
        "            y_train_enc =  np.concatenate((y_train_enc, y_train_enc_de[:no]))\n",
        "    X_val_pad =  np.concatenate((X_val_pad_de, X_val_pad_fr))\n",
        "    y_val_enc =  np.concatenate((y_val_enc_de, y_val_enc_fr))\n",
        "    print(imbala,len(X_train_pad_de),len(X_train_pad))\n",
        "\n",
        "    dropout_rate=.2\n",
        "    filter_sizes = [1,2,5]\n",
        "    num_filters = 75\n",
        "\n",
        "    input_layer = Input(shape = (seq_len,), name='text_input')\n",
        "    x = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable = True)(input_layer)\n",
        "    x = Reshape((seq_len, embedding_dim, 1))(x)\n",
        "\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embedding_dim),\n",
        "                                      kernel_initializer='he_normal', activation='relu')(x)\n",
        "        maxpool_pool.append(MaxPool2D(pool_size=(seq_len - filter_sizes[i] + 1, 1))(conv))\n",
        "\n",
        "    pool_layer = Concatenate(axis=1)(maxpool_pool)   \n",
        "\n",
        "    falt_layer = Flatten(name='flat')(pool_layer)\n",
        "    drop_layer = Dropout(dropout_rate,name='drop')(falt_layer)\n",
        "    pred_layer = Dense(no_Classes, activation = 'softmax', name='output_de')(drop_layer) \n",
        "\n",
        "    de_cnn2d_ml = Model(inputs = [input_layer], outputs = [pred_layer])\n",
        "\n",
        "    lr = .001\n",
        "    opt = Adam(lr=lr, decay=lr/100)\n",
        "\n",
        "    de_cnn2d_ml.compile(optimizer = opt, loss = ['categorical_crossentropy'], metrics = ['accuracy'])\n",
        "    early_stopping = EarlyStopping(patience = 5)\n",
        "\n",
        "    hist = de_cnn2d_ml.fit(x = X_train_pad, y = y_train_enc,\\\n",
        "                    validation_data = (X_val_pad, y_val_enc), \\\n",
        "                    epochs = 50, batch_size = 256, shuffle = True, class_weight = class_weight_dict, \\\n",
        "                    callbacks = [early_stopping])\n",
        "    \n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "    y_pred_test_de = de_cnn2d_ml.predict(X_test_pad_de)\n",
        "    y_pred_arg_de = y_pred_test_de.argmax(axis=1)\n",
        "    y_pred_test_de = [encoder.classes_[y] for y in y_pred_arg_de]\n",
        "\n",
        "    y_pred_test_fr = de_cnn2d_ml.predict(X_test_pad_fr)\n",
        "    y_pred_arg_fr = y_pred_test_fr.argmax(axis=1)\n",
        "    y_pred_test_fr= [encoder.classes_[y] for y in y_pred_arg_fr]\n",
        "\n",
        "    print('de test obs.',no,'accuracy %s' % accuracy_score(y_pred_test_de, y_test_de))\n",
        "    print('de test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test_de, y_test_de))\n",
        "    print('fr test obs.',no,'accuracy %s' % accuracy_score(y_pred_test_fr, y_test_fr))\n",
        "    print('fr test obs.',no,'b_accuracy %s' % balanced_accuracy_score(y_pred_test_fr, y_test_fr))"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIzDN8hAFXx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2ab9dfb-7b3e-468f-9934-7de13cb54b70"
      },
      "source": [
        "for obs in [100,250,500,1000,2000,5000]:\n",
        "     run_ml_CNN2D(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,\n",
        "             X_train_pad_fr,y_train_enc_fr,X_val_pad_fr,y_val_enc_fr,X_test_pad_fr,y_test_fr,\n",
        "             vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54 16548 10818\n",
            "Epoch 1/50\n",
            "43/43 [==============================] - 2s 42ms/step - loss: 4.2286 - accuracy: 0.0797 - val_loss: 4.2607 - val_accuracy: 0.0699\n",
            "Epoch 2/50\n",
            "43/43 [==============================] - 2s 50ms/step - loss: 2.5615 - accuracy: 0.4424 - val_loss: 3.5034 - val_accuracy: 0.2508\n",
            "Epoch 3/50\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 1.3115 - accuracy: 0.7462 - val_loss: 2.9744 - val_accuracy: 0.3824\n",
            "Epoch 4/50\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.7333 - accuracy: 0.8491 - val_loss: 2.7959 - val_accuracy: 0.4288\n",
            "Epoch 5/50\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.4909 - accuracy: 0.8853 - val_loss: 2.7512 - val_accuracy: 0.4420\n",
            "Epoch 6/50\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.3528 - accuracy: 0.9136 - val_loss: 2.7362 - val_accuracy: 0.4616\n",
            "Epoch 7/50\n",
            "43/43 [==============================] - 2s 36ms/step - loss: 0.2680 - accuracy: 0.9317 - val_loss: 2.6937 - val_accuracy: 0.4665\n",
            "Epoch 8/50\n",
            "43/43 [==============================] - 2s 35ms/step - loss: 0.2099 - accuracy: 0.9505 - val_loss: 2.7540 - val_accuracy: 0.4685\n",
            "Epoch 9/50\n",
            "43/43 [==============================] - 1s 34ms/step - loss: 0.1610 - accuracy: 0.9587 - val_loss: 2.7544 - val_accuracy: 0.4753\n",
            "Epoch 10/50\n",
            "43/43 [==============================] - 2s 35ms/step - loss: 0.1315 - accuracy: 0.9647 - val_loss: 2.7658 - val_accuracy: 0.4821\n",
            "Epoch 11/50\n",
            "43/43 [==============================] - 2s 35ms/step - loss: 0.1028 - accuracy: 0.9735 - val_loss: 2.7707 - val_accuracy: 0.4821\n",
            "Epoch 12/50\n",
            "43/43 [==============================] - 2s 37ms/step - loss: 0.0842 - accuracy: 0.9776 - val_loss: 2.7966 - val_accuracy: 0.4854\n",
            "de test obs. 100 accuracy 0.35351704133430023\n",
            "de test obs. 100 b_accuracy 0.34193454329932454\n",
            "fr test obs. 100 accuracy 0.9280973451327433\n",
            "fr test obs. 100 b_accuracy 0.902481003896748\n",
            "21 16548 10668\n",
            "Epoch 1/50\n",
            "42/42 [==============================] - 2s 41ms/step - loss: 4.4907 - accuracy: 0.0583 - val_loss: 4.1101 - val_accuracy: 0.0997\n",
            "Epoch 2/50\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 3.1416 - accuracy: 0.3148 - val_loss: 3.3542 - val_accuracy: 0.2554\n",
            "Epoch 3/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.7035 - accuracy: 0.6635 - val_loss: 2.4312 - val_accuracy: 0.4887\n",
            "Epoch 4/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.8605 - accuracy: 0.8286 - val_loss: 1.9555 - val_accuracy: 0.5728\n",
            "Epoch 5/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.5251 - accuracy: 0.8892 - val_loss: 1.7588 - val_accuracy: 0.6187\n",
            "Epoch 6/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.3678 - accuracy: 0.9140 - val_loss: 1.6955 - val_accuracy: 0.6247\n",
            "Epoch 7/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.2702 - accuracy: 0.9349 - val_loss: 1.6275 - val_accuracy: 0.6359\n",
            "Epoch 8/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.2110 - accuracy: 0.9471 - val_loss: 1.6041 - val_accuracy: 0.6356\n",
            "Epoch 9/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1684 - accuracy: 0.9588 - val_loss: 1.5949 - val_accuracy: 0.6392\n",
            "Epoch 10/50\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1352 - accuracy: 0.9646 - val_loss: 1.5685 - val_accuracy: 0.6414\n",
            "Epoch 11/50\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1068 - accuracy: 0.9716 - val_loss: 1.5659 - val_accuracy: 0.6471\n",
            "Epoch 12/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0929 - accuracy: 0.9761 - val_loss: 1.5709 - val_accuracy: 0.6403\n",
            "Epoch 13/50\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0735 - accuracy: 0.9797 - val_loss: 1.5779 - val_accuracy: 0.6433\n",
            "Epoch 14/50\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.0629 - accuracy: 0.9817 - val_loss: 1.5671 - val_accuracy: 0.6512\n",
            "Epoch 15/50\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.0542 - accuracy: 0.9846 - val_loss: 1.5971 - val_accuracy: 0.6449\n",
            "Epoch 16/50\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.0495 - accuracy: 0.9863 - val_loss: 1.5869 - val_accuracy: 0.6471\n",
            "de test obs. 250 accuracy 0.5554749818709209\n",
            "de test obs. 250 b_accuracy 0.5304321329790177\n",
            "fr test obs. 250 accuracy 0.9413716814159292\n",
            "fr test obs. 250 b_accuracy 0.9160144602628986\n",
            "10 16548 10418\n",
            "Epoch 1/50\n",
            "41/41 [==============================] - 2s 41ms/step - loss: 4.4813 - accuracy: 0.0412 - val_loss: 4.2077 - val_accuracy: 0.0232\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 3.2976 - accuracy: 0.2551 - val_loss: 3.3913 - val_accuracy: 0.2527\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 2.0062 - accuracy: 0.5794 - val_loss: 2.4199 - val_accuracy: 0.4865\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 1.1015 - accuracy: 0.7805 - val_loss: 1.7066 - val_accuracy: 0.6657\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.6458 - accuracy: 0.8648 - val_loss: 1.4175 - val_accuracy: 0.7077\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.4364 - accuracy: 0.9018 - val_loss: 1.2693 - val_accuracy: 0.7271\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.3146 - accuracy: 0.9237 - val_loss: 1.1647 - val_accuracy: 0.7517\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.2367 - accuracy: 0.9414 - val_loss: 1.1226 - val_accuracy: 0.7506\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.1838 - accuracy: 0.9552 - val_loss: 1.0679 - val_accuracy: 0.7673\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.1456 - accuracy: 0.9626 - val_loss: 1.0376 - val_accuracy: 0.7766\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 1s 37ms/step - loss: 0.1167 - accuracy: 0.9711 - val_loss: 1.0266 - val_accuracy: 0.7763\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 2s 39ms/step - loss: 0.1000 - accuracy: 0.9728 - val_loss: 1.0015 - val_accuracy: 0.7820\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 2s 39ms/step - loss: 0.0802 - accuracy: 0.9768 - val_loss: 1.0035 - val_accuracy: 0.7828\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 2s 39ms/step - loss: 0.0696 - accuracy: 0.9807 - val_loss: 0.9911 - val_accuracy: 0.7902\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 2s 39ms/step - loss: 0.0563 - accuracy: 0.9845 - val_loss: 0.9863 - val_accuracy: 0.7809\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 2s 39ms/step - loss: 0.0528 - accuracy: 0.9860 - val_loss: 0.9869 - val_accuracy: 0.7897\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0439 - accuracy: 0.9892 - val_loss: 0.9819 - val_accuracy: 0.7856\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0385 - accuracy: 0.9890 - val_loss: 0.9783 - val_accuracy: 0.7908\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0357 - accuracy: 0.9911 - val_loss: 0.9811 - val_accuracy: 0.7927\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0331 - accuracy: 0.9905 - val_loss: 0.9725 - val_accuracy: 0.7932\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0266 - accuracy: 0.9942 - val_loss: 0.9871 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0239 - accuracy: 0.9943 - val_loss: 0.9837 - val_accuracy: 0.7924\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.9826 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.9870 - val_accuracy: 0.7886\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.9858 - val_accuracy: 0.7891\n",
            "de test obs. 500 accuracy 0.7306018854242204\n",
            "de test obs. 500 b_accuracy 0.7119141595103923\n",
            "fr test obs. 500 accuracy 0.9535398230088495\n",
            "fr test obs. 500 b_accuracy 0.9348270609085265\n",
            "5 16548 10418\n",
            "Epoch 1/50\n",
            "41/41 [==============================] - 2s 40ms/step - loss: 4.5643 - accuracy: 0.0591 - val_loss: 4.1232 - val_accuracy: 0.0131\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 3.4120 - accuracy: 0.2481 - val_loss: 3.2485 - val_accuracy: 0.2688\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 2.1555 - accuracy: 0.5467 - val_loss: 2.2284 - val_accuracy: 0.5269\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 2s 38ms/step - loss: 1.2607 - accuracy: 0.7388 - val_loss: 1.5199 - val_accuracy: 0.6815\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.7843 - accuracy: 0.8280 - val_loss: 1.1482 - val_accuracy: 0.7479\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.5276 - accuracy: 0.8782 - val_loss: 0.9475 - val_accuracy: 0.7869\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.3834 - accuracy: 0.9077 - val_loss: 0.8509 - val_accuracy: 0.8052\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.2857 - accuracy: 0.9295 - val_loss: 0.7672 - val_accuracy: 0.8249\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.2237 - accuracy: 0.9441 - val_loss: 0.7196 - val_accuracy: 0.8315\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.1790 - accuracy: 0.9552 - val_loss: 0.6879 - val_accuracy: 0.8296\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.1397 - accuracy: 0.9644 - val_loss: 0.6632 - val_accuracy: 0.8377\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.1208 - accuracy: 0.9672 - val_loss: 0.6310 - val_accuracy: 0.8479\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.1025 - accuracy: 0.9725 - val_loss: 0.6218 - val_accuracy: 0.8413\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0864 - accuracy: 0.9747 - val_loss: 0.6046 - val_accuracy: 0.8489\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0748 - accuracy: 0.9809 - val_loss: 0.6023 - val_accuracy: 0.8484\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 1s 37ms/step - loss: 0.0633 - accuracy: 0.9834 - val_loss: 0.5921 - val_accuracy: 0.8517\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0573 - accuracy: 0.9845 - val_loss: 0.5947 - val_accuracy: 0.8517\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0481 - accuracy: 0.9866 - val_loss: 0.5761 - val_accuracy: 0.8539\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0440 - accuracy: 0.9877 - val_loss: 0.5768 - val_accuracy: 0.8509\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.5735 - val_accuracy: 0.8550\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 0.5790 - val_accuracy: 0.8520\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.5708 - val_accuracy: 0.8552\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.5683 - val_accuracy: 0.8607\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.5695 - val_accuracy: 0.8580\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.5660 - val_accuracy: 0.8569\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 0.5663 - val_accuracy: 0.8520\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.5654 - val_accuracy: 0.8582\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.5637 - val_accuracy: 0.8563\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.5622 - val_accuracy: 0.8607\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.5708 - val_accuracy: 0.8591\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 1s 34ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.5662 - val_accuracy: 0.8607\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 1s 34ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.5703 - val_accuracy: 0.8577\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.5671 - val_accuracy: 0.8612\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.5699 - val_accuracy: 0.8615\n",
            "de test obs. 1000 accuracy 0.8190717911530094\n",
            "de test obs. 1000 b_accuracy 0.7761517926205262\n",
            "fr test obs. 1000 accuracy 0.956858407079646\n",
            "fr test obs. 1000 b_accuracy 0.9351098511728082\n",
            "2 16548 9418\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - 2s 42ms/step - loss: 4.7814 - accuracy: 0.0381 - val_loss: 4.1455 - val_accuracy: 0.0778\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 3.8155 - accuracy: 0.2075 - val_loss: 3.5804 - val_accuracy: 0.2038\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 2.7371 - accuracy: 0.4252 - val_loss: 2.7150 - val_accuracy: 0.4480\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 1.7842 - accuracy: 0.6316 - val_loss: 1.8777 - val_accuracy: 0.6140\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 1s 36ms/step - loss: 1.1676 - accuracy: 0.7487 - val_loss: 1.3285 - val_accuracy: 0.7476\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.8136 - accuracy: 0.8198 - val_loss: 1.0179 - val_accuracy: 0.7995\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 1s 38ms/step - loss: 0.5856 - accuracy: 0.8632 - val_loss: 0.8466 - val_accuracy: 0.8339\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.4337 - accuracy: 0.9008 - val_loss: 0.7187 - val_accuracy: 0.8492\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.3293 - accuracy: 0.9208 - val_loss: 0.6308 - val_accuracy: 0.8634\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 1s 38ms/step - loss: 0.2573 - accuracy: 0.9410 - val_loss: 0.5850 - val_accuracy: 0.8697\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.2111 - accuracy: 0.9488 - val_loss: 0.5414 - val_accuracy: 0.8697\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.1720 - accuracy: 0.9541 - val_loss: 0.5071 - val_accuracy: 0.8798\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.1419 - accuracy: 0.9614 - val_loss: 0.4867 - val_accuracy: 0.8820\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.1227 - accuracy: 0.9693 - val_loss: 0.4577 - val_accuracy: 0.8899\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.1034 - accuracy: 0.9724 - val_loss: 0.4471 - val_accuracy: 0.8929\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0927 - accuracy: 0.9758 - val_loss: 0.4280 - val_accuracy: 0.8924\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 1s 36ms/step - loss: 0.0806 - accuracy: 0.9787 - val_loss: 0.4179 - val_accuracy: 0.8959\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 1s 35ms/step - loss: 0.0686 - accuracy: 0.9801 - val_loss: 0.4149 - val_accuracy: 0.8967\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 1s 35ms/step - loss: 0.0615 - accuracy: 0.9844 - val_loss: 0.4053 - val_accuracy: 0.9011\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 1s 36ms/step - loss: 0.0534 - accuracy: 0.9864 - val_loss: 0.3981 - val_accuracy: 0.9006\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 1s 36ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 0.3936 - val_accuracy: 0.9022\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0436 - accuracy: 0.9882 - val_loss: 0.3934 - val_accuracy: 0.9041\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0387 - accuracy: 0.9899 - val_loss: 0.3912 - val_accuracy: 0.9006\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0357 - accuracy: 0.9902 - val_loss: 0.3821 - val_accuracy: 0.9047\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.3795 - val_accuracy: 0.9058\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.3821 - val_accuracy: 0.9036\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 1s 38ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.3821 - val_accuracy: 0.9055\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 1s 38ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.3773 - val_accuracy: 0.9063\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0243 - accuracy: 0.9934 - val_loss: 0.3759 - val_accuracy: 0.9085\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.3793 - val_accuracy: 0.9071\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.3770 - val_accuracy: 0.9088\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.3786 - val_accuracy: 0.9082\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.3767 - val_accuracy: 0.9066\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.3754 - val_accuracy: 0.9071\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.3797 - val_accuracy: 0.9071\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.3805 - val_accuracy: 0.9079\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.3818 - val_accuracy: 0.9071\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 1s 37ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.3834 - val_accuracy: 0.9074\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 1s 36ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.3762 - val_accuracy: 0.9093\n",
            "de test obs. 2000 accuracy 0.8781725888324873\n",
            "de test obs. 2000 b_accuracy 0.8279276010532758\n",
            "fr test obs. 2000 accuracy 0.9535398230088495\n",
            "fr test obs. 2000 b_accuracy 0.9319838384375666\n",
            "1 16548 10418\n",
            "Epoch 1/50\n",
            "41/41 [==============================] - 2s 39ms/step - loss: 4.7519 - accuracy: 0.0467 - val_loss: 4.0632 - val_accuracy: 0.1046\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 3.7299 - accuracy: 0.2107 - val_loss: 3.3410 - val_accuracy: 0.3494\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 2.5959 - accuracy: 0.4811 - val_loss: 2.2662 - val_accuracy: 0.6285\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 1.6367 - accuracy: 0.6742 - val_loss: 1.4102 - val_accuracy: 0.7566\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 1.0586 - accuracy: 0.7707 - val_loss: 0.9495 - val_accuracy: 0.8194\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.7449 - accuracy: 0.8330 - val_loss: 0.7166 - val_accuracy: 0.8569\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.5578 - accuracy: 0.8729 - val_loss: 0.5943 - val_accuracy: 0.8798\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.4125 - accuracy: 0.9030 - val_loss: 0.5000 - val_accuracy: 0.8948\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.3267 - accuracy: 0.9190 - val_loss: 0.4412 - val_accuracy: 0.9063\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.2566 - accuracy: 0.9332 - val_loss: 0.3851 - val_accuracy: 0.9151\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.2038 - accuracy: 0.9495 - val_loss: 0.3545 - val_accuracy: 0.9189\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.1702 - accuracy: 0.9567 - val_loss: 0.3285 - val_accuracy: 0.9257\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.1394 - accuracy: 0.9626 - val_loss: 0.3074 - val_accuracy: 0.9241\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.1194 - accuracy: 0.9664 - val_loss: 0.2922 - val_accuracy: 0.9290\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.1057 - accuracy: 0.9717 - val_loss: 0.2724 - val_accuracy: 0.9314\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0898 - accuracy: 0.9762 - val_loss: 0.2616 - val_accuracy: 0.9336\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0811 - accuracy: 0.9775 - val_loss: 0.2566 - val_accuracy: 0.9350\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 1s 37ms/step - loss: 0.0706 - accuracy: 0.9813 - val_loss: 0.2522 - val_accuracy: 0.9372\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0635 - accuracy: 0.9812 - val_loss: 0.2394 - val_accuracy: 0.9424\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 1s 34ms/step - loss: 0.0529 - accuracy: 0.9845 - val_loss: 0.2342 - val_accuracy: 0.9429\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0495 - accuracy: 0.9873 - val_loss: 0.2287 - val_accuracy: 0.9432\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0420 - accuracy: 0.9888 - val_loss: 0.2268 - val_accuracy: 0.9424\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0403 - accuracy: 0.9898 - val_loss: 0.2233 - val_accuracy: 0.9437\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0373 - accuracy: 0.9898 - val_loss: 0.2229 - val_accuracy: 0.9443\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.2211 - val_accuracy: 0.9448\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0312 - accuracy: 0.9916 - val_loss: 0.2201 - val_accuracy: 0.9451\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 0.2189 - val_accuracy: 0.9459\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.2145 - val_accuracy: 0.9470\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.2162 - val_accuracy: 0.9451\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.2142 - val_accuracy: 0.9470\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.2166 - val_accuracy: 0.9462\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.2132 - val_accuracy: 0.9495\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0179 - accuracy: 0.9958 - val_loss: 0.2140 - val_accuracy: 0.9476\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.2142 - val_accuracy: 0.9470\n",
            "Epoch 35/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.2143 - val_accuracy: 0.9470\n",
            "Epoch 36/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.2131 - val_accuracy: 0.9465\n",
            "Epoch 37/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.2142 - val_accuracy: 0.9465\n",
            "Epoch 38/50\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.2163 - val_accuracy: 0.9467\n",
            "Epoch 39/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.2132 - val_accuracy: 0.9497\n",
            "Epoch 40/50\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.2134 - val_accuracy: 0.9508\n",
            "Epoch 41/50\n",
            "41/41 [==============================] - 1s 36ms/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: 0.2179 - val_accuracy: 0.9459\n",
            "de test obs. 5000 accuracy 0.9390862944162437\n",
            "de test obs. 5000 b_accuracy 0.9085978503989863\n",
            "fr test obs. 5000 accuracy 0.9513274336283186\n",
            "fr test obs. 5000 b_accuracy 0.9338290115814757\n",
            "0 16548 15418\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 4.3940 - accuracy: 0.0658 - val_loss: 3.5899 - val_accuracy: 0.2472\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 2.8922 - accuracy: 0.4244 - val_loss: 1.8942 - val_accuracy: 0.6709\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.4550 - accuracy: 0.7080 - val_loss: 0.9475 - val_accuracy: 0.8126\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.8429 - accuracy: 0.8151 - val_loss: 0.6507 - val_accuracy: 0.8640\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.5639 - accuracy: 0.8693 - val_loss: 0.5007 - val_accuracy: 0.8886\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.4024 - accuracy: 0.9029 - val_loss: 0.3981 - val_accuracy: 0.9077\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.3041 - accuracy: 0.9230 - val_loss: 0.3410 - val_accuracy: 0.9189\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.2310 - accuracy: 0.9392 - val_loss: 0.3052 - val_accuracy: 0.9257\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.1804 - accuracy: 0.9528 - val_loss: 0.2671 - val_accuracy: 0.9339\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.1423 - accuracy: 0.9609 - val_loss: 0.2462 - val_accuracy: 0.9391\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.1167 - accuracy: 0.9696 - val_loss: 0.2264 - val_accuracy: 0.9448\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0969 - accuracy: 0.9747 - val_loss: 0.2166 - val_accuracy: 0.9465\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.0790 - accuracy: 0.9781 - val_loss: 0.2010 - val_accuracy: 0.9489\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0663 - accuracy: 0.9822 - val_loss: 0.1916 - val_accuracy: 0.9522\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0600 - accuracy: 0.9837 - val_loss: 0.1872 - val_accuracy: 0.9497\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0511 - accuracy: 0.9859 - val_loss: 0.1807 - val_accuracy: 0.9579\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0451 - accuracy: 0.9873 - val_loss: 0.1739 - val_accuracy: 0.9582\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0372 - accuracy: 0.9893 - val_loss: 0.1720 - val_accuracy: 0.9585\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.0339 - accuracy: 0.9907 - val_loss: 0.1698 - val_accuracy: 0.9598\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0327 - accuracy: 0.9901 - val_loss: 0.1693 - val_accuracy: 0.9604\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.1688 - val_accuracy: 0.9601\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0257 - accuracy: 0.9929 - val_loss: 0.1686 - val_accuracy: 0.9623\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.1702 - val_accuracy: 0.9623\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.1649 - val_accuracy: 0.9607\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.1663 - val_accuracy: 0.9609\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.1648 - val_accuracy: 0.9623\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.1665 - val_accuracy: 0.9626\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.1683 - val_accuracy: 0.9623\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.1665 - val_accuracy: 0.9631\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.1654 - val_accuracy: 0.9645\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.1682 - val_accuracy: 0.9631\n",
            "de test obs. 10000 accuracy 0.9557650471356055\n",
            "de test obs. 10000 b_accuracy 0.9233029126775758\n",
            "fr test obs. 10000 accuracy 0.952433628318584\n",
            "fr test obs. 10000 b_accuracy 0.9305537139074179\n",
            "0 16548 20418\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 3s 38ms/step - loss: 4.1715 - accuracy: 0.1237 - val_loss: 3.1125 - val_accuracy: 0.4633\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 2.0927 - accuracy: 0.6056 - val_loss: 1.1267 - val_accuracy: 0.7968\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.9264 - accuracy: 0.8127 - val_loss: 0.6428 - val_accuracy: 0.8626\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 0.5620 - accuracy: 0.8727 - val_loss: 0.4648 - val_accuracy: 0.8946\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.3797 - accuracy: 0.9079 - val_loss: 0.3758 - val_accuracy: 0.9107\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 3s 34ms/step - loss: 0.2799 - accuracy: 0.9285 - val_loss: 0.3206 - val_accuracy: 0.9230\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 3s 34ms/step - loss: 0.2132 - accuracy: 0.9439 - val_loss: 0.2789 - val_accuracy: 0.9309\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.1614 - accuracy: 0.9569 - val_loss: 0.2423 - val_accuracy: 0.9394\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.1216 - accuracy: 0.9654 - val_loss: 0.2185 - val_accuracy: 0.9435\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0980 - accuracy: 0.9726 - val_loss: 0.1987 - val_accuracy: 0.9511\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0849 - accuracy: 0.9783 - val_loss: 0.1855 - val_accuracy: 0.9511\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0646 - accuracy: 0.9814 - val_loss: 0.1762 - val_accuracy: 0.9541\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0569 - accuracy: 0.9836 - val_loss: 0.1664 - val_accuracy: 0.9563\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0478 - accuracy: 0.9868 - val_loss: 0.1600 - val_accuracy: 0.9568\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.1559 - val_accuracy: 0.9590\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 3s 37ms/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.1514 - val_accuracy: 0.9601\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 0.0332 - accuracy: 0.9901 - val_loss: 0.1469 - val_accuracy: 0.9623\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.1458 - val_accuracy: 0.9656\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.1426 - val_accuracy: 0.9667\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.1453 - val_accuracy: 0.9656\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 0.0217 - accuracy: 0.9945 - val_loss: 0.1410 - val_accuracy: 0.9669\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.1413 - val_accuracy: 0.9653\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.1422 - val_accuracy: 0.9661\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.1419 - val_accuracy: 0.9659\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.1409 - val_accuracy: 0.9659\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.1412 - val_accuracy: 0.9697\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 3s 34ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.1450 - val_accuracy: 0.9675\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1436 - val_accuracy: 0.9678\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 3s 35ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.1453 - val_accuracy: 0.9683\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 3s 36ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.1459 - val_accuracy: 0.9667\n",
            "de test obs. 15000 accuracy 0.9644670050761421\n",
            "de test obs. 15000 b_accuracy 0.938502930393491\n",
            "fr test obs. 15000 accuracy 0.9513274336283186\n",
            "fr test obs. 15000 b_accuracy 0.9301577279215215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYthFWd4lUTf",
        "colab_type": "text"
      },
      "source": [
        "# Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGTYK6s5nUcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install ktrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bac0n_MGu0el",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names_ = df_de['cc5'].unique()\n",
        "class_names_.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNuN8eXD6eNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run_CNN(X_train_pad_de,y_train_enc_de,X_val_pad_de,y_val_enc_de,X_test_pad_de,y_test_de,vocab_size_de,embedding_matrix_de,class_weight_dict_de,obs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrsYuXhnCTBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var1 = 'categ'\n",
        "var2 = 'words_from_url'\n",
        "var3 = 'name'\n",
        "df_fr['text'] = 'fr ' + df_fr[var1].fillna('unknown')  + ' . ' + df_fr[var2].fillna('unknown')  + ' . ' + df_fr[var3].fillna('unknown') \n",
        "df_de['text'] = 'de ' + df_de[var1].fillna('unknown')  + ' . ' + df_de[var2].fillna('unknown')  + ' . ' + df_de[var3].fillna('unknown') \n",
        "df_at['text'] = 'de ' + df_at[var1].fillna('unknown')  + ' . ' + df_at[var2].fillna('unknown')  + ' . ' + df_at[var3].fillna('unknown') \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "def split_train_abs(df):\n",
        "    X_train, X_val_test, y_train, y_val_test  = train_test_split(df['text'], df['cc5'], random_state=42, shuffle=True)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val_test , y_val_test, random_state=42)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "X_train_de, X_val_de, X_test_de, y_train_de, y_val_de, y_test_de = split_train_abs(df_de)\n",
        "X_train_fr, X_val_fr, X_test_fr, y_train_fr, y_val_fr, y_test_fr = split_train_abs(df_fr)\n",
        "\n",
        "print('de',X_train_de.shape, X_val_de.shape, X_test_de.shape, y_train_de.shape, y_val_de.shape, y_test_de.shape )\n",
        "print('fr',X_train_fr.shape, X_val_fr.shape, X_test_fr.shape, y_train_fr.shape, y_val_fr.shape, y_test_fr.shape )\n",
        "\n",
        "X_train_de = [str(sen) for sen in X_train_de]\n",
        "X_val_de = [str(sen) for sen in X_val_de]\n",
        "X_test_de = [str(sen) for sen in X_test_de]\n",
        "\n",
        "y_train_de = [str(sen) for sen in y_train_de]\n",
        "y_val_de = [str(sen) for sen in y_val_de]\n",
        "y_test_de = [str(sen) for sen in y_test_de]\n",
        "\n",
        "X_train_fr = [str(sen) for sen in X_train_fr]\n",
        "X_val_fr = [str(sen) for sen in X_val_fr]\n",
        "X_test_fr = [str(sen) for sen in X_test_fr]\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(df_de['cc5'])\n",
        "\n",
        "def encode_label(y_):\n",
        "    y__ = encoder.transform(y_)\n",
        "    #y_enc =tf.keras.utils.to_categorical(y__, num_classes=no_Classes, dtype=\"float32\")\n",
        "    return y__\n",
        "\n",
        "y_train_enc_de = encode_label(y_train_de)\n",
        "y_val_enc_de = encode_label(y_val_de)\n",
        "y_test_enc_de = encode_label(y_test_de)\n",
        "\n",
        "y_train_enc_fr = encode_label(y_train_fr)\n",
        "y_val_enc_fr = encode_label(y_val_fr)\n",
        "y_test_enc_fr = encode_label(y_test_fr)\n",
        "\n",
        "print(y_train_enc_de.shape,y_val_enc_de.shape,y_test_enc_de.shape)\n",
        "print(y_train_enc_fr.shape,y_val_enc_fr.shape,y_test_enc_fr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkAMEHNclUgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "MODEL_NAME = 'xlm-roberta-large'#'bert-base-multilingual-cased'\n",
        "t = text.Transformer(MODEL_NAME, maxlen=60, class_names=class_names_)\n",
        "\n",
        "trn = t.preprocess_train(X_train_de, y_train_de)\n",
        "val = t.preprocess_test(X_val_de, y_val_de)\n",
        "#test = t.preprocess_test(X_test_de, y_test_enc_de)\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw0clG3J9VPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.lr_find()\n",
        "learner.lr_plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qmg8zlaH829",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit(5e-5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLIznHW57aZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install simpletransformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCdV1iATlUjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "from simpletransformers.classification import MultiLabelClassificationModel\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "train_data = pd.DataFrame(list(zip(X_train_de,y_train_de)), columns =['text','y'])\n",
        "eval_df = pd.DataFrame(list(zip(X_val_de,y_val_de)), columns =['text','y'])\n",
        "test_df = pd.DataFrame(list(zip(X_test_de,y_test_de)), columns =['text','y'])\n",
        "\n",
        " \n",
        "# Train and Evaluation data needs to be in a Pandas Dataframe of two columns. The first column is the text with type str, and the second column is the label with type int.\n",
        "#train_data = [['Example sentence belonging to class 1', 1], ['Example sentence belonging to class 0', 0]]\n",
        "#train_df = pd.DataFrame(train_data)\n",
        "\n",
        "#eval_data = [['Example eval sentence belonging to class 1', 1], ['Example eval sentence belonging to class 0', 0]]\n",
        "#eval_df = pd.DataFrame(eval_data)\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel('XLM,', 'XLM-RoBERTa') # You can set class weights by using the optional weight argument\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwqzwcyQ3t_Z",
        "colab_type": "text"
      },
      "source": [
        "get the french"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnTHX7GJ8HVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(class_names)\n",
        "Y_FRENCH.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoCTIP6a3wgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_FRENCH = list(df_fr['text'])\n",
        "Y_FRENCH = encode_label(df_fr['cc5'],encoder5)\n",
        "\n",
        "test = t.preprocess_test(X_FRENCH, Y_FRENCH)\n",
        "learner.validate(val_data=test, class_names=t.get_classes())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRp7ewNBlUmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded_predictor = ktrain.get_predictor(learner.model, preproc=preproc)\n",
        "reloaded_predictor.predict(X_test[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkE07ik3xmWB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPknKZ3kmYJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1AtuawmqvKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
        "\n",
        "torch.set_grad_enabled(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lze_FoM3rboE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store the model we want to use\n",
        "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "\n",
        "# We need to create the model and tokenizer\n",
        "model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EME7uTGWrceM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import (TFBertForSequenceClassification, \n",
        "                          BertTokenizer,\n",
        "                          TFRobertaForSequenceClassification, \n",
        "                          RobertaTokenizer)\n",
        "\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "#roberta_model = TFRobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
        "#roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLznIZuYtlI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence = \"Systolic arrays are cool. This 🐳 is cool too.\"\n",
        "\n",
        "bert_tokenized_sequence = bert_tokenizer.tokenize(sequence)\n",
        "\n",
        "print(\"BERT:\", bert_tokenized_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKi3lvCmtrZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "encoded_bert_sequence = bert_tokenizer.encode(list(X_train_de), add_special_tokens=True, max_length=128)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OXvSBM6v9XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame(zip(X_train_de , y_train_de),columns=['text','cc5'])\n",
        "df_train = pd.DataFrame(zip(X_train_de , y_train_de),columns=['text','cc5'])\n",
        "df_train = pd.DataFrame(zip(X_train_de , y_train_de),columns=['text','cc5'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnxnKgVgvY7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_bert_sequence = bert_tokenizer.encode(list(X_train_de), add_special_tokens=True, max_length=64)\n",
        "\n",
        "tf_train = tf.data.Dataset.from_tensor_slices((encoded_bert_sequence, df_train['cc5'].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYNnPNCpvJKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import glue_convert_examples_to_features\n",
        "\n",
        "bert_train_dataset = glue_convert_examples_to_features(tf_train, bert_tokenizer, 64, 'mrpc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT_oTop7t6H6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "bert_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpxrVm2qu2xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Fine-tuning BERT on MRPC\")\n",
        "bert_history = bert_model.fit(bert_train_dataset, epochs=3, validation_data=bert_validation_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6FoO9u0vEZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Evaluating the BERT model\")\n",
        "bert_model.evaluate(bert_validation_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLcNppbvvErA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}